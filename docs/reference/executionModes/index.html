<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.15">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Smart Data Lake Builder RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Smart Data Lake Builder Atom Feed"><title data-react-helmet="true">Execution Modes | Smart Data Lake Builder</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://www.smartdatalake.ch/docs/reference/executionModes"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Execution Modes | Smart Data Lake Builder"><meta data-react-helmet="true" name="description" content="This page is under review and currently not visible in the menu."><meta data-react-helmet="true" property="og:description" content="This page is under review and currently not visible in the menu."><link data-react-helmet="true" rel="icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://www.smartdatalake.ch/docs/reference/executionModes"><link data-react-helmet="true" rel="alternate" href="https://www.smartdatalake.ch/docs/reference/executionModes" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://www.smartdatalake.ch/docs/reference/executionModes" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.dc3a20c1.css">
<link rel="preload" href="/assets/js/runtime~main.29f9f513.js" as="script">
<link rel="preload" href="/assets/js/main.b58ebaed.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/sdl_logo.png" alt="Smart Data Lake Logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/sdl_logo.png" alt="Smart Data Lake Logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">Smart Data Lake</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/smart-data-lake/smart-data-lake" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_Pssr toggle_TdHA toggleDisabled_jDku"><div class="toggleTrack_SSoT" role="button" tabindex="-1"><div class="toggleTrackCheck_XobZ"><span class="toggleIcon_eZtF">ðŸŒœ</span></div><div class="toggleTrackX_YkSC"><span class="toggleIcon_eZtF">ðŸŒž</span></div><div class="toggleTrackThumb_uRm4"></div></div><input type="checkbox" class="toggleScreenReader_JnkT" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_P2Lg"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_RiI4" type="button"></button><main class="docMainContainer_TCnq docMainContainerEnhanced_WDCb"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_DM6M"><div class="docItemContainer_vinB"><article><div class="tocCollapsible_jdIR theme-doc-toc-mobile tocMobile_TmEX"><button type="button" class="clean-btn tocCollapsibleButton_Fzxq">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Execution Modes</h1></header><div class="admonition admonition-warning alert alert--danger"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="16" viewBox="0 0 12 16"><path fill-rule="evenodd" d="M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"></path></svg></span>warning</h5></div><div class="admonition-content"><p>This page is under review and currently not visible in the menu.</p></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="execution-modes">Execution modes<a class="hash-link" href="#execution-modes" title="Direct link to heading">â€‹</a></h2><p>Execution modes select the data to be processed. By default, if you start SmartDataLakeBuilder, there is no filter applied. This means every Action reads all data from its input DataObjects.</p><p>You can set an execution mode by defining attribute &quot;executionMode&quot; of an Action. Define the chosen ExecutionMode by setting type as follows:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">executionMode {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  type = PartitionDiffMode</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  attribute1 = ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="fixed-partition-values-filter">Fixed partition values filter<a class="hash-link" href="#fixed-partition-values-filter" title="Direct link to heading">â€‹</a></h3><p>You can apply a filter manually by specifying parameter <code>--partition-values</code> or <code>--multi-partition-values</code> on the command line. The partition values specified are passed to all start-Actions of a DAG and filtered for every input DataObject by its defined partition columns.
On execution every Action takes the partition values of the input and filters them again for every output DataObject by its defined partition columns, which serve again as partition values for the input of the next Action.
Note that during execution of the dag, no new partition values are added, they are only filtered. An exception is if you place a PartitionDiffMode in the middle of your pipeline, see next section.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="partitiondiffmode-dynamic-partition-values-filter">PartitionDiffMode: Dynamic partition values filter<a class="hash-link" href="#partitiondiffmode-dynamic-partition-values-filter" title="Direct link to heading">â€‹</a></h3><p>Alternatively you can let SmartDataLakeBuilder find missing partitions and set partition values automatically by specifying execution mode PartitionDiffMode.</p><p>By defining the <strong>applyCondition</strong> attribute you can give a condition to decide at runtime if the PartitionDiffMode should be applied or not.
Default is to apply the PartitionDiffMode if the given partition values are empty (partition values from command line or passed from previous action).
Define an applyCondition by a spark sql expression working with attributes of DefaultExecutionModeExpressionData returning a boolean.</p><p>By defining the <strong>failCondition</strong> attribute you can give a condition to fail application of execution mode if true.
It can be used to fail a run based on expected partitions, time and so on.
The expression is evaluated after execution of PartitionDiffMode, amongst others there are attributes inputPartitionValues, outputPartitionValues and selectedPartitionValues to make the decision.
Default is that the application of the PartitionDiffMode does not fail the action. If there is no data to process, the following actions are skipped.
Define a failCondition by a spark sql expression working with attributes of PartitionDiffModeExpressionData returning a boolean.</p><p>Example - fail if partitions are not processed in strictly increasing order of partition column &quot;dt&quot;:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">  failCondition = &quot;(size(selectedPartitionValues) &gt; 0 and array_min(transform(selectedPartitionValues, x -&amp;gt x.dt)) &amp;lt array_max(transform(outputPartitionValues, x &gt; x.dt)))&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Sometimes the failCondition can become quite complex with multiple terms concatenated by or-logic.
To improve interpretabily of error messages, multiple fail conditions can be configured as array with attribute <strong>failConditions</strong>. For every condition you can also define a description which will be inserted into the error message.</p><p>Finally By defining <strong>selectExpression</strong> you can customize which partitions are selected.
Define a spark sql expression working with attributes of PartitionDiffModeExpressionData returning a Seq(Map(String,String)).</p><p>Example - only process the last selected partition:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">  selectExpression = &quot;slice(selectedPartitionValues,-1,1)&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>By defining <strong>alternativeOutputId</strong> attribute you can define another DataObject which will be used to check for already existing data.
This can be used to select data to process against a DataObject later in the pipeline.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="sparkstreamingmode-incremental-load">SparkStreamingMode: Incremental load<a class="hash-link" href="#sparkstreamingmode-incremental-load" title="Direct link to heading">â€‹</a></h3><p>Some DataObjects are not partitioned, but nevertheless you dont want to read all data from the input on every run. You want to load it incrementally.
This can be accomplished by specifying execution mode SparkStreamingMode. Under the hood it uses &quot;Spark Structured Streaming&quot;.
In streaming mode this an Action with SparkStreamingMode is an asynchronous action. Its rhythm can be configured by setting triggerType and triggerTime.
If not in streaming mode SparkStreamingMode triggers a single microbatch by using triggerType=Once and is fully synchronized. Synchronous execution can be forced for streaming mode as well by explicitly setting triggerType=Once.
&quot;Spark Structured Streaming&quot; is keeping state information about processed data. It needs a checkpointLocation configured which can be given as parameter to SparkStreamingMode.</p><p>Note that &quot;Spark Structured Streaming&quot; needs an input DataObject supporting the creation of streaming DataFrames.
For the time being, only the input sources delivered with Spark Streaming are supported.
This are KafkaTopicDataObject and all SparkFileDataObjects, see also <a href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#creating-streaming-dataframes-and-streaming-datasets" target="_blank" rel="noopener noreferrer">Spark StructuredStreaming</a>.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="sparkincrementalmode-incremental-load">SparkIncrementalMode: Incremental Load<a class="hash-link" href="#sparkincrementalmode-incremental-load" title="Direct link to heading">â€‹</a></h3><p>As not every input DataObject supports the creation of streaming DataFrames, there is an other execution mode called SparkIncrementalMode.
You configure it by defining the attribute <strong>compareCol</strong> with a column name present in input and output DataObject.
SparkIncrementalMode then compares the maximum values between input and output and creates a filter condition.
On execution the filter condition is applied to the input DataObject to load the missing increment.
Note that compareCol needs to have a sortable datatype.</p><p>By defining <strong>applyCondition</strong> attribute you can give a condition to decide at runtime if the SparkIncrementalMode should be applied or not.
Default is to apply the SparkIncrementalMode. Define an applyCondition by a spark sql expression working with attributes of DefaultExecutionModeExpressionData returning a boolean.</p><p>By defining <strong>alternativeOutputId</strong> attribute you can define another DataObject which will be used to check for already existing data.
This can be used to select data to process against a DataObject later in the pipeline.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="failifnopartitionvaluesmode">FailIfNoPartitionValuesMode<a class="hash-link" href="#failifnopartitionvaluesmode" title="Direct link to heading">â€‹</a></h3><p>To simply check if partition values are present and fail otherwise, configure execution mode FailIfNoPartitionValuesMode.
This is useful to prevent potential reprocessing of whole table through wrong usage.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="processallmode">ProcessAllMode<a class="hash-link" href="#processallmode" title="Direct link to heading">â€‹</a></h3><p>An execution mode which forces processing all data from it&#x27;s inputs, removing partitionValues and filter conditions received from previous actions.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="custompartitionmode">CustomPartitionMode<a class="hash-link" href="#custompartitionmode" title="Direct link to heading">â€‹</a></h3><p>An execution mode to create custom partition execution mode logic in scala.
Implement trait CustomPartitionModeLogic by defining a function which receives main input&amp;output DataObject and returns partition values to process as Seq[Map<!-- -->[String,String]<!-- -->]</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="execution-condition">Execution Condition<a class="hash-link" href="#execution-condition" title="Direct link to heading">â€‹</a></h2><p>For every Action an executionCondition can be defined. The execution condition allows to define if an action is executed or skipped. The default behaviour is that an Action is skipped if at least one input SubFeed is skipped.
Define an executionCondition by a spark sql expression working with attributes of SubFeedsExpressionData returning a boolean.
The Action is skipped if the executionCondition is evaluated to false. In that case dependent actions get empty SubFeeds marked with isSkipped=true as input.</p><p>Example - skip Action only if input1 and input2 SubFeed are skipped:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">  executionCondition = &quot;!inputSubFeeds.input1.isSkipped or !inputSubFeeds.input2.isSkipped&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Example - Always execute Action and use all existing data as input:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">  executionCondition = true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  executionMode = ProcessAllMode</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/smart-data-lake/smart-data-lake/tree/documentation/docs/reference/executionModes.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_foO9"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></div></div><div class="col col--3"><div class="tableOfContents_cNA8 thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#execution-modes" class="table-of-contents__link toc-highlight">Execution modes</a><ul><li><a href="#fixed-partition-values-filter" class="table-of-contents__link toc-highlight">Fixed partition values filter</a></li><li><a href="#partitiondiffmode-dynamic-partition-values-filter" class="table-of-contents__link toc-highlight">PartitionDiffMode: Dynamic partition values filter</a></li><li><a href="#sparkstreamingmode-incremental-load" class="table-of-contents__link toc-highlight">SparkStreamingMode: Incremental load</a></li><li><a href="#sparkincrementalmode-incremental-load" class="table-of-contents__link toc-highlight">SparkIncrementalMode: Incremental Load</a></li><li><a href="#failifnopartitionvaluesmode" class="table-of-contents__link toc-highlight">FailIfNoPartitionValuesMode</a></li><li><a href="#processallmode" class="table-of-contents__link toc-highlight">ProcessAllMode</a></li><li><a href="#custompartitionmode" class="table-of-contents__link toc-highlight">CustomPartitionMode</a></li></ul></li><li><a href="#execution-condition" class="table-of-contents__link toc-highlight">Execution Condition</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/">Getting started</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/smart-data-lake/smart-data-lake" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://github.com/smart-data-lake/smart-data-lake/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub Issues<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a href="https://www.elca.ch" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>ELCA<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022 Smart Data Lake, Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.29f9f513.js"></script>
<script src="/assets/js/main.b58ebaed.js"></script>
</body>
</html>