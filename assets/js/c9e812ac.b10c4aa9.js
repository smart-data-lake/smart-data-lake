"use strict";(self.webpackChunksmart_data_lake=self.webpackChunksmart_data_lake||[]).push([[4329],{324:(t,a,e)=>{e.r(a),e.d(a,{assets:()=>l,contentTitle:()=>r,default:()=>k,frontMatter:()=>i,metadata:()=>s,toc:()=>p});var n=e(5893),o=e(1151);const i={title:"Combine Spark and Snowpark to ingest and transform data in one pipeline",description:"An example to create one unified data pipeline that uses Spark to ingest data into Snowflake, and Snowpark to transform data inside Snowflake.",slug:"sdl-snowpark",authors:[{name:"Zach Kull",title:"Data Expert",url:"https://www.linkedin.com/in/zacharias-kull-94705886/"}],tags:["Snowpark","Snowflake"],hide_table_of_contents:!1},r=void 0,s={permalink:"/blog/sdl-snowpark",editUrl:"https://github.com/smart-data-lake/smart-data-lake/tree/documentation/blog/2022-04-06-SDL-snowpark/2022-04-06-SDL-snowpark.md",source:"@site/blog/2022-04-06-SDL-snowpark/2022-04-06-SDL-snowpark.md",title:"Combine Spark and Snowpark to ingest and transform data in one pipeline",description:"An example to create one unified data pipeline that uses Spark to ingest data into Snowflake, and Snowpark to transform data inside Snowflake.",date:"2022-04-06T00:00:00.000Z",formattedDate:"April 6, 2022",tags:[{label:"Snowpark",permalink:"/blog/tags/snowpark"},{label:"Snowflake",permalink:"/blog/tags/snowflake"}],readingTime:7.285,hasTruncateMarker:!0,authors:[{name:"Zach Kull",title:"Data Expert",url:"https://www.linkedin.com/in/zacharias-kull-94705886/"}],frontMatter:{title:"Combine Spark and Snowpark to ingest and transform data in one pipeline",description:"An example to create one unified data pipeline that uses Spark to ingest data into Snowflake, and Snowpark to transform data inside Snowflake.",slug:"sdl-snowpark",authors:[{name:"Zach Kull",title:"Data Expert",url:"https://www.linkedin.com/in/zacharias-kull-94705886/"}],tags:["Snowpark","Snowflake"],hide_table_of_contents:!1},unlisted:!1,prevItem:{title:"Deployment on Databricks",permalink:"/blog/sdl-databricks"},nextItem:{title:"Using Airbyte connector to inspect github data",permalink:"/blog/sdl-airbyte"}},l={authorsImageUrls:[void 0]},p=[];function d(t){const a={p:"p",...(0,o.a)(),...t.components};return(0,n.jsx)(a.p,{children:"This article shows how to create one unified data pipeline that uses Spark to ingest data into Snowflake, and Snowpark to transform data inside Snowflake."})}function k(t={}){const{wrapper:a}={...(0,o.a)(),...t.components};return a?(0,n.jsx)(a,{...t,children:(0,n.jsx)(d,{...t})}):d(t)}},1151:(t,a,e)=>{e.d(a,{Z:()=>s,a:()=>r});var n=e(7294);const o={},i=n.createContext(o);function r(t){const a=n.useContext(i);return n.useMemo((function(){return"function"==typeof t?t(a):{...a,...t}}),[a,t])}function s(t){let a;return a=t.disableParentContext?"function"==typeof t.components?t.components(o):t.components||o:r(t.components),n.createElement(i.Provider,{value:a},t.children)}}}]);