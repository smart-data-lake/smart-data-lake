"use strict";(self.webpackChunksmart_data_lake=self.webpackChunksmart_data_lake||[]).push([[7029],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>h});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},d="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),d=p(a),u=r,h=d["".concat(l,".").concat(u)]||d[u]||m[u]||o;return a?n.createElement(h,i(i({ref:t},c),{},{components:a})):n.createElement(h,i({ref:t},c))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[d]="string"==typeof e?e:r,i[1]=s;for(var p=2;p<o;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},5162:(e,t,a)=>{a.d(t,{Z:()=>i});var n=a(7294),r=a(6010);const o={tabItem:"tabItem_Ymn6"};function i(e){let{children:t,hidden:a,className:i}=e;return n.createElement("div",{role:"tabpanel",className:(0,r.Z)(o.tabItem,i),hidden:a},t)}},5488:(e,t,a)=>{a.d(t,{Z:()=>m});var n=a(7462),r=a(7294),o=a(6010),i=a(2389),s=a(7392),l=a(7094),p=a(2466);const c={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function d(e){const{lazy:t,block:a,defaultValue:i,values:d,groupId:m,className:u}=e,h=r.Children.map(e.children,(e=>{if((0,r.isValidElement)(e)&&"value"in e.props)return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})),f=d??h.map((e=>{let{props:{value:t,label:a,attributes:n}}=e;return{value:t,label:a,attributes:n}})),g=(0,s.l)(f,((e,t)=>e.value===t.value));if(g.length>0)throw new Error(`Docusaurus error: Duplicate values "${g.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`);const k=null===i?i:i??h.find((e=>e.props.default))?.props.value??h[0].props.value;if(null!==k&&!f.some((e=>e.value===k)))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${k}" but none of its children has the corresponding value. Available values are: ${f.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);const{tabGroupChoices:b,setTabGroupChoices:v}=(0,l.U)(),[w,y]=(0,r.useState)(k),N=[],{blockElementScrollPositionUntilNextRender:D}=(0,p.o5)();if(null!=m){const e=b[m];null!=e&&e!==w&&f.some((t=>t.value===e))&&y(e)}const C=e=>{const t=e.currentTarget,a=N.indexOf(t),n=f[a].value;n!==w&&(D(t),y(n),null!=m&&v(m,String(n)))},O=e=>{let t=null;switch(e.key){case"ArrowRight":{const a=N.indexOf(e.currentTarget)+1;t=N[a]??N[0];break}case"ArrowLeft":{const a=N.indexOf(e.currentTarget)-1;t=N[a]??N[N.length-1];break}}t?.focus()};return r.createElement("div",{className:(0,o.Z)("tabs-container",c.tabList)},r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":a},u)},f.map((e=>{let{value:t,label:a,attributes:i}=e;return r.createElement("li",(0,n.Z)({role:"tab",tabIndex:w===t?0:-1,"aria-selected":w===t,key:t,ref:e=>N.push(e),onKeyDown:O,onFocus:C,onClick:C},i,{className:(0,o.Z)("tabs__item",c.tabItem,i?.className,{"tabs__item--active":w===t})}),a??t)}))),t?(0,r.cloneElement)(h.filter((e=>e.props.value===w))[0],{className:"margin-top--md"}):r.createElement("div",{className:"margin-top--md"},h.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==w})))))}function m(e){const t=(0,i.Z)();return r.createElement(d,(0,n.Z)({key:String(t)},e))}},1623:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>p,toc:()=>d});var n=a(7462),r=(a(7294),a(3905)),o=a(5488),i=a(5162);const s={id:"custom-webservice",title:"Custom Webservice"},l=void 0,p={unversionedId:"getting-started/part-3/custom-webservice",id:"getting-started/part-3/custom-webservice",title:"Custom Webservice",description:"Goal",source:"@site/docs/getting-started/part-3/custom-webservice.md",sourceDirName:"getting-started/part-3",slug:"/getting-started/part-3/custom-webservice",permalink:"/docs/getting-started/part-3/custom-webservice",draft:!1,editUrl:"https://github.com/smart-data-lake/smart-data-lake/tree/documentation/docs/getting-started/part-3/custom-webservice.md",tags:[],version:"current",frontMatter:{id:"custom-webservice",title:"Custom Webservice"},sidebar:"docs",previous:{title:"Keeping historical data",permalink:"/docs/getting-started/part-2/historical-data"},next:{title:"Incremental Mode",permalink:"/docs/getting-started/part-3/incremental-mode"}},c={},d=[{value:"Goal",id:"goal",level:2},{value:"Starting point",id:"starting-point",level:2},{value:"Define Data Objects",id:"define-data-objects",level:2},{value:"Define Action",id:"define-action",level:2},{value:"Try it out",id:"try-it-out",level:2},{value:"Get Data Frame",id:"get-data-frame",level:2},{value:"Preserve schema",id:"preserve-schema",level:2}],m={toc:d},u="wrapper";function h(e){let{components:t,...s}=e;return(0,r.kt)(u,(0,n.Z)({},m,s,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"goal"},"Goal"),(0,r.kt)("p",null,"  In the previous examples we worked mainly with data that was available as a file or could be fetched with the built-in ",(0,r.kt)("inlineCode",{parentName:"p"},"WebserviceFileDataObject"),".\nTo fetch data from a webservice, the ",(0,r.kt)("inlineCode",{parentName:"p"},"WebserviceFileDataObject")," is sometimes not enough and has to be customized.\nThe reasons why the built-in DataObject is not sufficient are manifold, but it's connected to the way Webservices are designed.\nWebservices often include design features like: "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"data pagination"),(0,r.kt)("li",{parentName:"ul"},"protect resources using rate limiting "),(0,r.kt)("li",{parentName:"ul"},"different authentication mechanisms"),(0,r.kt)("li",{parentName:"ul"},"filters for incremental load"),(0,r.kt)("li",{parentName:"ul"},"well defined schema"),(0,r.kt)("li",{parentName:"ul"},"...")),(0,r.kt)("p",null,"Smart Data Lake Builder can not cover all these various needs in a generic ",(0,r.kt)("inlineCode",{parentName:"p"},"WebserviceDataObject"),", which is why we have to write our own ",(0,r.kt)("inlineCode",{parentName:"p"},"CustomWebserviceDataObject"),".\nThe goal of this part is to learn how such a CustomWebserviceDataObject can be implemented in Scala."),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"Other than part 1 and 2, we are writing customized Scala classes in part 3 and making use of Apache Spark features.\nAs such, we expect you to have some Scala and Spark know-how to follow along."),(0,r.kt)("p",{parentName:"admonition"},"It is also a good idea to configure a working development environment at this point.\nIn the ",(0,r.kt)("a",{parentName:"p",href:"/docs/getting-started/setup"},"Technical Setup")," chapter we briefly introduced how to use IntelliJ for development.\nThat should greatly improve your development experience compared to manipulating the file in a simple text editor.")),(0,r.kt)("h2",{id:"starting-point"},"Starting point"),(0,r.kt)("p",null,"Again we start with the ",(0,r.kt)("inlineCode",{parentName:"p"},"application.conf")," that resulted from finishing the last part.\nIf you don't have the application.conf from part 2 anymore, please copy ",(0,r.kt)("a",{target:"_blank",href:a(9140).Z},"this")," configuration file to ",(0,r.kt)("strong",{parentName:"p"},"config/application.conf")," again."),(0,r.kt)("h2",{id:"define-data-objects"},"Define Data Objects"),(0,r.kt)("p",null,"We start by rewriting the existing ",(0,r.kt)("inlineCode",{parentName:"p"},"ext-departures")," DataObject.\nIn the configuration file, replace the old configuration with its new definition:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'ext-departures {\n  type = CustomWebserviceDataObject\n  schema = """array< struct< icao24: string, firstSeen: integer, estDepartureAirport: string, lastSeen: integer, estArrivalAirport: string, callsign: string, estDepartureAirportHorizDistance: integer, estDepartureAirportVertDistance: integer, estArrivalAirportHorizDistance: integer, estArrivalAirportVertDistance: integer, departureAirportCandidatesCount: integer, arrivalAirportCandidatesCount: integer >>"""\n  baseUrl = "https://opensky-network.org/api/flights/departure"\n  nRetry = 5\n  queryParameters = [{\n    airport = "LSZB"\n    begin = 1641393602\n    end = 1641483739\n  },{\n    airport = "EDDF"\n    begin = 1641393602\n    end = 1641483739\n  }]\n  timeouts {\n    connectionTimeoutMs = 200000\n    readTimeoutMs = 200000\n  }\n}\n')),(0,r.kt)("p",null,"The Configuration for this new ",(0,r.kt)("inlineCode",{parentName:"p"},"ext-departures")," includes the type of the DataObject, the expected schema, the base url from where we can fetch the departures from, the number of retries, a list of query parameters and timeout options.\nTo have more flexibility, we can now configure the query parameters as options instead defining them in the query string.",(0,r.kt)("br",{parentName:"p"}),"\n","The connection timeout corresponds to the time we wait until the connection is established and the read timeout equals the time we wait until the webservice responds after the request has been submitted.\nIf the request cannot be answered in the times configured, we try to automatically resend the request.\nHow many times a failed request will be resend, is controlled by the ",(0,r.kt)("inlineCode",{parentName:"p"},"nRetry")," parameter."),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("em",{parentName:"p"},"begin")," and ",(0,r.kt)("em",{parentName:"p"},"end")," can now be configured for each airport separatly.\nThe configuration expects unix timestamps, if you don't know what that means, have a look at this ",(0,r.kt)("a",{parentName:"p",href:"https://www.unixtimestamp.com/"},"website"),".\nThe webservice from opensky-network.org will not respond if the interval is larger than a week.\nHence, our ",(0,r.kt)("inlineCode",{parentName:"p"},"CustomWebserviceDataObject")," will enforce the rule that if the chosen interval is larger, we query only the next four days given the ",(0,r.kt)("em",{parentName:"p"},"begin")," configuration.")),(0,r.kt)("p",null,"Note that we changed the type to ",(0,r.kt)("inlineCode",{parentName:"p"},"CustomWebserviceDataObject"),".\nThis is a custom DataObject type, not included in standard Smart Data Lake Builder.\nTo make it work, please go to the project's root directory and copy the Scala class with\n",(0,r.kt)("inlineCode",{parentName:"p"},"cp part3/src/ ./ -r"),":"),(0,r.kt)("p",null,"This copied the following file:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"./src/scala/io/smartdatalake/workflow/dataobject/CustomWebserviceDataObject.scala")),(0,r.kt)("p",null,"In this part we will work exclusively on the ",(0,r.kt)("inlineCode",{parentName:"p"},"CustomWebserviceDataObject.scala")," file."),(0,r.kt)("h2",{id:"define-action"},"Define Action"),(0,r.kt)("p",null,"In the configuration we only change one action again:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"download-departures {\n  type = CopyAction\n  inputId = ext-departures\n  outputId = stg-departures\n  metadata {\n    feed = download\n  }\n}\n")),(0,r.kt)("p",null,"The type is no longer ",(0,r.kt)("inlineCode",{parentName:"p"},"FileTransferAction")," but a ",(0,r.kt)("inlineCode",{parentName:"p"},"CopyAction")," instead, as our new ",(0,r.kt)("inlineCode",{parentName:"p"},"CustomWebserviceDataObject")," converts the Json-Output of the Webservice into a Spark DataFrame."),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},(0,r.kt)("inlineCode",{parentName:"p"},"FileTransferAction"),"s are used, when your DataObject reads an InputStream or writes an OutputStream like ",(0,r.kt)("inlineCode",{parentName:"p"},"WebserviceFileDataObject")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"SFtpFileRefDataObject"),".\nThese transfer files one-to-one from input to output.",(0,r.kt)("br",{parentName:"p"}),"\n","More often you work with one of the many provided ",(0,r.kt)("inlineCode",{parentName:"p"},"SparkAction"),"s like the ",(0,r.kt)("inlineCode",{parentName:"p"},"CopyAction")," shown here.\nThey work by using Spark Data Frames under the hood. ")),(0,r.kt)("h2",{id:"try-it-out"},"Try it out"),(0,r.kt)("p",null,"Compile and execute the code of this project with the following commands.\nNote that parameter ",(0,r.kt)("inlineCode",{parentName:"p"},"--feed-sel")," only selects ",(0,r.kt)("inlineCode",{parentName:"p"},"download-departures")," as Action for execution. "),(0,r.kt)(o.Z,{groupId:"docker-podman-switch",defaultValue:"docker",values:[{label:"Docker",value:"docker"},{label:"Podman",value:"podman"}],mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"docker",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-jsx"},'mkdir .mvnrepo\ndocker run -v ${PWD}:/mnt/project -v ${PWD}/.mvnrepo:/mnt/.mvnrepo maven:3.6.0-jdk-11-slim -- mvn -f /mnt/project/pom.xml "-Dmaven.repo.local=/mnt/.mvnrepo" package\ndocker run --rm -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark:latest --config /mnt/config --feed-sel ids:download-departures\n'))),(0,r.kt)(i.Z,{value:"podman",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-jsx"},'mkdir .mvnrepo\npodman run -v ${PWD}:/mnt/project -v ${PWD}/.mvnrepo:/mnt/.mvnrepo maven:3.6.0-jdk-11-slim -- mvn -f /mnt/project/pom.xml "-Dmaven.repo.local=/mnt/.mvnrepo" package\npodman run --rm --hostname=localhost --pod getting-started -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark:latest --config /mnt/config --feed-sel ids:download-departures\n')))),(0,r.kt)("p",null,"Nothing should have changed. You should again receive data as json files in the corresponding ",(0,r.kt)("inlineCode",{parentName:"p"},"stg-departures")," folder.\nBut except of receiving the departures for only one airport, the DataObject returns the departures for all configured airports.\nIn this specific case this would be ",(0,r.kt)("em",{parentName:"p"},"LSZB")," and ",(0,r.kt)("em",{parentName:"p"},"EDDF")," within the corresponding time window."),(0,r.kt)("p",null,"Having a look at the log, something similar should appear on your screen. "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Bash"},"2021-11-10 14:00:32 INFO  ActionDAGRun$ActionEventListener:228 - Action~download-departures[CopyAction]: Prepare started\n2021-11-10 14:00:32 INFO  ActionDAGRun$ActionEventListener:237 - Action~download-departures[CopyAction]: Prepare succeeded\n2021-11-10 14:00:32 INFO  ActionDAGRun$ActionEventListener:228 - Action~download-departures[CopyAction]: Init started\n2021-11-10 14:00:33 INFO  CustomWebserviceDataObject:69 - Success for request https://opensky-network.org/api/flights/departure?airport=LSZB&begin=1630200800&end=1630310979\n2021-11-10 14:00:33 INFO  CustomWebserviceDataObject:69 - Success for request https://opensky-network.org/api/flights/departure?airport=EDDF&begin=1630200800&end=1630310979\n2021-11-10 14:00:35 INFO  ActionDAGRun$ActionEventListener:237 - Action~download-departures[CopyAction]: Init succeeded\n2021-11-10 14:00:35 INFO  ActionDAGRun$ActionEventListener:228 - Action~download-departures[CopyAction]: Exec started\n2021-11-10 14:00:35 INFO  CopyAction:158 - (Action~download-departures) getting DataFrame for DataObject~ext-departures\n2021-11-10 14:00:36 INFO  CustomWebserviceDataObject:69 - Success for request https://opensky-network.org/api/flights/departure?airport=LSZB&begin=1630200800&end=1630310979\n2021-11-10 14:00:37 INFO  CustomWebserviceDataObject:69 - Success for request https://opensky-network.org/api/flights/departure?airport=EDDF&begin=1630200800&end=1630310979\n")),(0,r.kt)("p",null,"It is important to notice that the two requests for each airport to the API were not send only once, but twice.\nThis stems from the fact that the method ",(0,r.kt)("inlineCode",{parentName:"p"},"getSparkDataFrame")," of the Data Object is called twice in the DAG execution of the Smart Data Lake Builder:\nOnce during the Init Phase and once again during the Exec Phase. See ",(0,r.kt)("a",{parentName:"p",href:"/docs/reference/executionPhases"},"this page")," for more information on that.\nBefore we address and mitigate this behaviour in the next section, let's have a look at the ",(0,r.kt)("inlineCode",{parentName:"p"},"getSparkDataFrame")," method and the currently implemented logic:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Scala"},'// use the queryParameters from the config\nval currentQueryParameters = checkQueryParameters(queryParameters)\n\n// given the query parameters, generate all requests\nval departureRequests = currentQueryParameters.map(\n  param => s"${baseUrl}?airport=${param.airport}&begin=${param.begin}&end=${param.end}"\n)\n// make requests\nval departuresResponses = departureRequests.map(request(_))\n// create dataframe with the correct schema and add created_at column with the current timestamp\nval departuresDf = departuresResponses.toDF("responseBinary")\n  .withColumn("responseString", byte2String($"responseBinary"))\n  .select(from_json($"responseString", DataType.fromDDL(schema)).as("response"))\n  .select(explode($"response").as("record"))\n  .select("record.*")\n  .withColumn("created_at", current_timestamp())\n// return\ndeparturesDf\n')),(0,r.kt)("p",null,"Given the configured query parameters, the requests are first prepared using the request method.\nIf you have a look at the implementation of the ",(0,r.kt)("inlineCode",{parentName:"p"},"request")," method, you notice that we provide some ScalaJCustomWebserviceClient that is based on the ",(0,r.kt)("em",{parentName:"p"},"ScalaJ")," library.\nAlso in the ",(0,r.kt)("inlineCode",{parentName:"p"},"request")," method you can find the configuration for the number of retries.\nAfterwards, we create a data frame out of the response.\nWe implemented some transformations to flatten the result returned by the API.",(0,r.kt)("br",{parentName:"p"}),"\n","Spark has lots of ",(0,r.kt)("em",{parentName:"p"},"Functions")," that can be used out of the box.\nWe used such a column based function ",(0,r.kt)("em",{parentName:"p"},"from_json")," to parse the response string with the right schema.\nAt the end we return the freshly created data frame ",(0,r.kt)("inlineCode",{parentName:"p"},"departuresDf"),"."),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"The return type of the response is ",(0,r.kt)("inlineCode",{parentName:"p"},"Array[Byte]"),". To convert that to ",(0,r.kt)("inlineCode",{parentName:"p"},"Array[String]")," a ",(0,r.kt)("em",{parentName:"p"},"User Defined Function")," (also called ",(0,r.kt)("em",{parentName:"p"},"UDF"),") ",(0,r.kt)("inlineCode",{parentName:"p"},"byte2String")," has been used, which is declared inside the getSparkDataFrame method.\nThis function is a nice example of how to write your own ",(0,r.kt)("em",{parentName:"p"},"UDF"),".")),(0,r.kt)("h2",{id:"get-data-frame"},"Get Data Frame"),(0,r.kt)("p",null,"In this section we will learn how we can avoid sending the request twice to the API using the execution phase information provided by the Smart Data Lake Builder.\nWe will now implement a simple ",(0,r.kt)("em",{parentName:"p"},"if ... else")," statement that allows us to return an empty data frame with the correct schema in the ",(0,r.kt)("strong",{parentName:"p"},"Init")," phase and to only query the data in the ",(0,r.kt)("strong",{parentName:"p"},"Exec")," phase.\nThis logic is implemented in the next code snipped and should replace the code currently enclosed between the two ",(0,r.kt)("inlineCode",{parentName:"p"},"// REPLACE BLOCK")," comments."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Scala"},'    if(context.phase == ExecutionPhase.Init){\n  // simply return an empty data frame\n  Seq[String]().toDF("responseString")\n          .select(from_json($"responseString", DataType.fromDDL(schema)).as("response"))\n          .select(explode($"response").as("record"))\n          .select("record.*")\n          .withColumn("created_at", current_timestamp())\n} else {\n  // use the queryParameters from the config\n  val currentQueryParameters = checkQueryParameters(queryParameters)\n\n  // given the query parameters, generate all requests\n  val departureRequests = currentQueryParameters.map(\n    param => s"${baseUrl}?airport=${param.airport}&begin=${param.begin}&end=${param.end}"\n  )\n  // make requests\n  val departuresResponses = departureRequests.map(request(_))\n  // create dataframe with the correct schema and add created_at column with the current timestamp\n  val departuresDf = departuresResponses.toDF("responseBinary")\n          .withColumn("responseString", byte2String($"responseBinary"))\n          .select(from_json($"responseString", DataType.fromDDL(schema)).as("response"))\n          .select(explode($"response").as("record"))\n          .select("record.*")\n          .withColumn("created_at", current_timestamp())\n\n  // put simple nextState logic below\n\n  // return\n  departuresDf\n}\n\n')),(0,r.kt)("p",null,"Note, in the ",(0,r.kt)("em",{parentName:"p"},"Init")," phase, the pre-defined ",(0,r.kt)("strong",{parentName:"p"},"schema")," (see the ",(0,r.kt)("inlineCode",{parentName:"p"},"ext-departures")," DataObject definition in the config) is used to create an empty/dummy json string, which then gets converted to the DataFrame."),(0,r.kt)("p",null,"Don't be confused about some comments in the code. They will be used in the next chapter.\nIf you re-compile the code of this project and then restart the program with the previous commands\nyou should see that we do not query the API twice anymore."),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"  Use the information of the ",(0,r.kt)("inlineCode",{parentName:"p"},"ExecutionPhase")," in your custom implementations whenever you need to have different logic during the different phases.")),(0,r.kt)("h2",{id:"preserve-schema"},"Preserve schema"),(0,r.kt)("p",null,"With this implementation, we still write the Spark data frame of our ",(0,r.kt)("inlineCode",{parentName:"p"},"CustomWebserviceDataObject")," in Json format.\nAs a consequence, we lose the schema definition when the data is read again.",(0,r.kt)("br",{parentName:"p"}),"\n","To improve this behaviour, let's directly use the ",(0,r.kt)("inlineCode",{parentName:"p"},"ext-departures")," as ",(0,r.kt)("em",{parentName:"p"},"inputId")," in the ",(0,r.kt)("inlineCode",{parentName:"p"},"deduplicate-departures")," action, and rename the Action as ",(0,r.kt)("inlineCode",{parentName:"p"},"download-deduplicate-departures"),".\nThe deduplicate action expects a DataFrame as input. Since our ",(0,r.kt)("inlineCode",{parentName:"p"},"CustomWebserviceDataObject")," delivers that, there is no need for an intermediate step anymore.",(0,r.kt)("br",{parentName:"p"}),"\n","After you've changed that, the first transformer has to be rewritten as well, since the input has changed.\nPlease replace it with the implementation below"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"{\n  type = SQLDfTransformer\n  code = \"select ext_departures.*, date_format(from_unixtime(firstseen),'yyyyMMdd') dt from ext_departures\"\n}\n")),(0,r.kt)("p",null,"The old Action ",(0,r.kt)("inlineCode",{parentName:"p"},"download-departures")," and the DataObject ",(0,r.kt)("inlineCode",{parentName:"p"},"stg-departures")," can be deleted, as it's not needed anymore."),(0,r.kt)("p",null,"At the end, your config file should look something like ",(0,r.kt)("a",{target:"_blank",href:a(9129).Z},"this")," and the CustomWebserviceDataObject code like ",(0,r.kt)("a",{target:"_blank",href:a(6933).Z},"this"),".\nNote that since we changed the file format to delta lake, your new ",(0,r.kt)("inlineCode",{parentName:"p"},"download-deduplicate-departures")," feed now needs the metastore that you setup in part 2.\nTherefore, you need to make sure that polynote and the metastore are running as shown in ",(0,r.kt)("a",{parentName:"p",href:"../part-2/delta-lake-format"},"the first step of part 2"),".\nThen, you need to delete the files in the data folder and then run the following command in another terminal: "),(0,r.kt)(o.Z,{groupId:"docker-podman-switch",defaultValue:"docker",values:[{label:"Docker",value:"docker"},{label:"Podman",value:"podman"}],mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"docker",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-jsx"},"mkdir -f data\ndocker run --rm -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config --network getting-started_default sdl-spark:latest --config /mnt/config --feed-sel ids:download-deduplicate-departures\n"))),(0,r.kt)(i.Z,{value:"podman",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-jsx"},"mkdir -f data\npodman run --rm --hostname=localhost -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config --pod getting-started sdl-spark:latest --config /mnt/config --feed-sel ids:download-deduplicate-departures\n")))))}h.isMDXComponent=!0},6933:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/files/CustomWebserviceDataObject-1-b9264f59c390d53941ed1f8d9e0cf2fc.scala"},9140:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/files/application-part2-historical-62b47cb172772c79ba8f08c7082ca360.conf"},9129:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/files/application-part3-download-custom-webservice-8128471803017a347edd923edbae995f.conf"}}]);