"use strict";(self.webpackChunksmart_data_lake=self.webpackChunksmart_data_lake||[]).push([[9233],{9497:(t,a,e)=>{e.r(a),e.d(a,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>o,metadata:()=>i,toc:()=>c});var n=e(5893),r=e(1151);const o={title:"Deployment on Databricks",description:"A brief example of deploying SDL on Databricks",slug:"sdl-databricks",authors:[{name:"Mandes Sch\xf6nherr",title:"Dr.sc.nat.",url:"https://github.com/mand35"}],tags:["Databricks","Cloud"],hide_table_of_contents:!1},s=void 0,i={permalink:"/blog/sdl-databricks",editUrl:"https://github.com/smart-data-lake/smart-data-lake/tree/documentation/blog/2022-04-07-SDL_databricks/2022-04-07-Databricks.md",source:"@site/blog/2022-04-07-SDL_databricks/2022-04-07-Databricks.md",title:"Deployment on Databricks",description:"A brief example of deploying SDL on Databricks",date:"2022-04-07T00:00:00.000Z",formattedDate:"April 7, 2022",tags:[{label:"Databricks",permalink:"/blog/tags/databricks"},{label:"Cloud",permalink:"/blog/tags/cloud"}],readingTime:5.9,hasTruncateMarker:!0,authors:[{name:"Mandes Sch\xf6nherr",title:"Dr.sc.nat.",url:"https://github.com/mand35"}],frontMatter:{title:"Deployment on Databricks",description:"A brief example of deploying SDL on Databricks",slug:"sdl-databricks",authors:[{name:"Mandes Sch\xf6nherr",title:"Dr.sc.nat.",url:"https://github.com/mand35"}],tags:["Databricks","Cloud"],hide_table_of_contents:!1},unlisted:!1,prevItem:{title:"Incremental historization using CDC and Airbyte MSSQL connector",permalink:"/blog/sdl-hist"},nextItem:{title:"Combine Spark and Snowpark to ingest and transform data in one pipeline",permalink:"/blog/sdl-snowpark"}},l={authorsImageUrls:[void 0]},c=[];function d(t){const a={a:"a",p:"p",...(0,r.a)(),...t.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(a.p,{children:["Many analytics applications are ported to the cloud, Data Lakes and Lakehouses in the cloud becoming more and more popular.\nThe ",(0,n.jsx)(a.a,{href:"https://databricks.com",children:"Databricks"})," platform provides an easy accessible and easy configurable way to implement a modern analytics platform.\nSmart Data Lake Builder on the other hand provides an open source, portable automation tool to load and transform the data."]}),"\n",(0,n.jsxs)(a.p,{children:["In this article the deployment of Smart Data Lake Builder (SDLB) on ",(0,n.jsx)(a.a,{href:"https://databricks.com",children:"Databricks"})," is described."]})]})}function m(t={}){const{wrapper:a}={...(0,r.a)(),...t.components};return a?(0,n.jsx)(a,{...t,children:(0,n.jsx)(d,{...t})}):d(t)}},1151:(t,a,e)=>{e.d(a,{Z:()=>i,a:()=>s});var n=e(7294);const r={},o=n.createContext(r);function s(t){const a=n.useContext(o);return n.useMemo((function(){return"function"==typeof t?t(a):{...a,...t}}),[a,t])}function i(t){let a;return a=t.disableParentContext?"function"==typeof t.components?t.components(r):t.components||r:s(t.components),n.createElement(o.Provider,{value:a},t.children)}}}]);