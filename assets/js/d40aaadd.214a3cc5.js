"use strict";(self.webpackChunksmart_data_lake=self.webpackChunksmart_data_lake||[]).push([[3794],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>m});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},d=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},h=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),p=c(a),h=r,m=p["".concat(l,".").concat(h)]||p[h]||u[h]||o;return a?n.createElement(m,i(i({ref:t},d),{},{components:a})):n.createElement(m,i({ref:t},d))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=h;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[p]="string"==typeof e?e:r,i[1]=s;for(var c=2;c<o;c++)i[c]=a[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}h.displayName="MDXCreateElement"},7839:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var n=a(7462),r=(a(7294),a(3905));const o={title:"Data Mesh with SDL",description:"Build a Data Mesh with SDL",slug:"sdl-data-mesh",authors:[{name:"Patrick Gr\xfctter",url:"https://github.com/pgruetter"}],tags:["data mesh"],hide_table_of_contents:!1},i="Data Mesh with SDL",s={permalink:"/blog/sdl-data-mesh",editUrl:"https://github.com/smart-data-lake/smart-data-lake/tree/documentation/blog/2023-09-17-data-mesh/2023-09-17-data-mesh.md",source:"@site/blog/2023-09-17-data-mesh/2023-09-17-data-mesh.md",title:"Data Mesh with SDL",description:"Build a Data Mesh with SDL",date:"2023-09-17T00:00:00.000Z",formattedDate:"September 17, 2023",tags:[{label:"data mesh",permalink:"/blog/tags/data-mesh"}],readingTime:5.555,hasTruncateMarker:!1,authors:[{name:"Patrick Gr\xfctter",url:"https://github.com/pgruetter"}],frontMatter:{title:"Data Mesh with SDL",description:"Build a Data Mesh with SDL",slug:"sdl-data-mesh",authors:[{name:"Patrick Gr\xfctter",url:"https://github.com/pgruetter"}],tags:["data mesh"],hide_table_of_contents:!1},nextItem:{title:"Housekeeping",permalink:"/blog/sdl-housekeeping"}},l={authorsImageUrls:[void 0]},c=[{value:"Domain Ownership",id:"domain-ownership",level:2},{value:"Scale Out Complexity",id:"scale-out-complexity",level:3},{value:"Continuous change",id:"continuous-change",level:3},{value:"Data as a Product",id:"data-as-a-product",level:2},{value:"Data Quality",id:"data-quality",level:3},{value:"Schema enforcement",id:"schema-enforcement",level:3},{value:"Lineage",id:"lineage",level:3},{value:"Interfaces",id:"interfaces",level:3},{value:"Self-Serve infrastructure platform",id:"self-serve-infrastructure-platform",level:2},{value:"Mobilize more developers",id:"mobilize-more-developers",level:3},{value:"Support your domain teams",id:"support-your-domain-teams",level:3},{value:"Federated governance",id:"federated-governance",level:2},{value:"Data Catalogs",id:"data-catalogs",level:3},{value:"Encryption",id:"encryption",level:3}],d={toc:c},p="wrapper";function u(e){let{components:t,...a}=e;return(0,r.kt)(p,(0,n.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Data Mesh is an emerging concept gaining momentum across organizations.\nIt is often described as a ",(0,r.kt)("em",{parentName:"p"},"sociotechnical")," paradigm because a paradigm shift towards Data Mesh does not simply involve\ntechnological changes but also has sociological implications.\nAs such, discussing a technical framework like Smart Data Lake Builder and analyzing how well it fits the\nData Mesh paradigm can inherently only be part of the whole picture.\nNevertheless, we want to do the exercise here to see how a technological framework can support the adoption."),(0,r.kt)("p",null,"In this article, we'll explore how the Smart Data Lake Builder aligns with the four principles as outlined by\n",(0,r.kt)("a",{parentName:"p",href:"https://martinfowler.com/articles/data-mesh-principles.html"},"Zhamak Dehghani"),"\nand assess which key concepts it supports. "),(0,r.kt)("p",null,"Please note that we expect some familiarity with the Data Mesh principles to follow along.\nThere are plenty of resources (books from ",(0,r.kt)("a",{parentName:"p",href:"https://www.oreilly.com/library/view/data-mesh/9781492092384/"},"O'Reilly"),"\nand ",(0,r.kt)("a",{parentName:"p",href:"https://www.manning.com/books/data-mesh-in-action"},"Manning"),",\n",(0,r.kt)("a",{parentName:"p",href:"https://martinfowler.com/articles/data-mesh-principles.html"},"articles"),"\nand ",(0,r.kt)("a",{parentName:"p",href:"https://www.datamesh-architecture.com/"},"dedicated websites"),") if you want to dive deeper into the topic."),(0,r.kt)("h2",{id:"domain-ownership"},"Domain Ownership"),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Individual domains or business units are responsible for the data they generate and maintain,\nfostering a sense of ownership and accountability.")),(0,r.kt)("h3",{id:"scale-out-complexity"},"Scale Out Complexity"),(0,r.kt)("p",null,"With a Data Mesh, your data organization can scale out as the centralized data team gets reduced.\nWith increased usage, you will have more data sources, more consumers, more interfaces and with that,\na large variety of systems and technologies. "),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"SDLB")," comes with a large set of connectors out-of-the-box with the addition of\n",(0,r.kt)("a",{parentName:"p",href:"https://airbyte.com/connectors?connector-type=Sources"},"Airbyte")," source connectors.\nAnything missing can be easily implemented as the whole ecosystem is open and builds on open standards."),(0,r.kt)("h3",{id:"continuous-change"},"Continuous change"),(0,r.kt)("p",null,"Data Mesh embraces continuous change in your Data Products.\nChanging source systems or additional requirements all require you to adapt (quickly)."),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"SDLB")," is built for changes.\nWith built-in schema evolution, changing schemas can be handled automatically.\nThanks to the declarative approach, adding additional data objects can be done in minutes\nand the dependencies don't need to be defined by hand."),(0,r.kt)("h2",{id:"data-as-a-product"},"Data as a Product"),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Data is treated as a product, with clear documentation, standardized interfaces,\nand well-defined quality measures to ensure its usability and value.")),(0,r.kt)("p",null,"It's important to note that in the end, data products can be implemented in different technologies\nas long as they adhere to the agreed upon interfaces."),(0,r.kt)("p",null,"Again, there are different aspects where ",(0,r.kt)("em",{parentName:"p"},"SDLB")," can help."),(0,r.kt)("h3",{id:"data-quality"},"Data Quality"),(0,r.kt)("p",null,"A Data Product has well-defined quality measures and should define Service-Level Objectives (SLOs)."),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"SDLB")," builds data quality into your pipelines.\nIt supports ",(0,r.kt)("a",{parentName:"p",href:"../../docs/reference/dataQuality#constraints"},"constraints")," and\n",(0,r.kt)("a",{parentName:"p",href:"../../docs/reference/dataQuality#expectations"},"expectations"),"\nthat are evaluated each time a pipeline is executed instead of having downstream checks after the execution."),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"SDLB")," also gathers metrics with every run.\nWith the metrics gathered, you can detect anomalies like number of records or bytes written.\nThese are often helpful in finding latent problems in your data pipeline."),(0,r.kt)("h3",{id:"schema-enforcement"},"Schema enforcement"),(0,r.kt)("p",null,"As another aspect of quality, you expect your source system to adhere to the agreed interface."),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"SDLB")," supports schema validation for all its data objects.\nIn your configuration, you can (optionally) define a schema and enforce it.\nThis saves you from surprises if an upstream system suddenly changes the schema of a data object you use."),(0,r.kt)("h3",{id:"lineage"},"Lineage"),(0,r.kt)("p",null,"To provide transparency about the origin and transformations of data in your Data Product,\na lineage diagram can greatly help."),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"SDLB")," is a metadata driven framework.\nYou define Data Objects, you define Actions between them. That's it.\nSDLB will figure out the dependencies at runtime but they can also be easily displayed from static configurations.\nThis is done i.e. in our ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/smart-data-lake/sdl-visualization"},"sdl-visualization"),", see also the ",(0,r.kt)("a",{parentName:"p",href:"https://ui-demo.smartdatalake.ch/"},"UI-Demo"),".\nSDL configuration files can be easily displayed and analyzed.\nThis provides the needed transparency of a Data Product. "),(0,r.kt)("h3",{id:"interfaces"},"Interfaces"),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"SDLB")," offers many standard Data Objects for all kinds of interfaces.\nWith the declarative approach and schema enforcement, you can make sure that your data always adheres to the\ndefined interface specification."),(0,r.kt)("p",null,"Often in Cloud Environments, we work with Delta or Iceberg Tables today.\nThese open standards are a powerful tool to share your Data Product, even in multicloud deployments."),(0,r.kt)("h2",{id:"self-serve-infrastructure-platform"},"Self-Serve infrastructure platform"),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Data infrastructure is designed to be self-serve, enabling teams to access and manage their data autonomously without\nrelying on central data teams.")),(0,r.kt)("h3",{id:"mobilize-more-developers"},"Mobilize more developers"),(0,r.kt)("p",null,"With increased usage of the Mesh, you need more developers in your domain teams building Data Products."),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"SDLB")," has an easy to learn, declarative approach that new users can learn quickly.\nIt supports SQL, Scala and Python for the definition of transformations so your developers can still\nuse the language they are most comfortable in.\nComplex logic and transformations like historization and deduplication are either built-in or can be extended\nin a generic way so your developers can leverage them easily."),(0,r.kt)("h3",{id:"support-your-domain-teams"},"Support your domain teams"),(0,r.kt)("p",null,"The self-serve infrastructure should support your domain team to quickly build new Data Products."),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"SDLB")," is ideal to integrate into DevOps pipelines as all configurations are written in textfile based HOCON format.\nEven if you have custom code, it will be written in SQL, Scala or Python which also integrates well\nin any existing DevOps environments.\nIt is designed to support code reviews, automated testing and deployment.\nWith the right templates, your domain teams can set up new Data Products quickly."),(0,r.kt)("h2",{id:"federated-governance"},"Federated governance"),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Governance of data and its quality is distributed across domains, with a focus on collaboration, standardized practices,\nand federated decision-making processes to maintain data integrity and trust.")),(0,r.kt)("p",null,"While many of the concepts for a federated governance are on an organizational level and not on a technical level,\n",(0,r.kt)("em",{parentName:"p"},"SDLB")," can again help on various points."),(0,r.kt)("h3",{id:"data-catalogs"},"Data Catalogs"),(0,r.kt)("p",null,"When it comes to Data Catalogs, there is no open, agreed upon standard (yet). "),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"SDLB"),"'s configuration files are open and can be visualized as mentioned before.\nThe concepts of Data Objects and Actions are very similar to many Data Catalog notations and\nwith that, they also integrate nicely in existing solutions.\nThere is i.e. an exporter to ",(0,r.kt)("a",{parentName:"p",href:"https://atlas.apache.org/#/"},"Apache Atlas")," which also builds the basis of\n",(0,r.kt)("a",{parentName:"p",href:"https://azure.microsoft.com/en-us/products/purview"},"Azure Purview"),"."),(0,r.kt)("h3",{id:"encryption"},"Encryption"),(0,r.kt)("p",null,"One aspect with increasing importance is privacy and compliance.\nFor these topics, it helps to have a unified, generic implementation to prevent your domain teams to each\nstart their own implementation. "),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"SDLB")," now supports encrypted columns that help i.e. with PII data (Personally Identifiable Information)."),(0,r.kt)("h1",{id:"summary"},"Summary"),(0,r.kt)("p",null,"There are a lot of aspects to consider when adopting a Data Mesh, many of which are on a technical level.\nWhile you want to give your domain teams the independence to choose the technologies they know best,\nyou still want a framework that is easy to learn, quick to adapt and open to work with any other Data Product.\nThis article hopefully gave you a basic overview of how Smart Data Lake Builder can help you."))}u.isMDXComponent=!0}}]);