"use strict";(self.webpackChunksmart_data_lake=self.webpackChunksmart_data_lake||[]).push([[6217],{6020:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>f,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var i=t(4848),o=t(8453);const r={title:"Configure for different environments"},a=void 0,s={id:"getting-started/part-2/environments",title:"Configure for different environments",description:"Goal",source:"@site/docs/getting-started/part-2/environments.md",sourceDirName:"getting-started/part-2",slug:"/getting-started/part-2/environments",permalink:"/docs/getting-started/part-2/environments",draft:!1,unlisted:!1,editUrl:"https://github.com/smart-data-lake/smart-data-lake/tree/documentation/docs/getting-started/part-2/environments.md",tags:[],version:"current",frontMatter:{title:"Configure for different environments"},sidebar:"tutorialSidebar",previous:{title:"Keeping historical data",permalink:"/docs/getting-started/part-2/historical-data"},next:{title:"Custom Webservice",permalink:"/docs/getting-started/part-3/custom-webservice"}},d={},c=[{value:"Goal",id:"goal",level:2},{value:"SDLB approach for environment configuration",id:"sdlb-approach-for-environment-configuration",level:2},{value:"Creating DEV configuration file",id:"creating-dev-configuration-file",level:2},{value:"Configuring other environments",id:"configuring-other-environments",level:2},{value:"Summary",id:"summary",level:2}];function l(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"goal",children:"Goal"}),"\n",(0,i.jsx)(n.p,{children:"Industrializing data pipelines also means running them in different environments, e.g. DEV (development), INTE (Integration) and PROD (Production).\nDifferent environments normally need parametrized settings for connections and secrets.\nIn this step we will introduce SDLB approach for environment configuration, create a configuration for the DEV environment, and discuss how it can be adapted for PROD."}),"\n",(0,i.jsx)(n.h2,{id:"sdlb-approach-for-environment-configuration",children:"SDLB approach for environment configuration"}),"\n",(0,i.jsxs)(n.p,{children:["As SDLB configuration files use HOCON format, environment configuration can be implemented using ",(0,i.jsx)(n.a,{href:"https://github.com/lightbend/config/blob/master/HOCON.md#substitutions",children:"HOCON substitution"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["SDLB conventions suggest to use a separate configuration file per environment located in a special folder ",(0,i.jsx)(n.code,{children:"envConfig"}),'.\nLet\'s call these files "environment configuration files". The ',(0,i.jsx)(n.code,{children:"envConfig"})," folder is a separate folder from the ",(0,i.jsx)(n.code,{children:"config"})," folder."]}),"\n",(0,i.jsxs)(n.p,{children:["When starting an SDLB Job, ",(0,i.jsx)(n.em,{children:"one"})," environment configuration file is selected, and ",(0,i.jsx)(n.em,{children:"all"})," configuration files from the ",(0,i.jsx)(n.code,{children:"config"})," folder.\nUsing HOCON substitution the definitions of the selected environment configuration file can be used in the normal configuration files."]}),"\n",(0,i.jsx)(n.p,{children:"Selecting additional configurations files on the SDLB command line is easy, as you can give a list of configuration file locations.\nTo start our SDLB job with for a specific environment, we can just add the corresponding environment file as follows:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"./startJob.sh -c /mnt/config,/mnt/envConfig/dev.conf --feed-sel compute\n"})}),"\n",(0,i.jsx)(n.h2,{id:"creating-dev-configuration-file",children:"Creating DEV configuration file"}),"\n",(0,i.jsxs)(n.p,{children:["The command above do anything new yet, as we first need to create the ",(0,i.jsx)(n.code,{children:"envConfig/dev.conf"})," file."]}),"\n",(0,i.jsx)(n.p,{children:"As part of this tutorial, let's make the following configurations customizable per environment:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"database: The database name to be used in DeltaLakeTableDataObjects"}),"\n",(0,i.jsxs)(n.li,{children:["basePath: The root path where data files are stored\nFor this create an environment file ",(0,i.jsx)(n.code,{children:"envConfig/dev.conf"})," with the following content, if it doesn't yet exist:"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'env {\n  database = default\n  basePath = "./"\n}\n'})}),"\n",(0,i.jsxs)(n.p,{children:["Then lets replace all ",(0,i.jsx)(n.code,{children:"table.database"})," and ",(0,i.jsx)(n.code,{children:"path"})," configuration entries with a HOCON substitution as follows:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'  int-departures {\n    type = DeltaLakeTableDataObject\n    path = ${env.basePath}"~{id}"\n    table = {\n      db = ${env.database}\n      name = int_departures\n      primaryKey = [icao24, estdepartureairport, dt]\n    }\n    allowSchemaEvolution = true\n  }\n'})}),"\n",(0,i.jsxs)(n.p,{children:["Note that HOCON substitution syntax needs to be placed outside of string double quotes.\nNow you can test the configuration without running any feed. This can be done by using command line parameter ",(0,i.jsx)(n.code,{children:"--test config"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"./startJob.sh -c /mnt/config,/mnt/envConfig/dev.conf --feed-sel compute --test config\n"})}),"\n",(0,i.jsx)(n.admonition,{title:"Automated Testing",type:"note",children:(0,i.jsxs)(n.p,{children:["Testing the configuration is a very good starting point for automated integration tests.\nIt is the easiest CI pipeline and recommended for every project. See also ",(0,i.jsx)(n.a,{href:"/docs/reference/testing",children:"Testing"}),"."]})}),"\n",(0,i.jsx)(n.h2,{id:"configuring-other-environments",children:"Configuring other environments"}),"\n",(0,i.jsxs)(n.p,{children:["To configure other environments like PROD (Production), a ",(0,i.jsx)(n.code,{children:"envConfig/prd.conf"})," file is created and the relevant configurations adapted.\nThen ",(0,i.jsx)(n.code,{children:"dev.conf"})," in ",(0,i.jsx)(n.code,{children:"startJob.sh"})," command is replaced with ",(0,i.jsx)(n.code,{children:"prd.conf"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["A special case is managing secrets for different environments, e.g. passwords.\nSDLB supports various ",(0,i.jsx)(n.a,{href:"/docs/reference/hoconSecrets",children:"Secret Providers"}),", which can be configured differently per environment."]}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"You have now seen different parts of industrializing a data pipeline like robust data formats, caring about historical data and configuring different environments.\nFurther, you have explored data interactively with spark-shell."}),"\n",(0,i.jsxs)(n.p,{children:["The final solution for departures/airports/btl.conf should look like the files ending with ",(0,i.jsx)(n.code,{children:"part-2-solution"})," in ",(0,i.jsx)(n.a,{href:"https://github.com/smart-data-lake/getting-started/tree/master/config",children:"this directory"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"In part 3 we will see how to incrementally load fresh flight data.\nSee you!"})]})}function f(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>s});var i=t(6540);const o={},r=i.createContext(o);function a(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);