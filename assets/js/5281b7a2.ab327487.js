"use strict";(self.webpackChunksmart_data_lake=self.webpackChunksmart_data_lake||[]).push([[5927],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>g});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},u=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},d="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),d=p(a),m=r,g=d["".concat(s,".").concat(m)]||d[m]||c[m]||l;return a?n.createElement(g,i(i({ref:t},u),{},{components:a})):n.createElement(g,i({ref:t},u))}));function g(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,i=new Array(l);i[0]=m;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o[d]="string"==typeof e?e:r,i[1]=o;for(var p=2;p<l;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},1527:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>c,frontMatter:()=>l,metadata:()=>o,toc:()=>p});var n=a(7462),r=(a(7294),a(3905));const l={id:"architecture",title:"Architecture"},i=void 0,o={unversionedId:"architecture",id:"architecture",title:"Architecture",description:"Smart Data Lake Builder (SDLB) is basically a Java application which is started on the command line.",source:"@site/docs/architecture.md",sourceDirName:".",slug:"/architecture",permalink:"/docs/architecture",draft:!1,editUrl:"https://github.com/smart-data-lake/smart-data-lake/tree/documentation/docs/architecture.md",tags:[],version:"current",frontMatter:{id:"architecture",title:"Architecture"},sidebar:"docs",previous:{title:"Features",permalink:"/docs/features"},next:{title:"Technical Setup",permalink:"/docs/getting-started/setup"}},s={},p=[{value:"Basic Requirements",id:"basic-requirements",level:2},{value:"Versions and supported configuration",id:"versions-and-supported-configuration",level:2},{value:"SDLB Version 1.X",id:"sdlb-version-1x",level:3},{value:"SDLB Version 2.X",id:"sdlb-version-2x",level:3},{value:"Release Notes",id:"release-notes",level:2},{value:"Logging",id:"logging",level:2}],u={toc:p},d="wrapper";function c(e){let{components:t,...a}=e;return(0,r.kt)(d,(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Smart Data Lake Builder (SDLB) is basically a Java application which is started on the ",(0,r.kt)("a",{parentName:"p",href:"/docs/reference/commandLine"},"command line"),".\nIt can run in many environments and platforms like a Databricks cluster, Azure Synapse, Google Dataproc, and also on your local machine, see ",(0,r.kt)("a",{parentName:"p",href:"getting-started/setup"},"Getting Started"),"."),(0,r.kt)("p",null,"Find below an overview of requirements, versions and supported configurations."),(0,r.kt)("h2",{id:"basic-requirements"},"Basic Requirements"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Needs Java 8+ to run"),(0,r.kt)("li",{parentName:"ul"},"Uses Hadoop Java library to read local and remote files (S3, ADLS, HDFS, ...)"),(0,r.kt)("li",{parentName:"ul"},"Is programmed in Scala"),(0,r.kt)("li",{parentName:"ul"},"Uses Maven 3+ as build system")),(0,r.kt)("h2",{id:"versions-and-supported-configuration"},"Versions and supported configuration"),(0,r.kt)("p",null,"SDLB is published as Maven artifacts on Maven Central.\nThe SDLB versions are build with specific versions of Apache Spark and other libraries.\nThis page gives an overview of the respective versions."),(0,r.kt)("h3",{id:"sdlb-version-1x"},"SDLB Version 1.X"),(0,r.kt)("p",null,"SDLB version 1.X used Apache Spark 2.X.\nThis branch of SDLB is no longer maintained.\nTo profit from the latest development, please upgrade to a more recent version of SDLB."),(0,r.kt)("h3",{id:"sdlb-version-2x"},"SDLB Version 2.X"),(0,r.kt)("p",null,"The following table gives an overview of dependency versions that are delivered with each major branch of SDLB."),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"SDL Version"),(0,r.kt)("th",{parentName:"tr",align:null},"Java/Scala/Hadoop Version"),(0,r.kt)("th",{parentName:"tr",align:null},"Hadoop Version"),(0,r.kt)("th",{parentName:"tr",align:null},"Spark Engine"),(0,r.kt)("th",{parentName:"tr",align:null},"Log4j"),(0,r.kt)("th",{parentName:"tr",align:null},"Snowflake/Snowpark Engine"),(0,r.kt)("th",{parentName:"tr",align:null},"Delta Lake"),(0,r.kt)("th",{parentName:"tr",align:null},"Iceberg"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"2.5.X"),(0,r.kt)("td",{parentName:"tr",align:null},"Java 8+, Scala 2.12"),(0,r.kt)("td",{parentName:"tr",align:null},"3.3.2"),(0,r.kt)("td",{parentName:"tr",align:null},"3.3.2"),(0,r.kt)("td",{parentName:"tr",align:null},"2.17.2"),(0,r.kt)("td",{parentName:"tr",align:null},"2.11.0 / 1.6.2"),(0,r.kt)("td",{parentName:"tr",align:null},"2.2.0"),(0,r.kt)("td",{parentName:"tr",align:null},"1.1.0")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"2.4.X"),(0,r.kt)("td",{parentName:"tr",align:null},"Java 8+, Scala 2.12"),(0,r.kt)("td",{parentName:"tr",align:null},"3.3.1"),(0,r.kt)("td",{parentName:"tr",align:null},"3.2.2"),(0,r.kt)("td",{parentName:"tr",align:null},"1.2.17"),(0,r.kt)("td",{parentName:"tr",align:null},"2.10.0 / 1.2.0"),(0,r.kt)("td",{parentName:"tr",align:null},"2.0.0"),(0,r.kt)("td",{parentName:"tr",align:null},"-")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"2.3.X"),(0,r.kt)("td",{parentName:"tr",align:null},"Java 8+, Scala 2.12"),(0,r.kt)("td",{parentName:"tr",align:null},"3.3.1"),(0,r.kt)("td",{parentName:"tr",align:null},"3.2.2"),(0,r.kt)("td",{parentName:"tr",align:null},"1.2.17"),(0,r.kt)("td",{parentName:"tr",align:null},"2.10.0 / 1.2.0"),(0,r.kt)("td",{parentName:"tr",align:null},"2.0.0"),(0,r.kt)("td",{parentName:"tr",align:null},"-")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"2.2.X"),(0,r.kt)("td",{parentName:"tr",align:null},"Java 8+, Scala 2.12"),(0,r.kt)("td",{parentName:"tr",align:null},"3.3.1"),(0,r.kt)("td",{parentName:"tr",align:null},"3.2.1"),(0,r.kt)("td",{parentName:"tr",align:null},"1.2.17"),(0,r.kt)("td",{parentName:"tr",align:null},"2.9.2 / 0.11.0"),(0,r.kt)("td",{parentName:"tr",align:null},"1.1.0"),(0,r.kt)("td",{parentName:"tr",align:null},"-")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"2.1.X"),(0,r.kt)("td",{parentName:"tr",align:null},"Java 8+, Scala 2.12"),(0,r.kt)("td",{parentName:"tr",align:null},"2.7.4"),(0,r.kt)("td",{parentName:"tr",align:null},"3.1.1"),(0,r.kt)("td",{parentName:"tr",align:null},"1.2.17"),(0,r.kt)("td",{parentName:"tr",align:null},"2.8.4"),(0,r.kt)("td",{parentName:"tr",align:null},"1.0.0"),(0,r.kt)("td",{parentName:"tr",align:null},"-")))),(0,r.kt)("p",null,"It's possible to customize dependencies and make Smart Data Lake Builder work with other version combinations, but this needs manual tuning of dependencies in your own maven project."),(0,r.kt)("p",null,"In general, Java library versions are held as close as possible to the ones used in the corresponding Spark version."),(0,r.kt)("h2",{id:"release-notes"},"Release Notes"),(0,r.kt)("p",null,"See SDBL Release Notes including breaking changes on ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/smart-data-lake/smart-data-lake/releases"},"Github")),(0,r.kt)("h2",{id:"logging"},"Logging"),(0,r.kt)("p",null,"By default, SDLB uses the logging libraries included in the corresponding Spark version. This is Log4j 1.2.x for Spark 2.4.x up to Spark 3.2.x.\nStarting from Spark 3.3.x it will use Log4j 2.x, see ",(0,r.kt)("a",{parentName:"p",href:"https://issues.apache.org/jira/browse/SPARK-6305"},"SPARK-6305"),"."),(0,r.kt)("p",null,"You can customize logging dependencies manually by creating your own maven project."))}c.isMDXComponent=!0}}]);