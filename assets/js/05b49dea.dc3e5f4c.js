"use strict";(self.webpackChunksmart_data_lake=self.webpackChunksmart_data_lake||[]).push([[2689],{7793:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>d});var i=n(4848),a=n(8453);const s={title:"Using Airbyte connector to inspect github data",description:"A short example using Airbyte github connector",slug:"sdl-airbyte",authors:[{name:"Mandes Sch\xf6nherr",title:"Dr.sc.nat.",url:"https://github.com/mand35"}],tags:["Airbyte","Connector"],image:"airbyte.png",hide_table_of_contents:!1},r=void 0,o={permalink:"/blog/sdl-airbyte",editUrl:"https://github.com/smart-data-lake/smart-data-lake/tree/documentation/blog/2022-03-18-SDL-airbyte/2022-03-18-SDL-airbyte.md",source:"@site/blog/2022-03-18-SDL-airbyte/2022-03-18-SDL-airbyte.md",title:"Using Airbyte connector to inspect github data",description:"A short example using Airbyte github connector",date:"2022-03-18T00:00:00.000Z",formattedDate:"March 18, 2022",tags:[{label:"Airbyte",permalink:"/blog/tags/airbyte"},{label:"Connector",permalink:"/blog/tags/connector"}],readingTime:4.48,hasTruncateMarker:!0,authors:[{name:"Mandes Sch\xf6nherr",title:"Dr.sc.nat.",url:"https://github.com/mand35"}],frontMatter:{title:"Using Airbyte connector to inspect github data",description:"A short example using Airbyte github connector",slug:"sdl-airbyte",authors:[{name:"Mandes Sch\xf6nherr",title:"Dr.sc.nat.",url:"https://github.com/mand35"}],tags:["Airbyte","Connector"],image:"airbyte.png",hide_table_of_contents:!1},unlisted:!1,prevItem:{title:"Combine Spark and Snowpark to ingest and transform data in one pipeline",permalink:"/blog/sdl-snowpark"}},c={authorsImageUrls:[void 0]},d=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"[Optional] Inspect the connector specification",id:"optional-inspect-the-connector-specification",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Run and inspect results",id:"run-and-inspect-results",level:2},{value:"Summary",id:"summary",level:2}];function l(e){const t={a:"a",code:"code",em:"em",h2:"h2",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(t.p,{children:["This article presents the deployment of an ",(0,i.jsx)(t.a,{href:"https://airbyte.com",children:"Airbyte Connector"})," with Smart Data Lake Builder (SDLB).\nIn particular the ",(0,i.jsx)(t.a,{href:"https://docs.airbyte.com/integrations/sources/github",children:"github connector"})," is implemented using the python sources."]}),"\n",(0,i.jsxs)(t.p,{children:["Airbyte is a framework to sync data from a variety of sources (APIs and databases) into data warehouses and data lakes.\nIn this example an Airbyte connector is utilized to stream data into Smart Data Lake (SDL).\nTherefore, the ",(0,i.jsx)(t.a,{href:"http://smartdatalake.ch/json-schema-viewer/index.html#viewer-page?v=2-2",children:"Airbyte DataObject"})," is used and will be configured.\nThe general ",(0,i.jsx)(t.a,{href:"https://docs.airbyte.com/understanding-airbyte/airbyte-specification#source",children:"Airbyte connector handling"})," is implemented in SDL, which includes the 4 main steps:"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"spec"}),": receiving the specification of the connector"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"check"}),": validating the specified configuration"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"discover"}),": gather a catalog of available streams and its schemas"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"read"}),": collect the actual data"]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["The actual connector is not provided in the SDL repository and needs to be obtained from the ",(0,i.jsx)(t.a,{href:"https://github.com/airbytehq/airbyte",children:"Airbyte repository"}),". Besides the ",(0,i.jsx)(t.a,{href:"https://docs.airbyte.com/integrations",children:"list of existing connectors"}),", custom connectors could be implemented in Python or Javascript."]}),"\n",(0,i.jsxs)(t.p,{children:["The following description builds on top of the example setup from the ",(0,i.jsx)(t.a,{href:"../../docs/getting-started/setup",children:"getting-started"})," guide, using ",(0,i.jsx)(t.a,{href:"https://docs.podman.io",children:"Podman"})," as container engine within a ",(0,i.jsx)(t.a,{href:"https://docs.microsoft.com/en-us/windows/wsl/install",children:"WSL"})," Ubuntu image."]}),"\n",(0,i.jsxs)(t.p,{children:["The ",(0,i.jsx)(t.a,{href:"https://docs.airbyte.com/integrations/sources/github",children:"github connector"})," is utilized to gather data about a specific repository."]}),"\n",(0,i.jsx)(t.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(t.p,{children:"After downloading and installing all necessary packages, the connector is briefly tested:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Python"}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.a,{href:"../../docs/getting-started/troubleshooting/docker-on-windows",children:"Podman"})," or ",(0,i.jsx)(t.a,{href:"https://www.docker.com/get-started",children:"Docker"})]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.a,{href:"https://github.com/smart-data-lake/getting-started/archive/refs/heads/master.zip",children:"SDL example"}),", download and unpack:","\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-Bash",children:"git clone https://github.com/smart-data-lake/getting-started.git SDL_airbyte\ncd SDL_airbyte\n"})}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["download the ",(0,i.jsx)(t.a,{href:"https://github.com/airbytehq/airbyte",children:"Airbyte repository"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-Bash",children:"git clone https://github.com/airbytehq/airbyte.git\n"})}),"\n","Alternatively, only the target connector can be downloaded:","\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-Bash",children:"svn checkout https://github.com/airbytehq/airbyte/trunk/airbyte-integrations/connectors/source-github\n"})}),"\n","Here the Airbyte ",(0,i.jsx)(t.code,{children:"airbyte/airbyte-integrations/connectors/source-github/"})," directory is copied into the ",(0,i.jsx)(t.code,{children:"SDL_airbyte"})," directory for handy calling the connector."]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"optional-inspect-the-connector-specification",children:"[Optional] Inspect the connector specification"}),"\n",(0,i.jsxs)(t.p,{children:["The first connector command ",(0,i.jsx)(t.code,{children:"spec"})," provides the connector specification. This is the basis to create a connector configuration. To run the connector as is, the Python ",(0,i.jsx)(t.code,{children:"airbyte-cdk"})," package needs to be installed and the connector can be launched:"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["Install Python airbyte-cdk: ",(0,i.jsx)(t.code,{children:"pip install airbyte_cdk"})]}),"\n",(0,i.jsxs)(t.li,{children:["try the connector:","\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-Bash",children:"cd SDL_airbyte\npython source_github/main.py spec | python -m json.tool\n"})}),"\n","This provides a ",(0,i.jsx)(t.a,{target:"_blank",href:n(1954).A+"",children:"JSON string"})," with the connector specification. The fields listed under ",(0,i.jsx)(t.code,{children:"properties"})," are relevant for the configuration (compare with the configuration  used later)."]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"configuration",children:"Configuration"}),"\n",(0,i.jsx)(t.p,{children:"To launch Smart Data Lake Builder (SDLB) with the Airbyte connector the following needs to be modified:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["add the Airbyte ",(0,i.jsx)(t.em,{children:(0,i.jsx)(t.strong,{children:"DataObject"})})," with its configuration to the ",(0,i.jsx)(t.code,{children:"config/application.conf"}),":"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-Python",children:'dataObjects {\n  ext-commits {\n    type = AirbyteDataObject\n    config = {\n      "credentials": {\n        "personal_access_token": "<yourPersonalAccessToken>" ### enter your personal access token here\n      },\n      "repository": "smart-data-lake/smart-data-lake",\n      "start_date": "2021-02-01T00:00:00Z",\n      "branch": "documentation develop-spark3 develop-spark2",\n      "page_size_for_large_streams": 100\n    },\n    streamName = "commits",\n    cmd = {\n      type = CmdScript\n      name = "airbyte_connector_github"\n      linuxCmd = "python3 /mnt/source-github/main.py"\n    }\n  }\n...\n  stg-commits {\n   type = DeltaLakeTableDataObject\n   path = "~{id}"\n   table {\n    db = "default"\n    name = "stg_commits"\n    primaryKey = [created_at]\n    }\n  }\n'})}),"\n",(0,i.jsxs)(t.p,{children:["Note the options set for ",(0,i.jsx)(t.code,{children:"ext-commits"})," which define the Airbyte connector settings.\nWhile the ",(0,i.jsx)(t.code,{children:"config"})," varies from connector to connector, the remaining fields are SDL specific.\nThe ",(0,i.jsx)(t.code,{children:"streamName"})," selects the stream, exactly one.\nIf multiple streams should be collected, multiple dataObjects need to be defined.\nIn ",(0,i.jsx)(t.code,{children:"linuxCmd"})," the actual connector script is called.\nIn our case we will mount the connector directory into the SDL container."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["also add the definition of the data stream ",(0,i.jsx)(t.em,{children:(0,i.jsx)(t.strong,{children:"action"})})," to pipe the coming data stream into a ",(0,i.jsx)(t.code,{children:"DeltaLakeTableDataObject"}),":"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-Bash",children:"  actions {\n    download-commits {\n      type = CopyAction\n      inputId = ext-commits\n      outputId = stg-commits\n      metadata {\n        feed = download\n      }\n    }\n...\n"})}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["Since Airbyte will be called as Python script in the sdl container, we need to (re-)build the container with Python support and the Python ",(0,i.jsx)(t.code,{children:"airbyte-cdk"})," package.\nTherefore, in the Dockerfile we add:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"RUN \\\napt update && \\\napt --assume-yes install python3 python3-pip && \\\npip3 install airbyte-cdk~=0.1.25\n"})}),"\n",(0,i.jsx)(t.p,{children:"and rebuild"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-Bash",children:"podman build . -t sdl-spark\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["Now we are ready to go. My full ",(0,i.jsx)(t.a,{target:"_blank",href:n(1296).A+"",children:"SDLB config file"})," additionally includes the pull-request stream."]}),"\n",(0,i.jsx)(t.h2,{id:"run-and-inspect-results",children:"Run and inspect results"}),"\n",(0,i.jsxs)(t.p,{children:["Since the data will be streamed into a ",(0,i.jsx)(t.code,{children:"DeltaLakeTableDataObject"}),", the metastore container is necessary. Further, we aim to inspect the data using the Polynote notebook. Thus, first these containers are launched using (in the SDL example base directory):"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-Bash",children:"./part2/podman-compose.sh #use the script from the getting-started guide\npodman pod ls\n"})}),"\n",(0,i.jsx)(t.p,{children:"With the second command we can verify the pod name and both running containers in it (should be three including the infra container)."}),"\n",(0,i.jsx)(t.p,{children:"Then, the SDLB can be launched using the additional option to mount the Airbyte connector directory:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-Bash",children:"podman run --hostname localhost --rm --pod sdl_airbyte -v ${PWD}/source-github/:/mnt/source-github -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark:latest --config /mnt/config --feed-sel download\n"})}),"\n",(0,i.jsx)(t.p,{children:"The output presents the successful run of the workflow:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-Bash",children:"2022-03-16 07:54:03 INFO  ActionDAGRun$ActionEventListener - Action~download-commits[CopyAction]: Exec succeeded [dag-1-80]\n2022-03-16 07:54:03 INFO  ActionDAGRun$ - exec SUCCEEDED for dag 1:\n                 \u250c\u2500\u2500\u2500\u2500\u2500\u2510\n                 \u2502start\u2502\n                 \u2514\u2500\u2500\u2500\u252c\u2500\u2518\n                     \u2502\n                     v\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502download-commits SUCCEEDED PT11.686865S\u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     [main]\n2022-03-16 07:54:03 INFO  LocalSmartDataLakeBuilder$ - LocalSmartDataLakeBuilder finished successfully: SUCCEEDED=1 [main]\n2022-03-16 07:54:03 INFO  SparkUI - Stopped Spark web UI at http://localhost:4040 [shutdown-hook-0]\n"})}),"\n",(0,i.jsxs)(t.p,{children:["Launching Polynote ",(0,i.jsx)(t.code,{children:"localhost:8192"})," in the browser, we can inspect data and develop further workflows. Here an example, where the commits are listed, which were committed in the name of someone else, excluding the web-flow. See ",(0,i.jsx)(t.a,{target:"_blank",href:n(7352).A+"",children:"Polynote Notebook"}),"\n",(0,i.jsx)(t.img,{alt:"polynote example",src:n(4596).A+"",width:"1018",height:"810"})]}),"\n",(0,i.jsx)(t.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(t.p,{children:"The Airbyte connectors provide easy access to a variety of data sources. The connectors can be utilized in SDLB with just a few settings. This also works great for more complex interfaces."})]})}function h(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},7352:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/files/SelectingData-fc913585bab1ef41a6b1f32ee50d5adb.ipynb"},1296:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/files/application-b6a5a6494622e5ff40741395d829f558.conf"},1954:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/files/github_spec_out-e78cbc05ed4f12e8414017c3698a8edb.json"},4596:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/polynote_commits-0877fa6cab02c46db63471b8220af7ea.png"},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>o});var i=n(6540);const a={},s=i.createContext(a);function r(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);