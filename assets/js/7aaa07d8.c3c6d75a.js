"use strict";(self.webpackChunksmart_data_lake=self.webpackChunksmart_data_lake||[]).push([[8141],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>m});var r=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var p=r.createContext({}),s=function(e){var t=r.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},d=function(e){var t=s(e.components);return r.createElement(p.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},c=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,p=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),c=s(a),m=n,k=c["".concat(p,".").concat(m)]||c[m]||u[m]||o;return a?r.createElement(k,l(l({ref:t},d),{},{components:a})):r.createElement(k,l({ref:t},d))}));function m(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,l=new Array(o);l[0]=c;var i={};for(var p in t)hasOwnProperty.call(t,p)&&(i[p]=t[p]);i.originalType=e,i.mdxType="string"==typeof e?e:n,l[1]=i;for(var s=2;s<o;s++)l[s]=a[s];return r.createElement.apply(null,l)}return r.createElement.apply(null,a)}c.displayName="MDXCreateElement"},1433:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>k,frontMatter:()=>o,metadata:()=>i,toc:()=>s});var r=a(7462),n=(a(7294),a(3905));const o={id:"build",title:"Build SDL"},l=void 0,i={unversionedId:"reference/build",id:"reference/build",title:"Build SDL",description:"Build from Source Code",source:"@site/docs/reference/build.md",sourceDirName:"reference",slug:"/reference/build",permalink:"/docs/reference/build",draft:!1,editUrl:"https://github.com/smart-data-lake/smart-data-lake/tree/documentation/docs/reference/build.md",tags:[],version:"current",frontMatter:{id:"build",title:"Build SDL"},sidebar:"docs",previous:{title:"Notes for Windows Users",permalink:"/docs/getting-started/troubleshooting/docker-on-windows"},next:{title:"Command Line",permalink:"/docs/reference/commandLine"}},p={},s=[{value:"Build from Source Code",id:"build-from-source-code",level:2},{value:"Build Dependencies",id:"build-dependencies",level:3},{value:"Releases and snapshots",id:"releases-and-snapshots",level:3},{value:"Start a new project",id:"start-a-new-project",level:3},{value:"Building JAR with Runtime Dependencies",id:"building-jar-with-runtime-dependencies",level:3},{value:"Build an SDL Container",id:"build-an-sdl-container",level:2}],d=e=>function(t){return console.warn("Component "+e+" was not imported, exported, or provided by MDXProvider as global scope"),(0,n.kt)("div",t)},u=d("Tabs"),c=d("TabItem"),m={toc:s};function k(e){let{components:t,...a}=e;return(0,n.kt)("wrapper",(0,r.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h2",{id:"build-from-source-code"},"Build from Source Code"),(0,n.kt)("p",null,"In the ",(0,n.kt)("a",{parentName:"p",href:"/docs/getting-started/setup"},"getting started guide")," we used Docker to get you up to speed quickly.\nIf you take a closer look at the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/smart-data-lake/getting-started/blob/master/Dockerfile"},"Dockerfile"),",\nyou will see that we simply execute Apache Maven for you to build the jar file and configure an appropriate entrypoint for the container. "),(0,n.kt)("p",null,"In a real world project, you probably want more control over the build process, this page helps you in this case."),(0,n.kt)("p",null,"Smart Data Lake Builder is build using ",(0,n.kt)("a",{parentName:"p",href:"https://maven.apache.org/"},"Apache Maven"),".\nHere is an overview of the various versions at play:"),(0,n.kt)("h3",{id:"build-dependencies"},"Build Dependencies"),(0,n.kt)("p",null,"SDL Version 1.x"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("em",{parentName:"li"},"Spark 2.4")),(0,n.kt)("li",{parentName:"ul"},"JDK 8 (Spark 2 doesn't support JDK 9 or higher)"),(0,n.kt)("li",{parentName:"ul"},"Scala 2.11 or 2.12"),(0,n.kt)("li",{parentName:"ul"},"Maven 3.0 (or higher)")),(0,n.kt)("p",null,"SDL Version 2.x"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("em",{parentName:"li"},"Spark 3.x")),(0,n.kt)("li",{parentName:"ul"},"JDK >= 8"),(0,n.kt)("li",{parentName:"ul"},"Scala 2.12 (Spark 3 doesn't support scala 2.11 anymore)"),(0,n.kt)("li",{parentName:"ul"},"Maven 3.0 (or higher)")),(0,n.kt)("admonition",{type:"tip"},(0,n.kt)("p",{parentName:"admonition"},"If you don't have strong reasons to still use Spark 2.X, you should use the latest version of Smart Data Lake Builder which comes with Spark 3.X.")),(0,n.kt)("h3",{id:"releases-and-snapshots"},"Releases and snapshots"),(0,n.kt)("p",null,"You rarely need to build Smart Data Lake Builder yourself.\nWe publish releases regularly on ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/smart-data-lake/smart-data-lake/releases"},"Github"),".\nThese releases are automatically published on Maven Central and can therefore be used directly.\nOn every merge to the develop branch, we also release snapshot releases to Sonatype, so you can even reference SNAPSHOT releases for cutting edge versions. "),(0,n.kt)("h3",{id:"start-a-new-project"},"Start a new project"),(0,n.kt)("p",null,"So how do you usually start with a new project?\nTake a look at ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/smart-data-lake/sdl-examples"},"sdl-examples")," as a template.\nYou start a new Maven project and define our ",(0,n.kt)("inlineCode",{parentName:"p"},"sdl-parent")," as your projects parent:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"<parent>\n    <groupId>io.smartdatalake</groupId>\n    <artifactId>sdl-parent</artifactId>\n    \x3c!--\n        Set the smartdatalake version to use here.\n        If version cannot be resolved, make sure maven central repository is defined in settings.xml and the corresponding profile activated.\n        If version in IntelliJ still cannot be resolved, a restart of IntelliJ might help!\n    --\x3e\n    <version>2.1.1</version>\n</parent>\n")),(0,n.kt)("h3",{id:"building-jar-with-runtime-dependencies"},"Building JAR with Runtime Dependencies"),(0,n.kt)("p",null,"With that, you also get all profiles defined in our parent project,\nso it's easy to generate a ",(0,n.kt)("strong",{parentName:"p"},(0,n.kt)("em",{parentName:"strong"},"fat-jar"))," for example (including all dependencies you need).\nWhen deploying to a cluster with Apache Spark preconfigured, you don't need to include this dependency yourself.\nUse the profile ",(0,n.kt)("strong",{parentName:"p"},(0,n.kt)("em",{parentName:"strong"},"fat-jar"))," in this case.",(0,n.kt)("br",{parentName:"p"}),"\n","If you want to generate a jar for local execution or somewhere Apache Spark is not provided, use the profile ",(0,n.kt)("strong",{parentName:"p"},(0,n.kt)("em",{parentName:"strong"},"fat-jar-with-spark"))," instead"),(0,n.kt)("h2",{id:"build-an-sdl-container"},"Build an SDL Container"),(0,n.kt)("p",null,"To build an SDL container a ",(0,n.kt)("em",{parentName:"p"},"Dockerfile")," and a ",(0,n.kt)("em",{parentName:"p"},"pom.xml")," is neccessary. The Dockerfile specifies:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"maven base image, and the openjdk image"),(0,n.kt)("li",{parentName:"ul"},"SDL specifiaction, defined in the ",(0,n.kt)("inlineCode",{parentName:"li"},"pom.xml")),(0,n.kt)("li",{parentName:"ul"},"log4j property file"),(0,n.kt)("li",{parentName:"ul"},"entrypoint")),(0,n.kt)("p",null,"An example would be:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},'#\n# Build stage\n#\nFROM docker.io/maven:3.6.0-jdk-11-slim AS build\nCOPY src /home/app/src\nCOPY pom.xml /home/app\nRUN mvn --quiet -f /home/app/pom.xml -Pcopy-libs package\n\n#\n# Package stage\n# Note that *.jar is provided to the docker image through /mnt/lib and added to the class-path for SDL.\n#\nFROM docker.io/openjdk:11-jre-slim\nCOPY --from=build /home/app/target/lib/*.jar /opt/app/lib/\nCOPY --from=build /home/app/src/main/resources/log4j.properties /home/app/lib/\nENTRYPOINT ["java","-D${CONFIG_OVERWRITE}", "-Duser.dir=/mnt/data","-Dlog4j.configuration=file:/home/app/lib/log4j.properties","-cp","/opt/app/lib/*:/mnt/lib/*","io.smartdatalake.app.LocalSmartDataLakeBuilder"]\n')),(0,n.kt)("p",null,"Custom Scala Classes for e.g. DataObjects and Transformers, can be build seperately and mounted into the container (into ",(0,n.kt)("inlineCode",{parentName:"p"},"/mnt/lib"),"). "),(0,n.kt)(u,{groupId:"docker-podman-switch",defaultValue:"docker",values:[{label:"Docker",value:"docker"},{label:"Podman",value:"podman"}],mdxType:"Tabs"},(0,n.kt)(c,{value:"docker",mdxType:"TabItem"},(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-jsx"},"docker build -t sdl-spark .\n"))),(0,n.kt)(c,{value:"podman",mdxType:"TabItem"},(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-jsx"},"podman build -t sdl-spark .\n")))),(0,n.kt)("p",null,"An example including the log4j.properties is also provided in the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/smart-data-lake/getting-started.git"},"getting-started"),"."))}k.isMDXComponent=!0}}]);