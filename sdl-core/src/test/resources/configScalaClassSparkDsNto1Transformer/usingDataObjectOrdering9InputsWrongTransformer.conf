actions {
  double_rating {
    type = CustomDataFrameAction
    inputIds = [src1Ds, src2Ds, src3Ds, src4Ds, src5Ds, src6Ds, src7Ds, src8Ds, src9Ds] //Ordering in inputIds list has to match order of parameters in transform method, but the parameter names can be named freely with this option
    outputIds = [tgt1Ds]
    metadata.feed = test_feed_name
    transformers = [
      {type = ScalaClassSparkDsNTo1Transformer, className = io.smartdatalake.workflow.action.TestResolutionByOrderingDs2To1Transformer, options = {parameterResolution = DataObjectOrdering}}
    ]
  }
}

dataObjects {
  src1Ds {
    type = CsvFileDataObject
    path = "target/src1Ds2to1"
    schema = """name string, rating int"""
  }
  src2Ds {
    type = CsvFileDataObject
    path = "target/src2Ds2to1"
    schema = """name string, rating int"""
  }
  src3Ds {
    type = CsvFileDataObject
    path = "target/src1Ds2to1"
    schema = """name string, rating int"""
  }
  src4Ds {
    type = CsvFileDataObject
    path = "target/src2Ds2to1"
    schema = """name string, rating int"""
  }
  src5Ds {
    type = CsvFileDataObject
    path = "target/src1Ds2to1"
    schema = """name string, rating int"""
  }
  src6Ds {
    type = CsvFileDataObject
    path = "target/src2Ds2to1"
    schema = """name string, rating int"""
  }
  src7Ds {
    type = CsvFileDataObject
    path = "target/src1Ds2to1"
    schema = """name string, rating int"""
  }
  src8Ds {
    type = CsvFileDataObject
    path = "target/src2Ds2to1"
    schema = """name string, rating int"""
  }
  src9Ds {
    type = CsvFileDataObject
    path = "target/src2Ds2to1"
    schema = """name string, rating int"""
  }
  tgt1Ds {
    type = CsvFileDataObject
    path = "target/tgt1Ds2to1"
  }
}