<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://www.smartdatalake.ch/blog</id>
    <title>Smart Data Lake Builder Blog</title>
    <updated>2023-11-09T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://www.smartdatalake.ch/blog"/>
    <subtitle>Smart Data Lake Builder Blog</subtitle>
    <icon>https://www.smartdatalake.ch/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[SDLB UI Updated!]]></title>
        <id>https://www.smartdatalake.ch/blog/sdl-uidemo</id>
        <link href="https://www.smartdatalake.ch/blog/sdl-uidemo"/>
        <updated>2023-11-09T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Data Pipeline Visualization Tool]]></summary>
        <content type="html"><![CDATA[<p>We are thrilled to announce a major overhaul of the <strong>SDLB UI</strong> designed to revolutionize the way we visualize, track, and manage data pipelines!
This addition to SDLB acts as a user-friendly technical data catalog that showcases dependencies through a lineage graph, along with metadata about data pipeline execution (workflows).</p>
<p>SDLBs UI tool is a step forward in data pipeline management, providing enhanced visibility and control.
Whether you are a data engineer, analyst, or scientist, this tool will enhance your abilities to manage data pipelines,
allowing you to be more productive and achieve exceptional results.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="-see-it-in-action">üåü See it in action<a href="https://www.smartdatalake.ch/blog/sdl-uidemo#-see-it-in-action" class="hash-link" aria-label="Direct link to üåü See it in action" title="Direct link to üåü See it in action">‚Äã</a></h2>
<p>Check out the new <a href="https://ui-demo.smartdatalake.ch/" target="_blank" rel="noopener noreferrer">UI-Demo</a>, where the final data pipeline of our <a href="https://www.smartdatalake.ch/docs/getting-started/setup">Getting Started Guide</a> is used as an example for our UI tool.
Witness firsthand how our tool simplifies data pipeline management and enhances your workflow efficiency.</p>
<p><img loading="lazy" alt="home" src="https://www.smartdatalake.ch/assets/images/home-758fa247e165d33815b7fd45edbc9361.png" width="684" height="477" class="img_ev3q"></p>
<p>Thanks to its user-friendly interface and powerful features, managing complex workflows has never been easier.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="-comprehensive-workflow-dashboard">üìä Comprehensive Workflow Dashboard<a href="https://www.smartdatalake.ch/blog/sdl-uidemo#-comprehensive-workflow-dashboard" class="hash-link" aria-label="Direct link to üìä Comprehensive Workflow Dashboard" title="Direct link to üìä Comprehensive Workflow Dashboard">‚Äã</a></h2>
<p>Get a bird's eye view of your data pipelines! Our new intuitive dashboard visualizes intricate details for each run,
including execution time, duration, and the feed configuration used.
Deep dive into the timeline of involved actions, with the ability to access detailed execution metrics by simply clicking on each action.
<img loading="lazy" alt="Timeline of Action" src="https://www.smartdatalake.ch/assets/images/timeline-cbf74778683a66781c724b01677cad0a.png" width="1237" height="481" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="-configuration-viewer-with-rich-content">üîç Configuration Viewer with Rich Content<a href="https://www.smartdatalake.ch/blog/sdl-uidemo#-configuration-viewer-with-rich-content" class="hash-link" aria-label="Direct link to üîç Configuration Viewer with Rich Content" title="Direct link to üîç Configuration Viewer with Rich Content">‚Äã</a></h2>
<p>Explore your configuration using the Configuration Viewer that contains all the information from your config file,
and extra information you provide as documentation. You can find:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="configuration-details">Configuration Details<a href="https://www.smartdatalake.ch/blog/sdl-uidemo#configuration-details" class="hash-link" aria-label="Direct link to Configuration Details" title="Direct link to Configuration Details">‚Äã</a></h3>
<p>View all the details of your SDLB configuration in an appealing UI.
For DataObjects the page is enriched with a list of the last SDLB Runs that modified the corresponding data, and some table statistics:</p>
<p><img loading="lazy" alt="configuration" src="https://www.smartdatalake.ch/assets/images/btl-distance-config-d71d6d76e17880996951fd66e1ab76ff.png" width="1069" height="717" class="img_ev3q"></p>
<p>Tags help to organize configuration objects and find related items.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="markdown-descriptions">Markdown Descriptions<a href="https://www.smartdatalake.ch/blog/sdl-uidemo#markdown-descriptions" class="hash-link" aria-label="Direct link to Markdown Descriptions" title="Direct link to Markdown Descriptions">‚Äã</a></h3>
<p>SDLB supports creating descriptions as markdown files, enabling you to provide comprehensive documentation about DataObjects and Actions.
Markdown description files can include images, hyperlinks, and other formatting options:</p>
<p><img loading="lazy" alt="description" src="https://www.smartdatalake.ch/assets/images/btl-distance-des-2c1ec076e8555c583b1260f9d71270e8.png" width="1069" height="682" class="img_ev3q"></p>
<p>Good documentation is very important for long-term maintenance of data pipelines.
The benefit of this documentation is that it's versioned together with your code and can be part of your code reviews.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="schema-and-column-statistics">Schema and Column Statistics<a href="https://www.smartdatalake.ch/blog/sdl-uidemo#schema-and-column-statistics" class="hash-link" aria-label="Direct link to Schema and Column Statistics" title="Direct link to Schema and Column Statistics">‚Äã</a></h3>
<p>The UI can now also show the schema of DataObjects, including column statistics:</p>
<p><img loading="lazy" alt="schemas" src="https://www.smartdatalake.ch/assets/images/btl-distance-schema-22ec2f776a0332fc388c9d127b53a2a6.png" width="1069" height="535" class="img_ev3q"></p>
<p>This helps a lot to get a better first impression of the content of a DataObject.
Schema and Statistics must be exported regularly using a Command Line Tool.
Best practice is to make this part of your release pipeline.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="transformation-documentation">Transformation Documentation<a href="https://www.smartdatalake.ch/blog/sdl-uidemo#transformation-documentation" class="hash-link" aria-label="Direct link to Transformation Documentation" title="Direct link to Transformation Documentation">‚Äã</a></h3>
<p>For Actions the UI provides clear visualizations of the transformers applied.
For Custom transformers implemented as Scala classes the view is enriched with source code documentation:</p>
<p><img loading="lazy" alt="transformers" src="https://www.smartdatalake.ch/assets/images/compute-distance-config-e5ec4c87c106938533e0c811e015387e.png" width="1069" height="656" class="img_ev3q"></p>
<p>This feature simplifies the understanding of complex data transformations, and again encourages to version documentation and code together, following the "documentation as code" approach.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lineage-graph">Lineage Graph<a href="https://www.smartdatalake.ch/blog/sdl-uidemo#lineage-graph" class="hash-link" aria-label="Direct link to Lineage Graph" title="Direct link to Lineage Graph">‚Äã</a></h3>
<p>Track and understand the flow of data across various processing stages with lineage graph visualization.
Visualize the dependencies between data objects and actions involved in your data pipeline, empowering you to monitor the data flow and answer questions about the impact of changes.</p>
<p><img loading="lazy" alt="lineage" src="https://www.smartdatalake.ch/assets/images/compute-distance-lineage-ac47d1783841becbacb4988ea536176e.png" width="364" height="839" class="img_ev3q"></p>
<p>The visualization supports switching between the graph of Actions (control flow), the graph of DataObjects (data flow), and a complete flow of Actions and DataObjects as shown in the screenshot above.
You can expand/collapse all up- and downstream nodes at once, or just individual edges one-by-one. And you can switch between vertical and horizontal layout.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary-and-outlook">Summary and Outlook<a href="https://www.smartdatalake.ch/blog/sdl-uidemo#summary-and-outlook" class="hash-link" aria-label="Direct link to Summary and Outlook" title="Direct link to Summary and Outlook">‚Äã</a></h2>
<p>The SDLB UI is game-changing tool to maintain and operate data pipelines more efficiently!
Get started today using the installation guide on the <a href="https://github.com/smart-data-lake/sdl-visualization" target="_blank" rel="noopener noreferrer">sdl-visualization</a> GitHub repository.
Or try out our <a href="https://www.smartdatalake.ch/docs/getting-started/setup">Getting Started Guide</a>, where you learn more about descriptive metadata and the UI in <a href="http://localhost:3000/docs/getting-started/part-3/metadata" target="_blank" rel="noopener noreferrer">part 3</a>.</p>
<p>For sure we will further invest to advance the UI. Features on the roadmap are real-time workflow run updates, improved metrics statistics and grouping in the lineage graph.
Should you have suggestions for improvements or bug reports, feel free to create an <a href="https://github.com/smart-data-lake/sdl-visualization/issues" target="_blank" rel="noopener noreferrer">issue</a>.</p>
<p>Soon, we also plan to release the UI "as-a-service". This will further simplify its usage for projects and production use.
Stay tuned!</p>]]></content>
        <author>
            <name>Shasha Jiang</name>
            <uri>https://github.com/dust629</uri>
        </author>
        <author>
            <name>Zacharias Kull</name>
            <uri>https://github.com/zzeekk</uri>
        </author>
        <category label="ui" term="ui"/>
        <category label="data catalog" term="data catalog"/>
        <category label="lineage" term="lineage"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data Mesh with SDL]]></title>
        <id>https://www.smartdatalake.ch/blog/sdl-data-mesh</id>
        <link href="https://www.smartdatalake.ch/blog/sdl-data-mesh"/>
        <updated>2023-09-17T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Build a Data Mesh with SDL]]></summary>
        <content type="html"><![CDATA[<p>Data Mesh is an emerging concept gaining momentum across organizations.
It is often described as a <em>sociotechnical</em> paradigm because a paradigm shift towards Data Mesh does not simply involve
technological changes but also has sociological implications.
As such, discussing a technical framework like Smart Data Lake Builder and analyzing how well it fits the
Data Mesh paradigm can inherently only be part of the whole picture.
Nevertheless, we want to do the exercise here to see how a technological framework can support the adoption.</p>
<p>In this article, we'll explore how the Smart Data Lake Builder aligns with the four principles as outlined by
<a href="https://martinfowler.com/articles/data-mesh-principles.html" target="_blank" rel="noopener noreferrer">Zhamak Dehghani</a>
and assess which key concepts it supports.</p>
<p>Please note that we expect some familiarity with the Data Mesh principles to follow along.
There are plenty of resources (books from <a href="https://www.oreilly.com/library/view/data-mesh/9781492092384/" target="_blank" rel="noopener noreferrer">O'Reilly</a>
and <a href="https://www.manning.com/books/data-mesh-in-action" target="_blank" rel="noopener noreferrer">Manning</a>,
<a href="https://martinfowler.com/articles/data-mesh-principles.html" target="_blank" rel="noopener noreferrer">articles</a>
and <a href="https://www.datamesh-architecture.com/" target="_blank" rel="noopener noreferrer">dedicated websites</a>) if you want to dive deeper into the topic.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="domain-ownership">Domain Ownership<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#domain-ownership" class="hash-link" aria-label="Direct link to Domain Ownership" title="Direct link to Domain Ownership">‚Äã</a></h2>
<p><em>Individual domains or business units are responsible for the data they generate and maintain,
fostering a sense of ownership and accountability.</em></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="scale-out-complexity">Scale Out Complexity<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#scale-out-complexity" class="hash-link" aria-label="Direct link to Scale Out Complexity" title="Direct link to Scale Out Complexity">‚Äã</a></h3>
<p>With a Data Mesh, your data organization can scale out as the centralized data team gets reduced.
With increased usage, you will have more data sources, more consumers, more interfaces and with that,
a large variety of systems and technologies.</p>
<p><em>SDLB</em> comes with a large set of connectors out-of-the-box with the addition of
<a href="https://airbyte.com/connectors?connector-type=Sources" target="_blank" rel="noopener noreferrer">Airbyte</a> source connectors.
Anything missing can be easily implemented as the whole ecosystem is open and builds on open standards.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="continuous-change">Continuous change<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#continuous-change" class="hash-link" aria-label="Direct link to Continuous change" title="Direct link to Continuous change">‚Äã</a></h3>
<p>Data Mesh embraces continuous change in your Data Products.
Changing source systems or additional requirements all require you to adapt (quickly).</p>
<p><em>SDLB</em> is built for changes.
With built-in schema evolution, changing schemas can be handled automatically.
Thanks to the declarative approach, adding additional data objects can be done in minutes
and the dependencies don't need to be defined by hand.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="data-as-a-product">Data as a Product<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#data-as-a-product" class="hash-link" aria-label="Direct link to Data as a Product" title="Direct link to Data as a Product">‚Äã</a></h2>
<p><em>Data is treated as a product, with clear documentation, standardized interfaces,
and well-defined quality measures to ensure its usability and value.</em></p>
<p>It's important to note that in the end, data products can be implemented in different technologies
as long as they adhere to the agreed upon interfaces.</p>
<p>Again, there are different aspects where <em>SDLB</em> can help.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-quality">Data Quality<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#data-quality" class="hash-link" aria-label="Direct link to Data Quality" title="Direct link to Data Quality">‚Äã</a></h3>
<p>A Data Product has well-defined quality measures and should define Service-Level Objectives (SLOs).</p>
<p><em>SDLB</em> builds data quality into your pipelines.
It supports <a href="https://www.smartdatalake.ch/docs/reference/dataQuality#constraints">constraints</a> and
<a href="https://www.smartdatalake.ch/docs/reference/dataQuality#expectations">expectations</a>
that are evaluated each time a pipeline is executed instead of having downstream checks after the execution.</p>
<p><em>SDLB</em> also gathers metrics with every run.
With the metrics gathered, you can detect anomalies like number of records or bytes written.
These are often helpful in finding latent problems in your data pipeline.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="schema-enforcement">Schema enforcement<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#schema-enforcement" class="hash-link" aria-label="Direct link to Schema enforcement" title="Direct link to Schema enforcement">‚Äã</a></h3>
<p>As another aspect of quality, you expect your source system to adhere to the agreed interface.</p>
<p><em>SDLB</em> supports schema validation for all its data objects.
In your configuration, you can (optionally) define a schema and enforce it.
This saves you from surprises if an upstream system suddenly changes the schema of a data object you use.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lineage">Lineage<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#lineage" class="hash-link" aria-label="Direct link to Lineage" title="Direct link to Lineage">‚Äã</a></h3>
<p>To provide transparency about the origin and transformations of data in your Data Product,
a lineage diagram can greatly help.</p>
<p><em>SDLB</em> is a metadata driven framework.
You define Data Objects, you define Actions between them. That's it.
SDLB will figure out the dependencies at runtime but they can also be easily displayed from static configurations.
This is done i.e. in our <a href="https://github.com/smart-data-lake/sdl-visualization" target="_blank" rel="noopener noreferrer">sdl-visualization</a>, see also the <a href="https://ui-demo.smartdatalake.ch/" target="_blank" rel="noopener noreferrer">UI-Demo</a>.
SDL configuration files can be easily displayed and analyzed.
This provides the needed transparency of a Data Product.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="interfaces">Interfaces<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#interfaces" class="hash-link" aria-label="Direct link to Interfaces" title="Direct link to Interfaces">‚Äã</a></h3>
<p><em>SDLB</em> offers many standard Data Objects for all kinds of interfaces.
With the declarative approach and schema enforcement, you can make sure that your data always adheres to the
defined interface specification.</p>
<p>Often in Cloud Environments, we work with Delta or Iceberg Tables today.
These open standards are a powerful tool to share your Data Product, even in multicloud deployments.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="self-serve-infrastructure-platform">Self-Serve infrastructure platform<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#self-serve-infrastructure-platform" class="hash-link" aria-label="Direct link to Self-Serve infrastructure platform" title="Direct link to Self-Serve infrastructure platform">‚Äã</a></h2>
<p><em>Data infrastructure is designed to be self-serve, enabling teams to access and manage their data autonomously without
relying on central data teams.</em></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mobilize-more-developers">Mobilize more developers<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#mobilize-more-developers" class="hash-link" aria-label="Direct link to Mobilize more developers" title="Direct link to Mobilize more developers">‚Äã</a></h3>
<p>With increased usage of the Mesh, you need more developers in your domain teams building Data Products.</p>
<p><em>SDLB</em> has an easy to learn, declarative approach that new users can learn quickly.
It supports SQL, Scala and Python for the definition of transformations so your developers can still
use the language they are most comfortable in.
Complex logic and transformations like historization and deduplication are either built-in or can be extended
in a generic way so your developers can leverage them easily.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="support-your-domain-teams">Support your domain teams<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#support-your-domain-teams" class="hash-link" aria-label="Direct link to Support your domain teams" title="Direct link to Support your domain teams">‚Äã</a></h3>
<p>The self-serve infrastructure should support your domain team to quickly build new Data Products.</p>
<p><em>SDLB</em> is ideal to integrate into DevOps pipelines as all configurations are written in textfile based HOCON format.
Even if you have custom code, it will be written in SQL, Scala or Python which also integrates well
in any existing DevOps environments.
It is designed to support code reviews, automated testing and deployment.
With the right templates, your domain teams can set up new Data Products quickly.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="federated-governance">Federated governance<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#federated-governance" class="hash-link" aria-label="Direct link to Federated governance" title="Direct link to Federated governance">‚Äã</a></h2>
<p><em>Governance of data and its quality is distributed across domains, with a focus on collaboration, standardized practices,
and federated decision-making processes to maintain data integrity and trust.</em></p>
<p>While many of the concepts for a federated governance are on an organizational level and not on a technical level,
<em>SDLB</em> can again help on various points.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-catalogs">Data Catalogs<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#data-catalogs" class="hash-link" aria-label="Direct link to Data Catalogs" title="Direct link to Data Catalogs">‚Äã</a></h3>
<p>When it comes to Data Catalogs, there is no open, agreed upon standard (yet).</p>
<p><em>SDLB</em>'s configuration files are open and can be visualized as mentioned before.
The concepts of Data Objects and Actions are very similar to many Data Catalog notations and
with that, they also integrate nicely in existing solutions.
There is i.e. an exporter to <a href="https://atlas.apache.org/#/" target="_blank" rel="noopener noreferrer">Apache Atlas</a> which also builds the basis of
<a href="https://azure.microsoft.com/en-us/products/purview" target="_blank" rel="noopener noreferrer">Azure Purview</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="encryption">Encryption<a href="https://www.smartdatalake.ch/blog/sdl-data-mesh#encryption" class="hash-link" aria-label="Direct link to Encryption" title="Direct link to Encryption">‚Äã</a></h3>
<p>One aspect with increasing importance is privacy and compliance.
For these topics, it helps to have a unified, generic implementation to prevent your domain teams to each
start their own implementation.</p>
<p><em>SDLB</em> now supports encrypted columns that help i.e. with PII data (Personally Identifiable Information).</p>
<h1>Summary</h1>
<p>There are a lot of aspects to consider when adopting a Data Mesh, many of which are on a technical level.
While you want to give your domain teams the independence to choose the technologies they know best,
you still want a framework that is easy to learn, quick to adapt and open to work with any other Data Product.
This article hopefully gave you a basic overview of how Smart Data Lake Builder can help you.</p>]]></content>
        <author>
            <name>Patrick Gr√ºtter</name>
            <uri>https://github.com/pgruetter</uri>
        </author>
        <category label="data mesh" term="data mesh"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Housekeeping]]></title>
        <id>https://www.smartdatalake.ch/blog/sdl-housekeeping</id>
        <link href="https://www.smartdatalake.ch/blog/sdl-housekeeping"/>
        <updated>2023-06-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Use advanced housekeeping functions to optimize execution]]></summary>
        <content type="html"><![CDATA[<p>In this article, we're taking a look on how we use SDLB's housekeeping features to keep our pipelines running efficiently.</p>
<p>Some DataObject contain housekeeping features of their own.
Make sure you use them!
For example, Delta Tables support commands like <code>optimize</code> and <code>vacuum</code> to optimize storage and delete no longer needed files.</p>
<p>But usually, those commands do not re-organize your partitions.
This is where SDLBs housekeeping mode comes in.</p>
<p>The example is taken from a real world project we've implemented.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="context">Context<a href="https://www.smartdatalake.ch/blog/sdl-housekeeping#context" class="hash-link" aria-label="Direct link to Context" title="Direct link to Context">‚Äã</a></h2>
<p>In this particular project we are collecting data from various reporting units and process it in batches.
The reporting units use an Azure Function to upload JSON files to an Azure Data Lake Storage.
From there, we pick them up for validation and processing.
Reporting units can upload data anytime, but it is only processed a few times a day.</p>
<p>Once validated, we use Delta Lake tables in Databricks to process data through the layers of the Lakehouse.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="partitioning">Partitioning<a href="https://www.smartdatalake.ch/blog/sdl-housekeeping#partitioning" class="hash-link" aria-label="Direct link to Partitioning" title="Direct link to Partitioning">‚Äã</a></h2>
<p>The Azure Function puts uploaded JSON files in a subfolder for each reporting unit.
As such, JSON files are already neatly partitioned by <code>reporting_unit</code>:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">uploadFolder/</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  reporting_unit=rp01</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    file1.json</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    file2.json</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    file3.json</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  reporting_unit=rp02</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    file1.json</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  reporting_unit=rp03</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    fileX.json</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>To read these JSON files, we can therefore use the following DataObject definition:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">import_json {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = JsonFileDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    path = uploadFolder/</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    partitions = [reporting_unit]    </span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>These files are then processed with a <code>FileTransferAction</code> into an output DataObject <code>stage_json</code>:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">stage_json {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = FileTransferAction</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    inputId = import_json</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    outputId = stage_json</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    executionMode = { type = FileIncrementalMoveMode }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    metadata.feed = stage_json</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Each time we start to process uploaded data, we use the <code>run_id</code> to keep track of all batch jobs and version of files delivered.
If you use a state path (see <a href="https://www.smartdatalake.ch/docs/reference/commandLine">commandLine</a>),
your runs automatically generate a <code>run_id</code> to identify the run, and you can use it by extending your DataObject:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">stage_json {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = JsonFileDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    path = processedFolder</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    partitions = [run_id,reporting_unit]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    schema = """reporting_unit string, run_id string, ...."""</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Note how we just use run_id as part of the schema without any further declaration.
Since we use the state path, SDLB uses a <code>run_id</code> internally, and if it's referenced as partition column in a DataObject, processed data get automatically assigned the id of the current run.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="drawback">Drawback<a href="https://www.smartdatalake.ch/blog/sdl-housekeeping#drawback" class="hash-link" aria-label="Direct link to Drawback" title="Direct link to Drawback">‚Äã</a></h2>
<p>Let's take a look at the resulting partition layout of <code>stage_json</code>:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">processedFolder/</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  run_id=1/</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    reporting_unit=rp01/</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      file1.json</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      file2.json</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      file3.json</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    reporting_unit=rp02/</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      file1.json</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    reporting_unit=rp03/</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      fileX.json</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This partition layout has many advantages in our case as we know exactly
during which run a particular file was processed and which reporting unit uploaded it.
In further stages we can clearly work with files that were processed in the current run and not touch any old <code>run_id</code>s.</p>
<p>For this use case, a few things are important to note:</p>
<ul>
<li>Some reporting units don't upload data for days. You end up with only a few reporting_unit partitions per run_id.</li>
<li>File sizes are rather small (&lt; 1 MiB), partition sizes end up very small too.</li>
<li>If you use hourly runs and run 24/7, you end up with 168 partitions per week, plus sub-partitions for reporting units.</li>
<li>Once files are correctly processed, we don't read the uploaded files anymore.
We still keep them as raw files should we ever need to re-process them.</li>
</ul>
<p>The drawback becomes apparent when you have actions working with all partitions, they will become very slow.
Spark doesn't like a lot of small partitions.</p>
<p>To mitigate that, we use SDLB's Housekeeping Feature.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="housekeepingmode">HousekeepingMode<a href="https://www.smartdatalake.ch/blog/sdl-housekeeping#housekeepingmode" class="hash-link" aria-label="Direct link to HousekeepingMode" title="Direct link to HousekeepingMode">‚Äã</a></h2>
<p>If you take a look at DataObject's parameters, you will see a <code>housekeepingMode</code>.
There are two modes available:</p>
<ul>
<li><strong>PartitionArchiveCompactionMode</strong>: to compact / archive partitions</li>
<li><strong>PartitionRetentionMode</strong>: to delete certain partitions completely</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="partitionarchivecompactionmode">PartitionArchiveCompactionMode<a href="https://www.smartdatalake.ch/blog/sdl-housekeeping#partitionarchivecompactionmode" class="hash-link" aria-label="Direct link to PartitionArchiveCompactionMode" title="Direct link to PartitionArchiveCompactionMode">‚Äã</a></h3>
<p>In this mode, you solve two tasks at once:</p>
<ul>
<li>You define how many smaller partitions are aggregated into one larger partition (archive)</li>
<li>Rewrite all files in a partition to combine many small files into larger files (compact)</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="archive">Archive<a href="https://www.smartdatalake.ch/blog/sdl-housekeeping#archive" class="hash-link" aria-label="Direct link to Archive" title="Direct link to Archive">‚Äã</a></h4>
<p>In our example above, we stated that we don't want to alter any input files, so we won't use compaction.
We want to keep them as is (raw data).
But we do want to get rid of all the small partitions after a certain amount of time.
For that, we extend <code>stage_json</code> to include the <code>housekeepingMode</code> with a <code>archivePartitionExpression</code>:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">stage_json {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = JsonFileDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    path = processedFolder</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    partitions = [run_id,reporting_unit]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    schema = """reporting_unit string, run_id string, ...."""</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    housekeepingMode = {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      type = PartitionArchiveCompactionMode</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      archivePartitionExpression = "if( elements.run_id &lt; (runId - 500), map('run_id', (cast(elements.run_id as integer) div 500) * 500, 'reporting_unit', elements.reporting_unit), elements)"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This expression probably needs some explanation:<br>
<!-- -->The Spark SQL expression works with attributes of <a href="https://github.com/smart-data-lake/smart-data-lake/blob/master-spark3/sdl-core/src/main/scala/io/smartdatalake/workflow/dataobject/HousekeepingMode.scala#L136" target="_blank" rel="noopener noreferrer"><code>PartitionExpressionData</code></a>.
In this case we use <code>runId</code> (the current runId) and <code>elements</code> (all partition values as map(string,string)).
It needs to return a map(string,string) to define new partition values.
In our case, it needs to define <code>run_id</code> and <code>reporting_unit</code> because these are the partitions defined in <code>stage_json</code>.</p>
<p>Let's take the expression apart:<br>
<code>if(elements.run_id &lt; (runId - 500), ...</code><br>
<!-- -->Only archive the partition if it's runId is older than 500 run_ids ago.</p>
<p><code>map('run_id', (cast(elements.run_id as integer) div 500) * 500, 'reporting_unit', elements.reporting_unit)</code><br>
<!-- -->Creates the map with the new values for the partitions.
The run_id is floored to the next 500 value, so as example, the new value of run_id 1984 will be 1500 (because integer 1984/500=3, 3*500=1500).<br>
<!-- -->Remember that we need to return all partition values in the map, also the ones we don't want to alter.
For <code>reporting_unit</code> we simply return the existing value <code>elements.reporting_unit</code>.</p>
<p><code>..., elements)</code><br>
<!-- -->This is the else condition and simply returns the existing partition values if there is nothing to archive.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>The housekeeping mode is applied after writing a DataObject.
Keep in mind, that it is executed with every run.</p></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="compaction">Compaction<a href="https://www.smartdatalake.ch/blog/sdl-housekeeping#compaction" class="hash-link" aria-label="Direct link to Compaction" title="Direct link to Compaction">‚Äã</a></h4>
<p>We don't want to compact files in our case.
But from the documentation you can see that compaction works very similarly:<br>
<!-- -->You also work with attributes from <code>PartitionExpressionData</code> but instead of new partition values,
you return a boolean to indicate for each partition if it should be compacted or not.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="partitionretentionmode">PartitionRetentionMode<a href="https://www.smartdatalake.ch/blog/sdl-housekeeping#partitionretentionmode" class="hash-link" aria-label="Direct link to PartitionRetentionMode" title="Direct link to PartitionRetentionMode">‚Äã</a></h3>
<p>Again, not used in our example as we never delete old files.
But if you need to, you define a Spark SQL expression returning a boolean indicating if a partition should be retained or deleted.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">stage_json {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = JsonFileDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    path = processedFolder</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    partitions = [run_id,reporting_unit]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    schema = """reporting_unit string, run_id string, ...."""</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    housekeepingMode = {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      type = PartitionRetentionMode</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      retentionCondition = "elements.run_id &gt; (runId - 500)"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://www.smartdatalake.ch/blog/sdl-housekeeping#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">‚Äã</a></h2>
<p>In our example, we had performance gradually decreasing because Spark had to read more than 10'000 partitions and subpartitions.
Just listing all available partitions, even if you only worked with the most recent one, took a few minutes and these operations added up.</p>
<p>With the housekeeping mode enabled, older partitions continuously get merged into larger partitions containing up to 500 runs.
This brought the duration of list operations back to a few seconds.</p>
<p>The operations are fully automated, no manual intervention is required.</p>]]></content>
        <author>
            <name>Patrick Gr√ºtter</name>
            <uri>https://github.com/pgruetter</uri>
        </author>
        <category label="housekeeping" term="housekeeping"/>
        <category label="performance" term="performance"/>
        <category label="partitioning" term="partitioning"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incremental historization using CDC and Airbyte MSSQL connector]]></title>
        <id>https://www.smartdatalake.ch/blog/sdl-hist</id>
        <link href="https://www.smartdatalake.ch/blog/sdl-hist"/>
        <updated>2022-05-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Tracking Data Changes of MSSQL databases with and without CDC]]></summary>
        <content type="html"><![CDATA[<p>In many cases datasets have no constant live. New data points are created, values changed and data expires. We are interested in keeping track of all these changes.
This article first presents collecting data utilizing <strong>JDBC</strong> and <strong>deduplication on the fly</strong>. Then, a <strong>Change Data Capture</strong> (CDC) enabled (MS)SQL table will be transferred and historized in the data lake using the <strong>Airbyte MS SQL connector</strong> supporting CDC. Methods for reducing the computational and storage efforts are mentioned.</p>
<p>In the <a href="https://www.smartdatalake.ch/docs/getting-started/part-2/historical-data">getting-started -&gt; part2 -&gt; keeping historical data</a> historization is already introduced briefly. Here, we go in slightly more detail and track data originating from an MS SQL database. For the sake of simplicity, the tools and systems are deployed in Podman containers, including SDLB, MSSQL server, as well as the metastore and polynote.</p>
<p>Here, a workflow is modeled, gathering data from a (MS)SQL database to the Data Lake. Therefore, the following steps will be performed:</p>
<ul>
<li>initializing a MS SQL server</li>
<li>importing data into MS SQL table</li>
<li>injecting data into the data lake</li>
<li>modifying data on the SQL server side</li>
<li>re-copy / update data into data lake</li>
</ul>
<p>The data will be inspected and monitored using a Polynote notebook.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="test-case">Test Case<a href="https://www.smartdatalake.ch/blog/sdl-hist#test-case" class="hash-link" aria-label="Direct link to Test Case" title="Direct link to Test Case">‚Äã</a></h2>
<p>As a test case a <a href="https://www.kaggle.com/datasets/datasnaek/chess" target="_blank" rel="noopener noreferrer">Chess Game Dataset</a> is selected. This data is a set of 20058 rows, in total 7MB. This is still faily small, but should be kind of representative.</p>
<p>The dataset will be imported into the SQL server using the <a target="_blank" href="https://www.smartdatalake.ch/assets/files/db_init_chess-f66d528d1f63d688cc156a7fb0e9516c.sql">db_init_chess.sql</a> script, which should be copied into the <code>config</code> directory.</p>
<p>It should be noted that there are a duplicates in the dataset. In the first case, the <em>deduplication</em> will be performed when the data is ported into the data lake (see configuration below). The procedure for table creation and modification is described below.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prerequisites">Prerequisites<a href="https://www.smartdatalake.ch/blog/sdl-hist#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites">‚Äã</a></h2>
<ul>
<li>Podman installation</li>
<li>SDLB with metastore and Polynote by cloning the getting-started example:<!-- -->
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">git clone https://github.com/smart-data-lake/getting-started.git SDL_sql</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  cd SDL_sql</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  unzip part2.additional-files.zip</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<!-- -->:::note "Directory Naming"
Note: The directory name "SDL_sql" will be related to the pod created later and thus to the specified commands below.
:::</li>
<li>Utilizing JDBC to MS SQL server, SDLB required this additional dependency. Therefore, add the following dependency to the <code>pom.xml</code>:<!-- -->
<div class="language-xml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-xml codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&lt;</span><span class="token tag" style="color:rgb(128, 0, 0)">dependency</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">	</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&lt;</span><span class="token tag" style="color:rgb(128, 0, 0)">groupId</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&gt;</span><span class="token plain">com.microsoft.sqlserver</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&lt;/</span><span class="token tag" style="color:rgb(128, 0, 0)">groupId</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">	</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&lt;</span><span class="token tag" style="color:rgb(128, 0, 0)">artifactId</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&gt;</span><span class="token plain">mssql-jdbc</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&lt;/</span><span class="token tag" style="color:rgb(128, 0, 0)">artifactId</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">	</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&lt;</span><span class="token tag" style="color:rgb(128, 0, 0)">version</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&gt;</span><span class="token plain">10.2.0.jre11</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&lt;/</span><span class="token tag" style="color:rgb(128, 0, 0)">version</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&lt;/</span><span class="token tag" style="color:rgb(128, 0, 0)">dependency</span><span class="token tag punctuation" style="color:rgb(4, 81, 165)">&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>build sdl-spark: <code>podman build -t sdl-spark .</code></li>
<li>build the SDLB objects:<!-- -->
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">mkdir .mvnrepo</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">podman run -v ${PWD}:/mnt/project -v ${PWD}/.mvnrepo:/mnt/.mvnrepo maven:3.6.0-jdk-11-slim -- mvn -f /mnt/project/pom.xml "-Dmaven.repo.local=/mnt/.mvnrepo" package</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>download the test case data from <a href="https://www.kaggle.com/datasets/datasnaek/chess/download" target="_blank" rel="noopener noreferrer">Kaggle</a> and unzip into <code>SDL_sql/data</code> directory</li>
<li>copy polynote notebook <a target="_blank" href="https://www.smartdatalake.ch/assets/files/sql_data_monitor-aa012c7e78c37559e44fcc25991e38a9.ipynb">sql_data_monitor.ipynb</a> for later inspection into the <code>polynote/notebooks</code> directory</li>
</ul>
<div class="theme-admonition theme-admonition-danger admonition_xJq3 alert alert--danger"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"></path></svg></span>danger</div><div class="admonitionContent_BuS1"><p>The notebook will only be editable if the permissions are changed to be writable by other users <code>chmod -R 777 polynote/notebooks</code></p></div></div>
<ul>
<li>script for creating table on the SQL server: <a target="_blank" href="https://www.smartdatalake.ch/assets/files/db_init_chess-f66d528d1f63d688cc156a7fb0e9516c.sql">db_init_chess.sql</a> into the <code>config</code> directory</li>
<li>script for modifying the table on the SQL server: <a target="_blank" href="https://www.smartdatalake.ch/assets/files/db_mod_chess-b1cad59e3d4df7cc8a098caf0b9f405e.sql">db_mod_chess.sql</a> into the <code>config</code> directory</li>
<li>a restart script <a target="_blank" href="https://www.smartdatalake.ch/assets/files/restart_databases-dee8cd590e385d628d1f8df38960a7c0.sh">restart_databases.sh</a> is provided to clean and restart from scratch, including: stopping the containers, cleaning databases, freshly starting the containers and initializing the SQL database</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prepare-source-database">Prepare Source Database<a href="https://www.smartdatalake.ch/blog/sdl-hist#prepare-source-database" class="hash-link" aria-label="Direct link to Prepare Source Database" title="Direct link to Prepare Source Database">‚Äã</a></h2>
<ul>
<li>start the pod with the metastore and polynote:<!-- -->
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">mkdir -p data/_metastore</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">./part2/podman-compose.sh #use the script from the getting-started guide</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>start the MS SQL server:<!-- -->
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman run -d --pod sdl_sql --hostname mssqlserver --add-host mssqlserver:127.0.0.1 --name mssql -v ${PWD}/data:/data  -v ${PWD}/config:/config -e "ACCEPT_EULA=Y" -e "SA_PASSWORD=%abcd1234%" mcr.microsoft.com/mssql/server:2017-latest</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>initialize the database:<!-- -->
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman exec -it mssql /opt/mssql-tools/bin/sqlcmd -S mssqlserver -U sa -P '%abcd1234%' -i /config/db_init_chess.sql</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>list the table:<!-- -->
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman exec -it mssql /opt/mssql-tools/bin/sqlcmd -S mssqlserver -U sa -P '%abcd1234%' -Q "SELECT count(*) FROM foobar.dbo.chess"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">podman exec -it mssql /opt/mssql-tools/bin/sqlcmd -S mssqlserver -U sa -P '%abcd1234%' -Q "SELECT * FROM foobar.dbo.chess WHERE id = '079kHDqh'"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<!-- -->This should report 20058 row and we see an example of duplicates.</li>
</ul>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>This could be shortened, by just calling the <a target="_blank" href="https://www.smartdatalake.ch/assets/files/restart_databases-dee8cd590e385d628d1f8df38960a7c0.sh"><code>bash restart_databases.sh</code></a>, which contains the above commands, after stopping the containers and cleaning directories.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="define-workflow">Define Workflow<a href="https://www.smartdatalake.ch/blog/sdl-hist#define-workflow" class="hash-link" aria-label="Direct link to Define Workflow" title="Direct link to Define Workflow">‚Äã</a></h2>
<p>The SDLB configuration file consists of:</p>
<ul>
<li>global settings for the metastore</li>
<li>connection details</li>
<li>data objects and</li>
<li>action</li>
</ul>
<p>Create the <code>config/chess.conf</code> file with the following described sections or copy the <a target="_blank" href="https://www.smartdatalake.ch/assets/files/chess-49c77f7e01ad6fb42540b06f4a93ac75.conf">full script</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="spark-settings">Spark Settings<a href="https://www.smartdatalake.ch/blog/sdl-hist#spark-settings" class="hash-link" aria-label="Direct link to Spark Settings" title="Direct link to Spark Settings">‚Äã</a></h3>
<p>For the metastore, the location, driver and access is defined. Further, the amount of tasks and partitions are limited, due to our reasonable small problem size.</p>
<div class="language-hocon codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-hocon codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">global {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  spark-options {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    "spark.hadoop.javax.jdo.option.ConnectionURL" = "jdbc:derby://metastore:1527/db;create=true"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    "spark.hadoop.javax.jdo.option.ConnectionDriverName" = "org.apache.derby.jdbc.ClientDriver"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    "spark.hadoop.javax.jdo.option.ConnectionUserName" = "sa"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    "spark.hadoop.javax.jdo.option.ConnectionPassword" = "1234"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    "spark.databricks.delta.snapshotPartitions" = 2</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    "spark.sql.shuffle.partitions" = 2</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}  </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="connection">Connection<a href="https://www.smartdatalake.ch/blog/sdl-hist#connection" class="hash-link" aria-label="Direct link to Connection" title="Direct link to Connection">‚Äã</a></h3>
<p>The connection to the local MS SQL server is specified using JDBC settings and clear text authentication specification. In practice, a more secure authentication mode should be selected, e.g. injection by environment variables.</p>
<div class="language-hocon codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-hocon codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">connections {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  localSql {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = JdbcTableConnection</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    url = "jdbc:sqlserver://mssqlserver:1433;encrypt=true;trustServerCertificate=true"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    driver = com.microsoft.sqlserver.jdbc.SQLServerDriver</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    authMode {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      type = BasicAuthMode</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      userVariable = "CLEAR#sa"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      passwordVariable = "CLEAR#%abcd1234%"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dataobjects">DataObjects<a href="https://www.smartdatalake.ch/blog/sdl-hist#dataobjects" class="hash-link" aria-label="Direct link to DataObjects" title="Direct link to DataObjects">‚Äã</a></h3>
<p>In a first place, two DataObjects are defined. The <code>ext-chess</code> defining the external source (the table on the MS SQL server), using JDBC connection. The <code>int-chess</code> defines a delta lake table object as integration layer as targets for our ingestion/historization action.</p>
<div class="language-hocon codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-hocon codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">dataObjects {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  ext-chess {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = JdbcTableDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    connectionId = localSql</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    table = {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      name = "dbo.chess"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      db = "foobar"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  int-chess {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = DeltaLakeTableDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    path = "~{id}"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    table {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      db = "default"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      name = "int_chess"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      primaryKey = [id]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  #...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actions">Actions<a href="https://www.smartdatalake.ch/blog/sdl-hist#actions" class="hash-link" aria-label="Direct link to Actions" title="Direct link to Actions">‚Äã</a></h3>
<p>The <code>histData</code> action specifies the copy and historization of data, by setting the type <strong>HistorizeAction</strong>. Therewith, the incoming data will be joined with the existing data. Each data point gets two additional values: <strong>dl_ts_captured</strong> (time the data is captured in the data lake) and <strong>dl_ts_delimited</strong> (time of invalidation). In case of a data record change, the original row gets invalidated (with the current time) and a new row is added with the current time as capturing value. As long as the data point is active, <strong>dl_ts_delimited</strong> is set to max date `9999-12-31 23:59:59.999999.</p>
<p>The default HistorizationAction algorithm compares all new data with all the existing data, row by row <strong>AND</strong> column by column. Further, the complete joined table is re-written to the data lake.
For DataObjects supporting transactions HistorizeAction provides an algorithm using a merge operation to do the historization. By selecting <code>mergeModeEnable = true</code> the resulting table gets another column with <code>dl_hash</code>. This hash is used to compare rows much more efficiently. Not every column need to be compared, only the hash. Further, already existing rows (identified by the hash), do not need to be re-written. The merge operation applies only the needed inserts and updates to the output DataObject.</p>
<p>Furthermore, a <em>transformer</em> needs to be added to deduplicate the input data, which has duplicated rows with slightly different game times. This is needed as HistorizationAction expects the input to be unique over the primary key of the output DataObject.</p>
<div class="language-hocon codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-hocon codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">actions {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  histData {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = HistorizeAction</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    mergeModeEnable = true</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    inputId = ext-chess</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    outputId = int-chess</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    transformers = [{</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      type = ScalaCodeDfTransformer</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      code = """</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">        import org.apache.spark.sql.{DataFrame, SparkSession}</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">        (session:SparkSession, options:Map[String, String], df:DataFrame, dataObjectId:String) =&gt; {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">          import session.implicits._</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">          df.dropDuplicates(Seq("id"))</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      """</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">   }]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">   metadata {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      feed = download</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  #...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The full configuration looks like <a target="_blank" href="https://www.smartdatalake.ch/assets/files/chess-49c77f7e01ad6fb42540b06f4a93ac75.conf">chess.conf</a>. Note that there are already further DataObjects and Actions defined, described and used later.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="run">Run<a href="https://www.smartdatalake.ch/blog/sdl-hist#run" class="hash-link" aria-label="Direct link to Run" title="Direct link to Run">‚Äã</a></h2>
<p>The Pod with metastore, polynote and the "external" SQL server should already being running. Now the SDLB container is launched within the same POD and the action histData ingests the data into the data lake:</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman run --hostname localhost -e SPARK_LOCAL_HOSTNAME=localhost --rm --pod sdl_sql -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark --config /mnt/config --feed-sel ids:histData</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The data can be inspected using the Polynote notebook (<code>sql_data_monitor.ipynb</code> downloaded above), which can be launched using <a href="http://localhost:8192/notebook/sql_data_monitor.ipynb" target="_blank" rel="noopener noreferrer">Polynote (click here)</a>.</p>
<p>Now, let's assume a change in the source database. Here the <code>victory_status</code> <code>outoftime</code> is renamed to <code>overtime</code>. Furthermore one entry is deleted. Run script using:</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman exec -it mssql /opt/mssql-tools/bin/sqlcmd -S mssqlserver -U sa -P '%abcd1234%' -i /config/db_mod_chess.sql</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Note: 1680 rows were changed + 1 row deleted.</p>
<p>Furthermore, the data lake gets updated using the same command as above:</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman run --hostname localhost -e SPARK_LOCAL_HOSTNAME=localhost --rm --pod sdl_sql -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark --config /mnt/config --feed-sel ids:histData</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In the <a href="http://localhost:8192/notebook/sql_data_monitor.ipynb" target="_blank" rel="noopener noreferrer">Polynote (click here)</a> sql_data_monitor.ipynb, the data lake table can be inspected again. The table and its additional columns are presented, as well as the original and updated rows for a modified row (<em>id = QQ3iIM2V</em>) and the deleted row (<em>id = 009mKOEz</em>).</p>
<p><img loading="lazy" alt="polynote example output" src="https://www.smartdatalake.ch/assets/images/historization_res-dbcab5954c3121455ffdc2dd351ccf93.png" width="911" height="385" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="change-data-capture">Change Data Capture<a href="https://www.smartdatalake.ch/blog/sdl-hist#change-data-capture" class="hash-link" aria-label="Direct link to Change Data Capture" title="Direct link to Change Data Capture">‚Äã</a></h2>
<p>So far the whole table is collected and compared with the existing data lake table.
Various databases support Change Data Capture (CDC). CDC already keeps track of changes similar to the comparision done by the historization feature of SDL.
This can be used to optimize performance of the historization feature, gathering only database updates, reducing the amount of transferred and compared data significantly. Therewith, only data changed (created, modified, or deleted) since the last synchronisation will be read from the database. It needs the status of the last synchronisation to be attached to the successful stream. This <strong>state</strong> is handled in SDLB.</p>
<p>In the following, an example is presented utilizing the MS SQL server CDC feature. Since the implemented JDBC connector cannot handle CDC data, an Airbyte connector is utilized, see <a href="https://docs.airbyte.com/understanding-airbyte/cdc/" target="_blank" rel="noopener noreferrer">Airbyte CDC</a> for details.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="enable-cdc-on-the-sql-server">Enable CDC on the SQL Server<a href="https://www.smartdatalake.ch/blog/sdl-hist#enable-cdc-on-the-sql-server" class="hash-link" aria-label="Direct link to Enable CDC on the SQL Server" title="Direct link to Enable CDC on the SQL Server">‚Äã</a></h3>
<p>First the SQL server need to be configured to have a table <a href="https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/enable-and-disable-change-data-capture-sql-server?view=sql-server-ver15" target="_blank" rel="noopener noreferrer">CDC enabled</a>. Additionally to the used table <em>chess</em>, another table is created with the CDC feature enabled. This table <em>chess_cdc</em> is created by copying and deduplicating the original table. The table creation is already performed in the above introduced and used <a target="_blank" href="https://www.smartdatalake.ch/assets/files/db_init_chess-f66d528d1f63d688cc156a7fb0e9516c.sql">MS SQL initalization</a> script. In practice, further SQL settings should be considered, including proper user and permissions specification, and an adaptation of the retention period (3 days default).</p>
<p>Furthermore, the SQL agent need to be enabled. Therefore, the database need to be restarted (here container is restarted). This is handled in the above mentioned <a target="_blank" href="https://www.smartdatalake.ch/assets/files/restart_databases-dee8cd590e385d628d1f8df38960a7c0.sh">restart_databases.sh</a> script. If not already used above, run:</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">bash restart_databases.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Let's double check the CDC enabled table:</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman exec -it mssql /opt/mssql-tools/bin/sqlcmd -S mssqlserver -U sa -P '%abcd1234%' -Q "SELECT * FROM foobar.cdc.dbo_chess_cdc_CT where id = '079kHDqh'"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Here the first 5 columns are added for the CDC.
It should be noted that CDC additional data vary by implementation from different DB products.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="airbyte-mssql-connector">Airbyte MSSQL connector<a href="https://www.smartdatalake.ch/blog/sdl-hist#airbyte-mssql-connector" class="hash-link" aria-label="Direct link to Airbyte MSSQL connector" title="Direct link to Airbyte MSSQL connector">‚Äã</a></h3>
<p>Since Sparks JDBC data source (used above) does not support CDC data, the connector is changed to <a href="https://docs.airbyte.com/integrations/sources/mssql" target="_blank" rel="noopener noreferrer">Airbyte MSSQL</a>.
In contrast to the article <a href="https://www.smartdatalake.ch/blog/sdl-airbyte">Using Airbyte connector to inspect github data</a>, where Airbyte github connector ran as python script, here the connector runs as a container within the SDLB container.
I targeted a setup using: WSL2, SDLB with podman, and the Airbyte container with podman in the SDLB container. Unfortunately, there are issues with fuse overlay filesystem when using container in container with podman. Therefore, I switched to <a href="https://buildah.io/" target="_blank" rel="noopener noreferrer">buildah</a> in the SDLB container. Unfortunately, the entrypoint is not recognized as expected. As a workaround the following script corrects this.
I guess in another environment, e.g. in a cloud environment or just using docker in docker, this would work out of the box.</p>
<p>Here are my steps to get it running:</p>
<ul>
<li>add buildah and the Airbyte container to the SDLB <a target="_blank" href="https://www.smartdatalake.ch/assets/files/Dockerfile-106772189af8db20db3f24d48737b13f.txt">Dockerfile</a> (just before the entrypoint):<!-- -->
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">RUN apt-get update</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">RUN apt-get -y install buildah</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">RUN echo 'unqualified-search-registries=["docker.io"]' &gt;&gt; /etc/containers/registries.conf</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">RUN buildah --storage-driver=vfs from --name airbyte-mssql docker.io/airbyte/source-mssql</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>rebuild the SDLB container: <code>podman build -t sdl-spark .</code></li>
<li>workaround script to parse all arguments correctly in the Airbyte container while using buildah without the proper entrypoint. Copy <a target="_blank" href="https://www.smartdatalake.ch/assets/files/start_buildah-8928533426fd919b1146d8ddf307201b.sh">start_buildah.sh</a> script into <code>config</code> directory</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sdlb-configuration">SDLB configuration<a href="https://www.smartdatalake.ch/blog/sdl-hist#sdlb-configuration" class="hash-link" aria-label="Direct link to SDLB configuration" title="Direct link to SDLB configuration">‚Äã</a></h3>
<p>Now, the related DataObjects and Action are added to the SDLB configuration <a target="_blank" href="https://www.smartdatalake.ch/assets/files/chess-49c77f7e01ad6fb42540b06f4a93ac75.conf">config/chess.conf</a>.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="dataobject">DataObject<a href="https://www.smartdatalake.ch/blog/sdl-hist#dataobject" class="hash-link" aria-label="Direct link to DataObject" title="Direct link to DataObject">‚Äã</a></h4>
<p>As a source object the AirbyteDataObject is used. Again the MSSQL server with the user credentials are specified. Further, in the streamName the table is selected. The cmd specifies how to run Airbyte. Here the mentioned workaround script is called in the container. As target, again a Delta Lake table is chosen, here called <code>int_chess_cdc</code>. Practically, we would prevent of duplicating tables, here we create a new one to provide the possibility to compare both results.</p>
<div class="language-hocon codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-hocon codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">dataObjects {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ext-chess-cdc {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = AirbyteDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    config = {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      host = "mssqlserver"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      port = 1433</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      database = "foobar"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      username = "sa"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      password = "%abcd1234%"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      replication_method = "CDC"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    },</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    streamName = "chess_cdc",</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    cmd = {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      type = DockerRunScript</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      name = "airbyte_source-mssql"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      image = "airbyte-mssql"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      linuxDockerCmd = "bash /mnt/config/start_buildah.sh"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  int-chess-cdc {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = DeltaLakeTableDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    path = "~{id}"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    table {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      db = "default"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      name = "int_chess_cdc"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      primaryKey = [id]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="action">Action<a href="https://www.smartdatalake.ch/blog/sdl-hist#action" class="hash-link" aria-label="Direct link to Action" title="Direct link to Action">‚Äã</a></h4>
<p>Again the SDLB action <em>HistorizeAction</em> with <em>mergeModeEnabled</em> is selected. Further, the incremental execution mode is enabled. With CDC we get only changed data, which will be merged with the SDL existing table. Further, the column and value need to be specified to identify deleted data points. Depending on the CDC implementation this could be the deletion date (like we have here) or an operation flag mentioning the deletion operation as code, or even differently. SDLB expects a fixed value for deletion. That's why we specify an <code>AdditionalColumnsTransformer</code> transformer to first create an intermediate column mapping any date to <em>true</em>.</p>
<div class="language-hocon codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-hocon codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">actions {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  histDataAirbyte {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = HistorizeAction</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    mergeModeEnable = true</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    executionMode = { type = DataObjectStateIncrementalMode }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    inputId = ext-chess-cdc</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    outputId = int-chess-cdc</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    mergeModeCDCColumn = "cdc_deleted"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    mergeModeCDCDeletedValue = true</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    transformers = [{</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      type = AdditionalColumnsTransformer</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      additionalDerivedColumns = {cdc_deleted = "_ab_cdc_deleted_at is not null"}</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    metadata {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      feed = download</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Finally, SDLB is launched using the same settings as above, now with the feed <code>ids:histDataAirbyte</code> and specifying the <em>state</em> directory and name:</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman run --hostname localhost -e SPARK_LOCAL_HOSTNAME=localhost --rm --pod sdl_sql -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark --config /mnt/config --feed-sel ids:histDataAirbyte --state-path /mnt/data/state -n SDL_sql</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Again the SQL database modification is processed using <a target="_blank" href="https://www.smartdatalake.ch/assets/files/db_mod_chess_cdc-11e5ec52cc1ebb7c34d5ae65ed898038.sql">config/db_mod_chess_cdc.sql</a>:</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman exec -it mssql /opt/mssql-tools/bin/sqlcmd -S mssqlserver -U sa -P '%abcd1234%' -i /config/db_mod_chess_cdc.sql</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>And the SDL update with the same command as just used:</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman run --hostname localhost -e SPARK_LOCAL_HOSTNAME=localhost --rm --pod sdl_sql -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark --config /mnt/config --feed-sel ids:histDataAirbyte --state-path /mnt/data/state -n SDL_sql</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Again the delta lake tables can be inspected using <a href="http://localhost:8192/notebook/sql_data_monitor.ipynb" target="_blank" rel="noopener noreferrer">Polynote (click here)</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">Summary<a href="https://www.smartdatalake.ch/blog/sdl-hist#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary">‚Äã</a></h2>
<p>Smart Data Lake Builder (SDLB) provides a powerful tool to capture data from SQL databases and provides features to track changes, as well as optimized procedures to process Change Data Capture (CDC) data. There are various connectors to interact with SQL databases (e.g. JDBC and Airbyte). Powerful transformers help to handle the data stream within the action, e.g. for deduplication. Furthermore, the join and merge of new data with existing tables, as well as the writing of the data is optimized, reducing the computational an IO efforts with standard HistorizeAction.</p>]]></content>
        <author>
            <name>Mandes Sch√∂nherr</name>
            <uri>https://github.com/mand35</uri>
        </author>
        <category label="historization" term="historization"/>
        <category label="MSSQL" term="MSSQL"/>
        <category label="incremental" term="incremental"/>
        <category label="CDC" term="CDC"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deployment on Databricks]]></title>
        <id>https://www.smartdatalake.ch/blog/sdl-databricks</id>
        <link href="https://www.smartdatalake.ch/blog/sdl-databricks"/>
        <updated>2022-04-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[A brief example of deploying SDL on Databricks]]></summary>
        <content type="html"><![CDATA[<p>Many analytics applications are ported to the cloud, Data Lakes and Lakehouses in the cloud becoming more and more popular.
The <a href="https://databricks.com/" target="_blank" rel="noopener noreferrer">Databricks</a> platform provides an easy accessible and easy configurable way to implement a modern analytics platform.
Smart Data Lake Builder on the other hand provides an open source, portable automation tool to load and transform the data.</p>
<p>In this article the deployment of Smart Data Lake Builder (SDLB) on <a href="https://databricks.com/" target="_blank" rel="noopener noreferrer">Databricks</a> is described.</p>
<p>Before jumping in, it should be mentioned, that there are also many other methods to deploy SDLB in the cloud, e.g. using containers on Azure, Azure Kubernetes Service, Azure Synapse Clusters, Google Dataproc...
The present method provides the advantage of having many aspects taken care of by Databricks like Cluster management, Job scheduling and integrated data science notebooks.
Further, the presented SDLB pipeline is just a simple example, focusing on the integration into Databricks environment.
SDLB provides a wide range of features and its full power is not revealed here.</p>
<p>Let's get started:</p>
<ol>
<li>
<p><a href="https://databricks.com/" target="_blank" rel="noopener noreferrer"><strong>Databricks</strong></a> accounts can be created as <a href="https://databricks.com/try-databricks" target="_blank" rel="noopener noreferrer">Free Trial</a> or as <a href="https://community.databricks.com/s/login/SelfRegister" target="_blank" rel="noopener noreferrer">Community Account</a></p>
<ul>
<li>Account and Workspace creation are described in detail <a href="https://docs.databricks.com/getting-started/account-setup.html" target="_blank" rel="noopener noreferrer">here</a>, there are few hints and modifications presented below.</li>
<li>I selected AWS backend, but there are conceptually no differences to the other providers. If you already have an Azure, AWS or Google Cloud account/subscription this can be used, otherwise you can register a trial subscription there.</li>
</ul>
</li>
<li>
<p><strong>Workspace stack</strong> is created using the Quickstart as described in the documentation. When finished launch the Workspace.</p>
</li>
<li>
<p><strong>Databricks CLI</strong>: for file transfer of configuration files, scripts and data, the <a href="https://docs.databricks.com/dev-tools/cli/index.html" target="_blank" rel="noopener noreferrer">Databricks CLI</a> is installed locally. <strong>Configure</strong> the CLI, using the Workspace URL and in the Workspace "Settings" -&gt; "User Settings" -&gt; "Access tokens" create a new token.</p>
</li>
<li>
<p><strong>Cluster</strong> creation, in the Workspace open the <em>Cluster</em> Creation form.</p>
<ul>
<li>
<p>Spark version: When selecting the <em>Databricks version</em> pay attention to the related Spark version.
This needs to match the Spark version we build SDLB with later. Here, <code>10.4 LTS</code> is selected with <code>Spark 3.2.1</code> and <code>Scala 2.12</code>.
Alternatively, SDLB can be build with a different Spark version, see also <a href="https://www.smartdatalake.ch/docs/architecture">Architecture</a> for supported versions.</p>
</li>
<li>
<p>typesafe library version correction script: the workspace currently includes version 1.2.1 from com.typesafe<!-- -->:config<!-- --> java library.
SDLB relies on functions of a newer version (&gt;1.3.0) of this library.
Thus, we provide a newer version of the com.typesafe<!-- -->:config<!-- --> java library in an initialization script: <em>Advanced options</em> -&gt; <em>Init Scripts</em> specify <code>dbfs:/databricks/scripts/config-install.sh</code></p>
<ul>
<li>Further, the script needs to be created and uploaded. You can use the following script in a local terminal:</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">cat &lt;&lt; EOF &gt;&gt; ./config-install.sh</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">#!/bin/bash</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">wget -O /databricks/jars/-----config-1.4.1.jar https://repo1.maven.org/maven2/com/typesafe/config/1.4.1/config-1.4.1.jar</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">EOF</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">databricks fs mkdirs dbfs:/databricks/scripts</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">databricks fs cp ./config-install.sh dbfs:/databricks/scripts/</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Alternatively, you can also use a Databricks notebook for the script upload by executing the following cell:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">%sh</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">cat &lt;&lt; EOF &gt;&gt; ./config-install.sh</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">#!/bin/bash</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">wget -O /databricks/jars/-----config-1.4.1.jar https://repo1.maven.org/maven2/com/typesafe/config/1.4.1/config-1.4.1.jar</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">EOF</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">mkdir /dbfs/databricks/scripts</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">cp ./config-install.sh /dbfs/databricks/scripts/</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Note: to double-check the library version I ran <code>grep typesafe pom.xml</code> in the <a href="https://github.com/smart-data-lake/smart-data-lake.git" target="_blank" rel="noopener noreferrer">SmartDataLake</a> source</p>
<p>Note: the added <code>-----</code> will ensure that this <code>.jar</code> is preferred before the default Workspace Spark version (which starts with <code>----</code>).
If you are curious you could double-check e.g. with a Workspace Shell Notebook running <code>ls /databricks/jars/*config*</code></p>
</li>
</ul>
</li>
<li>
<p><strong>fat-jar</strong>:
We need to provide the SDLB sources and all required libraries. Therefore, we compile and pack the Scala code into a Jar including the dependencies. We use the <a href="https://github.com/smart-data-lake/getting-started.git" target="_blank" rel="noopener noreferrer">getting-started</a> as dummy project, which itself pulls the SDLB sources.</p>
<ul>
<li>download the <a href="https://github.com/smart-data-lake/getting-started.git" target="_blank" rel="noopener noreferrer">getting-started</a> source and build it with the <code>-P fat-jar</code> profile</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman run -v ${PWD}:/mnt/project -v ${PWD}/.mvnrepo:/mnt/.mvnrepo maven:3.6.0-jdk-11-slim -- mvn -DskipTests  -P fat-jar  -f /mnt/project/pom.xml "-Dmaven.repo.local=/mnt/.mvnrepo" package</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>General build instructions can be found in the <a href="https://www.smartdatalake.ch/docs/getting-started/setup#compile-scala-classes">getting-started</a> documentation.
Therewith, the file <code>target/getting-started-1.0-jar-with-dependencies.jar</code> is created.
The <em>fat-jar</em> profile will include all required dependencies. The profile is defined in the <a href="https://github.com/smart-data-lake/smart-data-lake" target="_blank" rel="noopener noreferrer">smart-data-lake</a> pom.xml.</p>
</li>
<li>
<p>upload files</p>
<ul>
<li>JAR: in the "Workspace" -&gt; your user -&gt; create a directory <code>jars</code> and "import" the library using the link in "(To import a library, such as a jar or egg, click here)" and select the above created fat-jar to upload. As a result the jar will be listed in the Workspace directory.</li>
<li><strong>SDLB application</strong>: As an example a dataset from Airbnb NYC will be downloaded from Github, first written into a CSV file and later partially ported into a table. Therefore, the pipeline is defined first locally in a new file <code>application.conf</code>:</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">dataObjects {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  ext-ab-csv-web {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = WebserviceFileDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    url = "https://raw.githubusercontent.com/adishourya/Airbnb/master/new-york-city-airbnb-open-data/AB_NYC_2019.csv"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    followRedirects = true</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    readTimeoutMs=200000</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  stg-ab {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = CsvFileDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    schema = """id integer, name string, host_id integer, host_name string, neighbourhood_group string, neighbourhood string, latitude double, longitude double, room_type  string, price integer, minimum_nights integer, number_of_reviews integer, last_review timestamp, reviews_per_month double, calculated_host_listings_count integer, availability_365 integer"""</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    path = "file:///dbfs/data/~{id}"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  int-ab {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = DeltaLakeTableDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    path = "~{id}"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    table {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      db = "default"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      name = "int_ab"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      primaryKey = [id]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">actions {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  loadWeb2Csv {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = FileTransferAction</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    inputId = ext-ab-csv-web</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    outputId = stg-ab</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    metadata {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      feed = download</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  loadCsvLoc2Db {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = CopyAction</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    inputId = stg-ab</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    outputId = int-ab</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    transformers = [{</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      type = SQLDfTransformer</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      code = "select id, name, host_id,host_name,neighbourhood_group,neighbourhood,latitude,longitude from stg_ab"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    metadata {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      feed = copy</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>upload using Databricks CLI</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">databricks fs mkdirs dbfs:/conf/</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">databricks fs cp application.conf dbfs:/conf/application.conf</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>
<p><strong>Job creation</strong>:
Here, the Databricks job gets defined, specifying the SDL library and, the entry point and the arguments. Here we specify only the download feed.
Therefore, open in the sidebar <em>Jobs</em> -&gt; <em>Create Job</em>:</p>
<ul>
<li><strong>Type</strong>: <code>JAR</code></li>
<li><strong>Main Class</strong>: <code>io.smartdatalake.app.LocalSmartDataLakeBuilder</code></li>
<li><strong>add</strong> <em>Dependent Libraries</em>: "Workspace" -&gt; select the file previously uploaded "getting-started..." file in the "jars" directory
<img loading="lazy" alt="jar select" src="https://www.smartdatalake.ch/assets/images/add_library-004c4b45355447e0191352a0c3d1e26c.png" width="630" height="652" class="img_ev3q"></li>
<li><strong>Cluster</strong> select the cluster created above with the corrected typesafe library</li>
<li><strong>Parameters</strong>: <code>["-c", "file:///dbfs/conf/", "--feed-sel", "download"]</code>, which specifies the location of the SDLB configuration and selects the feed "download"
<img loading="lazy" alt="download task" src="https://www.smartdatalake.ch/assets/images/download_task-104bd82fd84e5fb593b161282586942e.png" width="589" height="641" class="img_ev3q"></li>
</ul>
</li>
<li>
<p><strong>Launch</strong> the job:
Launch the job.
When finished in the "Runs" section of that job we can verify the successful run status</p>
</li>
<li>
<p><strong>Results</strong>
After running the SDLB pipeline the data should be downloaded into the staging file <code>stg_ab/result.csv</code> and selected parts into the table <code>int_ab</code></p>
<ul>
<li>csv file: in the first step we downloaded the CSV file. This can be verified, e.g. by inspecting the data directory in the Databricks CLI using <code>databricks fs ls dbfs:/data/stg-ab</code> or running in a Workspace shell notebook <code>ls /dbfs/data/stg-ab</code></li>
<li>database: in the second phase specific columns are put into the database. This can be verified in the Workspace -&gt; Data -&gt; default -&gt; int_ab
<img loading="lazy" alt="select table" src="https://www.smartdatalake.ch/assets/images/select_table-7e7e1d0657aff229863bfe5d87b16c2e.png" width="726" height="476" class="img_ev3q">
<img loading="lazy" alt="table" src="https://www.smartdatalake.ch/assets/images/table-f62d6019e5cbbb9c404209061ceb6b80.png" width="1694" height="821" class="img_ev3q"></li>
</ul>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>Note that our final table was defined as <code>DeltaLakeTableDataObject</code>.
With that, Smart Data Lake Builder automatically generates a Delta Lake Table in your Databricks workspace.</p></div></div>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="lessons-learned">Lessons Learned<a href="https://www.smartdatalake.ch/blog/sdl-databricks#lessons-learned" class="hash-link" aria-label="Direct link to Lessons Learned" title="Direct link to Lessons Learned">‚Äã</a></h2>
<p>There are a few steps necessary, including building and uploading SDLB.
Further, we need to be careful with the used versions of the underlying libraries.
With these few steps we can reveal the power of SDLB and Databricks, creating a portable and reproducible pipeline into a Databricks Lakehouse.</p>]]></content>
        <author>
            <name>Mandes Sch√∂nherr</name>
            <uri>https://github.com/mand35</uri>
        </author>
        <category label="Databricks" term="Databricks"/>
        <category label="Cloud" term="Cloud"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Combine Spark and Snowpark to ingest and transform data in one pipeline]]></title>
        <id>https://www.smartdatalake.ch/blog/sdl-snowpark</id>
        <link href="https://www.smartdatalake.ch/blog/sdl-snowpark"/>
        <updated>2022-04-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[An example to create one unified data pipeline that uses Spark to ingest data into Snowflake, and Snowpark to transform data inside Snowflake.]]></summary>
        <content type="html"><![CDATA[<p>This article shows how to create one unified data pipeline that uses Spark to ingest data into Snowflake, and Snowpark to transform data inside Snowflake.</p>
<p>Recent developments in Smart Data Lake Builder (SDLB) included refactorings to integrate alternative execution engines to Spark.
In particular <a href="https://docs.snowflake.com/en/developer-guide/snowpark/index.html" target="_blank" rel="noopener noreferrer">Snowpark</a> integration was implemented, a Spark like DataFrame API for implementing transformations in Snowflake.</p>
<p>Implementing transformations in Snowflake has big performance and cost benefits. And using a DataFrame API is much more powerful than coding in SQL, see also <a href="https://medium.com/towards-data-science/modern-data-stack-which-place-for-spark-8e10365a8772" target="_blank" rel="noopener noreferrer">Modern Data Stack: Which Place for Spark?</a>.</p>
<p>Snowpark is good for transforming data inside Snowflake, but not all data might be located in Snowflake and suitable for Snowflake.
Here it is interesting to use Spark and its many connectors, in particular to ingest and export data.</p>
<p>Combining Spark and Snowpark in a smart data pipeline using a DataFrame API would be the ideal solution.
With the integration of Snowpark as engine in SDLB we created just that.</p>
<p>This blog post will show how to migrate our example data pipeline of the <a href="https://www.smartdatalake.ch/docs/getting-started/setup">Getting Started</a> guide Part 1 to use Spark for ingestion and Snowpark for transformation.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prerequisites">Prerequisites<a href="https://www.smartdatalake.ch/blog/sdl-snowpark#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites">‚Äã</a></h2>
<ul>
<li>Create a Snowflake trial account on <a href="https://signup.snowflake.com/" target="_blank" rel="noopener noreferrer">https://signup.snowflake.com/</a> and note the following connection informations:<!-- -->
<ul>
<li>Account URL (copy by navigating to "Organization" and clicking the link symbol on the right of the account name)</li>
<li>Username</li>
<li>Password</li>
</ul>
</li>
<li>Create database "testdb" in Snowflake: <code>create database testdb;</code></li>
<li>Create schema "testdb.test" in Snowflake: <code>create schema testdb.test;</code></li>
<li>Setup running SDLB docker image with part-1 configuration as described in <a href="https://www.smartdatalake.ch/docs/getting-started/setup">Getting Started</a>
<ul>
<li>build sdl-spark image</li>
<li>copy final application.conf of part-1: <code>cp config/application.conf.part-1-solution config/application.conf</code></li>
<li>run download actions with parameter <code>--feed-sel download</code></li>
<li>run compute actions with parameter <code>--feed-sel compute</code></li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="goal">Goal<a href="https://www.smartdatalake.ch/blog/sdl-snowpark#goal" class="hash-link" aria-label="Direct link to Goal" title="Direct link to Goal">‚Äã</a></h2>
<p>The example of part-1 has the following DataObjects</p>
<p>Staging Layer</p>
<ul>
<li>stg-departures: JsonFileDataObject</li>
<li>stg-airports: CsvFileDataObject</li>
</ul>
<p>Integration Layer</p>
<ul>
<li>int-airports: CsvFileDataObject</li>
</ul>
<p>Business Transformation Layer</p>
<ul>
<li>btl-departures-arrivals-airports: CsvFileDataObject</li>
<li>btl-distances: CsvFileDataObject</li>
</ul>
<p>In this example we will migrate Integration and Business Transformation Layer to Snowflake.
We will use Spark to fill Staging and Integration Layer, and Snowpark for transformation from Integration to Business Transformation Layer.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prepare-the-snowflake-library">Prepare the Snowflake library<a href="https://www.smartdatalake.ch/blog/sdl-snowpark#prepare-the-snowflake-library" class="hash-link" aria-label="Direct link to Prepare the Snowflake library" title="Direct link to Prepare the Snowflake library">‚Äã</a></h2>
<p>First we have add SDLBs Snowflake library to the projects pom.xml dependencies section:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  &lt;dependencies&gt;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ....</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &lt;dependency&gt;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &lt;groupId&gt;io.smartdatalake&lt;/groupId&gt;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &lt;artifactId&gt;sdl-snowflake_${scala.minor.version}&lt;/artifactId&gt;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &lt;version&gt;${project.parent.version}&lt;/version&gt;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &lt;/dependency&gt;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  &lt;/dependencies&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Then SDLB version needs to be updated to version 2.3.0-SNAPSHOT at least in the parent section:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  &lt;parent&gt;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &lt;groupId&gt;io.smartdatalake&lt;/groupId&gt;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &lt;artifactId&gt;sdl-parent&lt;/artifactId&gt;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    &lt;version&gt;2.3.0-SNAPSHOT&lt;/version&gt;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  &lt;/parent&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="define-snowflake-connection">Define Snowflake connection<a href="https://www.smartdatalake.ch/blog/sdl-snowpark#define-snowflake-connection" class="hash-link" aria-label="Direct link to Define Snowflake connection" title="Direct link to Define Snowflake connection">‚Äã</a></h2>
<p>To define the Snowflake connection in config/application.conf, add connections section with connection "sf-con", and fill in informations according to prerequisits:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  connections {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    sf-con {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      type = SnowflakeTableConnection</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      url = "&lt;accountUrl&gt;",</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      warehouse = "COMPUTE_WH",</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      database = "testdb",</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      role = "ACCOUNTADMIN",</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      authMode = {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">        type = BasicAuthMode</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">        userVariable = "CLEAR#&lt;username&gt;"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">        passwordVariable = "CLEAR#&lt;pwd&gt;"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="migrate-dataobjects">Migrate DataObjects<a href="https://www.smartdatalake.ch/blog/sdl-snowpark#migrate-dataobjects" class="hash-link" aria-label="Direct link to Migrate DataObjects" title="Direct link to Migrate DataObjects">‚Äã</a></h2>
<p>Now we can change the DataObject type to SnowflakeTableDataObject and the new Snowflake connection, adding the definition of the table:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  int-airports {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = SnowflakeTableDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    connectionId = sf-con</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    table {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      db = "test"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      name = "int_airports"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  btl-departures-arrivals-airports {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = SnowflakeTableDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    connectionId = sf-con</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    table {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      db = "test"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      name = "btl_departures_arrivals_airports"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  btl-distances {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = SnowflakeTableDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    connectionId = sf-con</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    table {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      db = "test"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      name = "btl_distances"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Note that the attribute <code>db</code> of the SnowflakeTableDataObject should be filled with the schema of the Snowflake table and that this is <em>not</em> the same as the attribute <code>database</code> of SnowflakeTableConnection.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="migrating-actions">Migrating Actions<a href="https://www.smartdatalake.ch/blog/sdl-snowpark#migrating-actions" class="hash-link" aria-label="Direct link to Migrating Actions" title="Direct link to Migrating Actions">‚Äã</a></h2>
<p>The new SDLB version introduced some naming changes:</p>
<ul>
<li>The CustomSparkAction can now also process Snowpark-DataFrames and is therefore renamed to CustomDataFrameAction.</li>
<li>The ScalaClassDfTransformer was specific for Spark. In the new SDLB version there is a specific scala-class DataFrame transformer for Spark and Snowpark, e.g. ScalaClassSparkDfTransformer and ScalaClassSnowparkDfTransformer. And there is even a ScalaClassGenericDfTransformer to implement transformations using a unified API. In our case we will migrate the transformation to use Snowpark and set the type to ScalaClassSnowparkDfTransformer.</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  join-departures-airports {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = CustomSparkAction -&gt; CustomDataFrameAction</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  compute-distances {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    transformers = [{</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      type = ScalaClassDfTransformer -&gt; ScalaClassSnowparkDfTransformer</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>There is no need to change the SQL transformtions of join-departures-airport, as the SQL should run on Snowpark aswell.</p>
<p>On the other hand the ComputeDistanceTransformer was implemented with the Spark DataFrame API. We need to migrate it to Snowpark DataFrame API to run this Action with Snowpark. Luckily the API's are very similar. Often it's sufficient to change the import statement, the class we're extending and the session parameters type:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  import com.snowflake.snowpark.functions._</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  import com.snowflake.snowpark.{DataFrame, Session}</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  import io.smartdatalake.workflow.action.snowflake.customlogic.CustomSnowparkDfTransformer</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  class ComputeDistanceTransformer extends CustomSnowparkDfTransformer {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    def transform(session: Session, options: Map[String, String], df: DataFrame, dataObjectId: String) : DataFrame = {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      ...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>If you have UDFs in your code, it gets trickier. The UDF Code gets serialized to Snowflake, details see <a href="https://docs.snowflake.com/en/developer-guide/snowpark/scala/creating-udfs.html" target="_blank" rel="noopener noreferrer">Snowpark UDFs</a>. Special care must be taken to minimize the scope the UDF is defined in. Thats why we move the function into the companion object.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  object ComputeDistanceTransformer {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    def calculateDistanceInKilometer(depLat: Double, depLng: Double, arrLat: Double, arrLng: Double): Double = {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      val AVERAGE_RADIUS_OF_EARTH_KM = 6371</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      val latDistance = Math.toRadians(depLat - arrLat)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      val lngDistance = Math.toRadians(depLng - arrLng)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      val a = Math.sin(latDistance / 2) * Math.sin(latDistance / 2) + Math.cos(Math.toRadians(depLat)) * Math.cos(Math.toRadians(arrLat)) * Math.sin(lngDistance / 2) * Math.sin(lngDistance / 2)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      val c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a))</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      AVERAGE_RADIUS_OF_EARTH_KM * c</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    def getCalculateDistanceInKilometerUdf(session: Session) = {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      // using only udf(...) function results in "SnowparkClientException: Error Code: 0207, Error message: No default Session found. Use &lt;session&gt;.udf.registerTemporary() to explicitly refer to a session."</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      session.udf.registerTemporary(ComputeDistanceTransformer.calculateDistanceInKilometer _)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Note that we need to pass the Session to a function for registering the UDF. There is an Error 0207 if we use "udf" function (at least in snowpark version 1.2.0).
Finally we need to adapt the call of the UDF as follows:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  df.withColumn("distance", ComputeDistanceTransformer.getCalculateDistanceInKilometerUdf(session)(col("dep_latitude_deg"),col("dep_longitude_deg"),col("arr_latitude_deg"), col("arr_longitude_deg")))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="compile-and-run">Compile and run<a href="https://www.smartdatalake.ch/blog/sdl-snowpark#compile-and-run" class="hash-link" aria-label="Direct link to Compile and run" title="Direct link to Compile and run">‚Äã</a></h2>
<p>Time to see if it works.
Lets build an update SDLB docker image with the updated SDLB version:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  podman build -t sdl-spark .</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Then compile the code with the UDF:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  mkdir .mvnrepo</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  podman run -v ${PWD}:/mnt/project -v ${PWD}/.mvnrepo:/mnt/.mvnrepo maven:3.6.0-jdk-11-slim -- mvn -f /mnt/project/pom.xml "-Dmaven.repo.local=/mnt/.mvnrepo" package</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Download initial data with <code>--feed-sel download</code>:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  podman run --rm -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark:latest --config /mnt/config --feed-sel download</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Compute with <code>--feed-sel compute</code>:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  podman run --rm -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark:latest --config /mnt/config --feed-sel compute</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>If the SDLB run was SUCCESSFUL, you should now see TEST.BTL_DISTANCES table in Snowpark.
To check that Spark was used for Action select-airport-cols and Snowpark for Action compute-distances, look for the following logs, e.g. SnowparkSubFeed for Action~compute-distances:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  INFO  CopyAction - (Action~compute-distances) selected subFeedType SnowparkSubFeed [init-compute-distances]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h1>Engine selection - uncover the magic</h1>
<p>Browsing through the logs it turns out that the Action~join-departures-airports was still executed with Spark (SparkSubFeed)!</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  INFO  CustomDataFrameAction - (Action~join-departures-airports) selected subFeedType SparkSubFeed [init-join-departures-airports]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>An Action determines the engine to use in Init-phase by checking the supported types of inputs, outputs and transformations. In our case we have input DataObject stg-departures which is still a JsonFileDataObject, that can not create a Snowpark-DataFrame. As we would like to execute this join as well in Snowflake with Snowpark for performance reasons, lets create a SnowflakeTableDataObject int-departures and use it as input for Action~join-departures-airports.</p>
<p>Add a DataObject int-departures:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  int-departures {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = SnowflakeTableDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    connectionId = sf-con</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    table {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      db = "test"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      name = "int_departures"</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Add an Action copy-departures:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  copy-departures {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = CopyAction</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    inputId = stg-departures</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    outputId = int-departures</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    metadata {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      feed = compute</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Fix inputs of Action join-departures-airports:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  inputIds = [int-departures, int-airports]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>... and code of the first SQL transformer:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  code = {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    btl-connected-airports = """</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      select int_departures.estdepartureairport, int_departures.estarrivalairport, airports.*</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      from int_departures join int_airports airports on int_departures.estArrivalAirport = airports.ident</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    """</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Compute with Spark and Snowpark again by using <code>--feed-sel compute</code> and browsing the logs, we can see that Action~join-departures-airports was executed with Snowpark:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  (Action~join-departures-airports) selected subFeedType SnowparkSubFeed [init-join-departures-airports]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h1>Summary</h1>
<p>We have seen that its quite easy to migrate SDLB pipelines to use Snowpark instead of Spark, also only partially for selected Actions. SDLB's support of different DataFrame-API-Engines allows to still benefit of all other features of SDLB, like having full early validation over the whole pipeline by checking the schemas needed by Actions later in the pipeline.</p>
<p>Migrating Scala code of custom transformations using Spark DataFrame API needs some adaptions of import statements, but the rest stays mostly 1:1 the same. UDFs are also supported and dont need changes, but there might be surprises regarding data types (Snowparks Variant-type is not the same as Sparks nested datatypes) and deployment of needed libraries. We might investigate that in future blog post.</p>]]></content>
        <author>
            <name>Zach Kull</name>
            <uri>https://www.linkedin.com/in/zacharias-kull-94705886/</uri>
        </author>
        <category label="Snowpark" term="Snowpark"/>
        <category label="Snowflake" term="Snowflake"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Airbyte connector to inspect github data]]></title>
        <id>https://www.smartdatalake.ch/blog/sdl-airbyte</id>
        <link href="https://www.smartdatalake.ch/blog/sdl-airbyte"/>
        <updated>2022-03-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[A short example using Airbyte github connector]]></summary>
        <content type="html"><![CDATA[<p>This article presents the deployment of an <a href="https://airbyte.com/" target="_blank" rel="noopener noreferrer">Airbyte Connector</a> with Smart Data Lake Builder (SDLB).
In particular the <a href="https://docs.airbyte.com/integrations/sources/github" target="_blank" rel="noopener noreferrer">github connector</a> is implemented using the python sources.</p>
<p>Airbyte is a framework to sync data from a variety of sources (APIs and databases) into data warehouses and data lakes.
In this example an Airbyte connector is utilized to stream data into Smart Data Lake (SDL).
Therefore, the <a href="http://smartdatalake.ch/json-schema-viewer/index.html#viewer-page?v=2-2" target="_blank" rel="noopener noreferrer">Airbyte DataObject</a> is used and will be configured.
The general <a href="https://docs.airbyte.com/understanding-airbyte/airbyte-specification#source" target="_blank" rel="noopener noreferrer">Airbyte connector handling</a> is implemented in SDL, which includes the 4 main steps:</p>
<ul>
<li><code>spec</code>: receiving the specification of the connector</li>
<li><code>check</code>: validating the specified configuration</li>
<li><code>discover</code>: gather a catalog of available streams and its schemas</li>
<li><code>read</code>: collect the actual data</li>
</ul>
<p>The actual connector is not provided in the SDL repository and needs to be obtained from the <a href="https://github.com/airbytehq/airbyte" target="_blank" rel="noopener noreferrer">Airbyte repository</a>. Besides the <a href="https://docs.airbyte.com/integrations" target="_blank" rel="noopener noreferrer">list of existing connectors</a>, custom connectors could be implemented in Python or Javascript.</p>
<p>The following description builds on top of the example setup from the <a href="https://www.smartdatalake.ch/docs/getting-started/setup">getting-started</a> guide, using <a href="https://docs.podman.io/" target="_blank" rel="noopener noreferrer">Podman</a> as container engine within a <a href="https://docs.microsoft.com/en-us/windows/wsl/install" target="_blank" rel="noopener noreferrer">WSL</a> Ubuntu image.</p>
<p>The <a href="https://docs.airbyte.com/integrations/sources/github" target="_blank" rel="noopener noreferrer">github connector</a> is utilized to gather data about a specific repository.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prerequisites">Prerequisites<a href="https://www.smartdatalake.ch/blog/sdl-airbyte#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites">‚Äã</a></h2>
<p>After downloading and installing all necessary packages, the connector is briefly tested:</p>
<ul>
<li>Python</li>
<li><a href="https://www.smartdatalake.ch/docs/getting-started/troubleshooting/docker-on-windows">Podman</a> or <a href="https://www.docker.com/get-started" target="_blank" rel="noopener noreferrer">Docker</a></li>
<li><a href="https://github.com/smart-data-lake/getting-started/archive/refs/heads/master.zip" target="_blank" rel="noopener noreferrer">SDL example</a>, download and unpack:<!-- -->
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">git clone https://github.com/smart-data-lake/getting-started.git SDL_airbyte</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">cd SDL_airbyte</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>download the <a href="https://github.com/airbytehq/airbyte" target="_blank" rel="noopener noreferrer">Airbyte repository</a>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">git clone https://github.com/airbytehq/airbyte.git</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<!-- -->Alternatively, only the target connector can be downloaded:<!-- -->
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">svn checkout https://github.com/airbytehq/airbyte/trunk/airbyte-integrations/connectors/source-github</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<!-- -->Here the Airbyte <code>airbyte/airbyte-integrations/connectors/source-github/</code> directory is copied into the <code>SDL_airbyte</code> directory for handy calling the connector.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="optional-inspect-the-connector-specification">[Optional] Inspect the connector specification<a href="https://www.smartdatalake.ch/blog/sdl-airbyte#optional-inspect-the-connector-specification" class="hash-link" aria-label="Direct link to [Optional] Inspect the connector specification" title="Direct link to [Optional] Inspect the connector specification">‚Äã</a></h2>
<p>The first connector command <code>spec</code> provides the connector specification. This is the basis to create a connector configuration. To run the connector as is, the Python <code>airbyte-cdk</code> package needs to be installed and the connector can be launched:</p>
<ul>
<li>Install Python airbyte-cdk: <code>pip install airbyte_cdk</code></li>
<li>try the connector:<!-- -->
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">cd SDL_airbyte</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">python source_github/main.py spec | python -m json.tool</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<!-- -->This provides a <a target="_blank" href="https://www.smartdatalake.ch/assets/files/github_spec_out-e78cbc05ed4f12e8414017c3698a8edb.json">JSON string</a> with the connector specification. The fields listed under <code>properties</code> are relevant for the configuration (compare with the configuration  used later).</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="configuration">Configuration<a href="https://www.smartdatalake.ch/blog/sdl-airbyte#configuration" class="hash-link" aria-label="Direct link to Configuration" title="Direct link to Configuration">‚Äã</a></h2>
<p>To launch Smart Data Lake Builder (SDLB) with the Airbyte connector the following needs to be modified:</p>
<ul>
<li>
<p>add the Airbyte <em><strong>DataObject</strong></em> with its configuration to the <code>config/application.conf</code>:</p>
<div class="language-Python language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">dataObjects </span><span class="token punctuation" style="color:rgb(4, 81, 165)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  ext</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">commits </span><span class="token punctuation" style="color:rgb(4, 81, 165)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><span class="token builtin" style="color:rgb(0, 112, 193)">type</span><span class="token plain"> </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> AirbyteDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    config </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(4, 81, 165)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      </span><span class="token string" style="color:rgb(163, 21, 21)">"credentials"</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(4, 81, 165)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">        </span><span class="token string" style="color:rgb(163, 21, 21)">"personal_access_token"</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">"&lt;yourPersonalAccessToken&gt;"</span><span class="token plain"> </span><span class="token comment" style="color:rgb(0, 128, 0)">### enter your personal access token here</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      </span><span class="token punctuation" style="color:rgb(4, 81, 165)">}</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      </span><span class="token string" style="color:rgb(163, 21, 21)">"repository"</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">"smart-data-lake/smart-data-lake"</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      </span><span class="token string" style="color:rgb(163, 21, 21)">"start_date"</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">"2021-02-01T00:00:00Z"</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      </span><span class="token string" style="color:rgb(163, 21, 21)">"branch"</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">"documentation develop-spark3 develop-spark2"</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      </span><span class="token string" style="color:rgb(163, 21, 21)">"page_size_for_large_streams"</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> </span><span class="token number" style="color:rgb(9, 134, 88)">100</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(4, 81, 165)">}</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    streamName </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">"commits"</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    cmd </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(4, 81, 165)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      </span><span class="token builtin" style="color:rgb(0, 112, 193)">type</span><span class="token plain"> </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> CmdScript</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      name </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">"airbyte_connector_github"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      linuxCmd </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">"python3 /mnt/source-github/main.py"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(4, 81, 165)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(4, 81, 165)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  stg</span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token plain">commits </span><span class="token punctuation" style="color:rgb(4, 81, 165)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">   </span><span class="token builtin" style="color:rgb(0, 112, 193)">type</span><span class="token plain"> </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> DeltaLakeTableDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">   path </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">"~{id}"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">   table </span><span class="token punctuation" style="color:rgb(4, 81, 165)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    db </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">"default"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    name </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">"stg_commits"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    primaryKey </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token plain">created_at</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(4, 81, 165)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(4, 81, 165)">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Note the options set for <code>ext-commits</code> which define the Airbyte connector settings.
While the <code>config</code> varies from connector to connector, the remaining fields are SDL specific.
The <code>streamName</code> selects the stream, exactly one.
If multiple streams should be collected, multiple dataObjects need to be defined.
In <code>linuxCmd</code> the actual connector script is called.
In our case we will mount the connector directory into the SDL container.</p>
</li>
<li>
<p>also add the definition of the data stream <em><strong>action</strong></em> to pipe the coming data stream into a <code>DeltaLakeTableDataObject</code>:</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">  actions {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    download-commits {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      type = CopyAction</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      inputId = ext-commits</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      outputId = stg-commits</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      metadata {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">        feed = download</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>
<p>Since Airbyte will be called as Python script in the sdl container, we need to (re-)build the container with Python support and the Python <code>airbyte-cdk</code> package.
Therefore, in the Dockerfile we add:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">RUN \</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">apt update &amp;&amp; \</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">apt --assume-yes install python3 python3-pip &amp;&amp; \</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">pip3 install airbyte-cdk~=0.1.25</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>and rebuild</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman build . -t sdl-spark</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
</ul>
<p>Now we are ready to go. My full <a target="_blank" href="https://www.smartdatalake.ch/assets/files/application-b6a5a6494622e5ff40741395d829f558.conf">SDLB config file</a> additionally includes the pull-request stream.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="run-and-inspect-results">Run and inspect results<a href="https://www.smartdatalake.ch/blog/sdl-airbyte#run-and-inspect-results" class="hash-link" aria-label="Direct link to Run and inspect results" title="Direct link to Run and inspect results">‚Äã</a></h2>
<p>Since the data will be streamed into a <code>DeltaLakeTableDataObject</code>, the metastore container is necessary. Further, we aim to inspect the data using the Polynote notebook. Thus, first these containers are launched using (in the SDL example base directory):</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">./part2/podman-compose.sh #use the script from the getting-started guide</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">podman pod ls</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>With the second command we can verify the pod name and both running containers in it (should be three including the infra container).</p>
<p>Then, the SDLB can be launched using the additional option to mount the Airbyte connector directory:</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman run --hostname localhost --rm --pod sdl_airbyte -v ${PWD}/source-github/:/mnt/source-github -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark:latest --config /mnt/config --feed-sel download</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The output presents the successful run of the workflow:</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">2022-03-16 07:54:03 INFO  ActionDAGRun$ActionEventListener - Action~download-commits[CopyAction]: Exec succeeded [dag-1-80]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">2022-03-16 07:54:03 INFO  ActionDAGRun$ - exec SUCCEEDED for dag 1:</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 ‚îÇstart‚îÇ</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                     ‚îÇ</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                     v</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"> ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"> ‚îÇdownload-commits SUCCEEDED PT11.686865S‚îÇ</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"> ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     [main]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">2022-03-16 07:54:03 INFO  LocalSmartDataLakeBuilder$ - LocalSmartDataLakeBuilder finished successfully: SUCCEEDED=1 [main]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">2022-03-16 07:54:03 INFO  SparkUI - Stopped Spark web UI at http://localhost:4040 [shutdown-hook-0]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Launching Polynote <code>localhost:8192</code> in the browser, we can inspect data and develop further workflows. Here an example, where the commits are listed, which were committed in the name of someone else, excluding the web-flow. See <a target="_blank" href="https://www.smartdatalake.ch/assets/files/SelectingData-fc913585bab1ef41a6b1f32ee50d5adb.ipynb">Polynote Notebook</a>
<img loading="lazy" alt="polynote example" src="https://www.smartdatalake.ch/assets/images/polynote_commits-0877fa6cab02c46db63471b8220af7ea.png" width="1018" height="810" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">Summary<a href="https://www.smartdatalake.ch/blog/sdl-airbyte#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary">‚Äã</a></h2>
<p>The Airbyte connectors provide easy access to a variety of data sources. The connectors can be utilized in SDLB with just a few settings. This also works great for more complex interfaces.</p>]]></content>
        <author>
            <name>Mandes Sch√∂nherr</name>
            <uri>https://github.com/mand35</uri>
        </author>
        <category label="Airbyte" term="Airbyte"/>
        <category label="Connector" term="Connector"/>
    </entry>
</feed>