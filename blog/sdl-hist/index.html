<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.15">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Smart Data Lake Builder RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Smart Data Lake Builder Atom Feed"><title data-react-helmet="true">Incremental historization using CDC and Airbyte MSSQL connector | Smart Data Lake Builder</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://www.smartdatalake.ch/blog/sdl-hist"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" property="og:title" content="Incremental historization using CDC and Airbyte MSSQL connector | Smart Data Lake Builder"><meta data-react-helmet="true" name="description" content="Tracking Data Changes of MSSQL databases with and without CDC"><meta data-react-helmet="true" property="og:description" content="Tracking Data Changes of MSSQL databases with and without CDC"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="article:published_time" content="2022-05-11T00:00:00.000Z"><meta data-react-helmet="true" property="article:author" content="https://github.com/mand35"><meta data-react-helmet="true" property="article:tag" content="historization,MSSQL,incremental,CDC"><link data-react-helmet="true" rel="icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://www.smartdatalake.ch/blog/sdl-hist"><link data-react-helmet="true" rel="alternate" href="https://www.smartdatalake.ch/blog/sdl-hist" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://www.smartdatalake.ch/blog/sdl-hist" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.dc3a20c1.css">
<link rel="preload" href="/assets/js/runtime~main.20ecc8fe.js" as="script">
<link rel="preload" href="/assets/js/main.c97093ac.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/sdl_logo.png" alt="Smart Data Lake Logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/sdl_logo.png" alt="Smart Data Lake Logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">Smart Data Lake</b></a><a class="navbar__item navbar__link" href="/docs/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/smart-data-lake/smart-data-lake" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_Pssr toggle_TdHA toggleDisabled_jDku"><div class="toggleTrack_SSoT" role="button" tabindex="-1"><div class="toggleTrackCheck_XobZ"><span class="toggleIcon_eZtF">ðŸŒœ</span></div><div class="toggleTrackX_YkSC"><span class="toggleIcon_eZtF">ðŸŒž</span></div><div class="toggleTrackThumb_uRm4"></div></div><input type="checkbox" class="toggleScreenReader_JnkT" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_a9qW thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_uKok margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Kvuv"><li class="sidebarItem_CF0Q"><a aria-current="page" class="sidebarItemLink_miNk sidebarItemLinkActive_RRTD" href="/blog/sdl-hist">Incremental historization using CDC and Airbyte MSSQL connector</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/sdl-databricks">Deployment on Databricks</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/sdl-snowpark">Combine Spark and Snowpark to ingest and transform data in one pipeline</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/sdl-airbyte">Using Airbyte connector to inspect github data</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_rzP5" itemprop="headline">Incremental historization using CDC and Airbyte MSSQL connector</h1><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2022-05-11T00:00:00.000Z" itemprop="datePublished">May 11, 2022</time> Â· <!-- -->13 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/mand35" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Mandes SchÃ¶nherr</span></a></div><small class="avatar__subtitle" itemprop="description">Dr.sc.nat.</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p>In many cases datasets have no constant live. New data points are created, values changed and data expires. We are interested in keeping track of all these changes.
This article first presents collecting data utilizing <strong>JDBC</strong> and <strong>deduplication on the fly</strong>. Then, a <strong>Change Data Capture</strong> (CDC) enabled (MS)SQL table will be transferred and historized in the data lake using the <strong>Airbyte MS SQL connector</strong> supporting CDC. Methods for reducing the computational and storage efforts are mentioned.</p><p>In the <a href="/docs/getting-started/part-2/historical-data">getting-started -&gt; part2 -&gt; keeping historical data</a> historization is already introduced briefly. Here, we go in slightly more detail and track data originating from an MS SQL database. For the sake of simplicity, the tools and systems are deployed in Podman containers, including SDLB, MSSQL server, as well as the metastore and polynote. </p><p>Here, a workflow is modeled, gathering data from a (MS)SQL database to the Data Lake. Therefore, the following steps will be performed:</p><ul><li>initializing a MS SQL server</li><li>importing data into MS SQL table</li><li>injecting data into the data lake</li><li>modifying data on the SQL server side</li><li>re-copy / update data into data lake</li></ul><p>The data will be inspected and monitored using a Polynote notebook.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="test-case">Test Case<a class="hash-link" href="#test-case" title="Direct link to heading">â€‹</a></h2><p>As a test case a <a href="https://www.kaggle.com/datasets/datasnaek/chess" target="_blank" rel="noopener noreferrer">Chess Game Dataset</a> is selected. This data is a set of 20058 rows, in total 7MB. This is still faily small, but should be kind of representative.</p><p>The dataset will be imported into the SQL server using the <a target="_blank" href="/assets/files/db_init_chess-f66d528d1f63d688cc156a7fb0e9516c.sql">db_init_chess.sql</a> script, which should be copied into the <code>config</code> directory. </p><p>It should be noted that there are a duplicates in the dataset. In the first case, the <em>deduplication</em> will be performed when the data is ported into the data lake (see configuration below). The procedure for table creation and modification is described below. </p><h2 class="anchor anchorWithStickyNavbar_mojV" id="prerequisites">Prerequisites<a class="hash-link" href="#prerequisites" title="Direct link to heading">â€‹</a></h2><ul><li>Podman installation</li><li>SDLB with metastore and Polynote by cloning the getting-started example: <div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/smart-data-lake/getting-started.git SDL_sql</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd SDL_sql</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">unzip part2.additional-files.zip</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="admonition admonition-note alert alert--secondary"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>&quot;Directory Naming&quot;</h5></div><div class="admonition-content"><p>Note: The directory name &quot;SDL_sql&quot; will be related to the pod created later and thus to the specified commands below.</p></div></div></li><li>Utilizing JDBC to MS SQL server, SDLB required this additional dependency. Therefore, add the following dependency to the <code>pom.xml</code>:<div class="codeBlockContainer_I0IT language-xml theme-code-block"><div class="codeBlockContent_wNvx xml"><pre tabindex="0" class="prism-code language-xml codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token tag punctuation" style="color:#393A34">&lt;</span><span class="token tag" style="color:#00009f">dependency</span><span class="token tag punctuation" style="color:#393A34">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token tag punctuation" style="color:#393A34">&lt;</span><span class="token tag" style="color:#00009f">groupId</span><span class="token tag punctuation" style="color:#393A34">&gt;</span><span class="token plain">com.microsoft.sqlserver</span><span class="token tag punctuation" style="color:#393A34">&lt;/</span><span class="token tag" style="color:#00009f">groupId</span><span class="token tag punctuation" style="color:#393A34">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token tag punctuation" style="color:#393A34">&lt;</span><span class="token tag" style="color:#00009f">artifactId</span><span class="token tag punctuation" style="color:#393A34">&gt;</span><span class="token plain">mssql-jdbc</span><span class="token tag punctuation" style="color:#393A34">&lt;/</span><span class="token tag" style="color:#00009f">artifactId</span><span class="token tag punctuation" style="color:#393A34">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token tag punctuation" style="color:#393A34">&lt;</span><span class="token tag" style="color:#00009f">version</span><span class="token tag punctuation" style="color:#393A34">&gt;</span><span class="token plain">10.2.0.jre11</span><span class="token tag punctuation" style="color:#393A34">&lt;/</span><span class="token tag" style="color:#00009f">version</span><span class="token tag punctuation" style="color:#393A34">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token tag punctuation" style="color:#393A34">&lt;/</span><span class="token tag" style="color:#00009f">dependency</span><span class="token tag punctuation" style="color:#393A34">&gt;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div></li><li>build sdl-spark: <code>podman build -t sdl-spark .</code></li><li>build the SDLB objects: <div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">mkdir .mvnrepo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">podman run -v ${PWD}:/mnt/project -v ${PWD}/.mvnrepo:/mnt/.mvnrepo maven:3.6.0-jdk-11-slim -- mvn -f /mnt/project/pom.xml &quot;-Dmaven.repo.local=/mnt/.mvnrepo&quot; package</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div></li><li>download the test case data from <a href="https://www.kaggle.com/datasets/datasnaek/chess/download" target="_blank" rel="noopener noreferrer">Kaggle</a> and unzip into <code>SDL_sql/data</code> directory</li><li>copy polynote notebook <a target="_blank" href="/assets/files/sql_data_monitor-aa012c7e78c37559e44fcc25991e38a9.ipynb">sql_data_monitor.ipynb</a> for later inspection into the <code>polynote/notebooks</code> directory</li></ul><div class="admonition admonition-warning alert alert--danger"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="16" viewBox="0 0 12 16"><path fill-rule="evenodd" d="M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"></path></svg></span>warning</h5></div><div class="admonition-content"><p>  The notebook will only be editable if the permissions are changed to be writable by other users <code>chmod -R 777 polynote/notebooks</code></p></div></div><ul><li>script for creating table on the SQL server: <a target="_blank" href="/assets/files/db_init_chess-f66d528d1f63d688cc156a7fb0e9516c.sql">db_init_chess.sql</a> into the <code>config</code> directory</li><li>script for modifying the table on the SQL server: <a target="_blank" href="/assets/files/db_mod_chess-b1cad59e3d4df7cc8a098caf0b9f405e.sql">db_mod_chess.sql</a> into the <code>config</code> directory</li><li>a restart script <a target="_blank" href="/assets/files/restart_databases-ab3a7ace9c7c469008f6f050a44c4c89.sh">restart_databases.sh</a> is provided to clean and restart from scratch, including: stopping the containers, cleaning databases, freshly starting the containers and initializing the SQL database </li></ul><h2 class="anchor anchorWithStickyNavbar_mojV" id="prepare-source-database">Prepare Source Database<a class="hash-link" href="#prepare-source-database" title="Direct link to heading">â€‹</a></h2><ul><li>start the pod with the metastore and polynote: <div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">mkdir -p data/_metastore</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">podman-compose up</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div></li><li>start the MS SQL server: <div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">podman run -d --pod sdl_sql --hostname mssqlserver --add-host mssqlserver:127.0.0.1 --name mssql -v ${PWD}/data:/data  -v ${PWD}/config:/config -e &quot;ACCEPT_EULA=Y&quot; -e &quot;SA_PASSWORD=%abcd1234%&quot; mcr.microsoft.com/mssql/server:2017-latest</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div></li><li>initialize the database: <div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">podman exec -it mssql /opt/mssql-tools/bin/sqlcmd -S mssqlserver -U sa -P &#x27;%abcd1234%&#x27; -i /config/db_init_chess.sql</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div></li><li>list the table: <div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">podman exec -it mssql /opt/mssql-tools/bin/sqlcmd -S mssqlserver -U sa -P &#x27;%abcd1234%&#x27; -Q &quot;SELECT count(*) FROM foobar.dbo.chess&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">podman exec -it mssql /opt/mssql-tools/bin/sqlcmd -S mssqlserver -U sa -P &#x27;%abcd1234%&#x27; -Q &quot;SELECT * FROM foobar.dbo.chess WHERE id = &#x27;079kHDqh&#x27;&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div>This should report 20058 row and we see an example of duplicates.</li></ul><div class="admonition admonition-note alert alert--secondary"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></div><div class="admonition-content"><p>  This could be shortened, by just calling the <a target="_blank" href="/assets/files/restart_databases-ab3a7ace9c7c469008f6f050a44c4c89.sh"><code>bash restart_databases.sh</code></a>, which contains the above commands, after stopping the containers and cleaning directories. </p></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="define-workflow">Define Workflow<a class="hash-link" href="#define-workflow" title="Direct link to heading">â€‹</a></h2><p>The SDLB configuration file consists of:</p><ul><li>global settings for the metastore </li><li>connection details </li><li>data objects and</li><li>action</li></ul><p>Create the <code>config/chess.conf</code> file with the following described sections or copy the <a target="_blank" href="/assets/files/chess-49c77f7e01ad6fb42540b06f4a93ac75.conf">full script</a>.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="spark-settings">Spark Settings<a class="hash-link" href="#spark-settings" title="Direct link to heading">â€‹</a></h3><p>For the metastore, the location, driver and access is defined. Further, the amount of tasks and partitions are limited, due to our reasonable small problem size.</p><div class="codeBlockContainer_I0IT language-hocon theme-code-block"><div class="codeBlockContent_wNvx hocon"><pre tabindex="0" class="prism-code language-hocon codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">global {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  spark-options {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;spark.hadoop.javax.jdo.option.ConnectionURL&quot; = &quot;jdbc:derby://metastore:1527/db;create=true&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;spark.hadoop.javax.jdo.option.ConnectionDriverName&quot; = &quot;org.apache.derby.jdbc.ClientDriver&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;spark.hadoop.javax.jdo.option.ConnectionUserName&quot; = &quot;sa&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;spark.hadoop.javax.jdo.option.ConnectionPassword&quot; = &quot;1234&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;spark.databricks.delta.snapshotPartitions&quot; = 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;spark.sql.shuffle.partitions&quot; = 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}  </span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="connection">Connection<a class="hash-link" href="#connection" title="Direct link to heading">â€‹</a></h3><p>The connection to the local MS SQL server is specified using JDBC settings and clear text authentication specification. In practice, a more secure authentication mode should be selected, e.g. injection by environment variables. </p><div class="codeBlockContainer_I0IT language-hocon theme-code-block"><div class="codeBlockContent_wNvx hocon"><pre tabindex="0" class="prism-code language-hocon codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">connections {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  localSql {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    type = JdbcTableConnection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    url = &quot;jdbc:sqlserver://mssqlserver:1433;encrypt=true;trustServerCertificate=true&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    driver = com.microsoft.sqlserver.jdbc.SQLServerDriver</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    authMode {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      type = BasicAuthMode</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      userVariable = &quot;CLEAR#sa&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      passwordVariable = &quot;CLEAR#%abcd1234%&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="dataobjects">DataObjects<a class="hash-link" href="#dataobjects" title="Direct link to heading">â€‹</a></h3><p>In a first place, two dataObjects are defined. The <code>ext-chess</code> defining the external source (the table on the MS SQL server), using JDBC connection. The <code>int-chess</code> defines a delta lake table object as integration layer as targets for our ingestion/historization action. </p><div class="codeBlockContainer_I0IT language-hocon theme-code-block"><div class="codeBlockContent_wNvx hocon"><pre tabindex="0" class="prism-code language-hocon codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">dataObjects {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ext-chess {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    type = JdbcTableDataObject</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    connectionId = localSql</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    table = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      name = &quot;dbo.chess&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      db = &quot;foobar&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  int-chess {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    type = DeltaLakeTableDataObject</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    path = &quot;~{id}&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    table {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      db = &quot;default&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      name = &quot;int_chess&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      primaryKey = [id]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  #...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="actions">Actions<a class="hash-link" href="#actions" title="Direct link to heading">â€‹</a></h3><p>The <code>histData</code> action specifies the copy and historization of data, by setting the type <strong>HistorizeAction</strong>. Therewith, the incoming data will be joined with the existing data. Each data point gets two additional values: <strong>dl_ts_captured</strong> (time the data is captured in the data lake) and <strong>dl_ts_delimited</strong> (time of invalidation). In case of a data record change, the original row gets invalidated (with the current time) and a new row is added with the current time as capturing value. As long as the data point is active, <strong>dl_ts_delimited</strong> is set to max date `9999-12-31 23:59:59.999999.</p><p>The default HistorizationAction algorithm compares all new data with all the existing data, row by row <strong>AND</strong> column by column. Further, the complete joined table is re-written to the data lake.
For DataObjects supporting transactions HistorizeAction provides an algorithm using a merge operation to do the historization. By selecting <code>mergeModeEnable = true</code> the resulting table gets another column with <code>dl_hash</code>. This hash is used to compare rows much more efficiently. Not every column need to be compared, only the hash. Further, already existing rows (identified by the hash), do not need to be re-written. The merge operation applies only the needed inserts and updates to the output DataObject.</p><p>Furthermore, a <em>transformer</em> needs to be added to deduplicate the input data, which has duplicated rows with slightly different game times. This is needed as HistorizationAction expects the input to be unique over the primary key of the output DataObject.</p><div class="codeBlockContainer_I0IT language-hocon theme-code-block"><div class="codeBlockContent_wNvx hocon"><pre tabindex="0" class="prism-code language-hocon codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">actions {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  histData {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    type = HistorizeAction</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mergeModeEnable = true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    inputId = ext-chess</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    outputId = int-chess</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    transformers = [{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      type = ScalaCodeDfTransformer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      code = &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        import org.apache.spark.sql.{DataFrame, SparkSession}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        (session:SparkSession, options:Map[String, String], df:DataFrame, dataObjectId:String) =&gt; {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          import session.implicits._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          df.dropDuplicates(Seq(&quot;id&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   }]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   metadata {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      feed = download</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  #...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>The full configuration looks like <a target="_blank" href="/assets/files/chess-49c77f7e01ad6fb42540b06f4a93ac75.conf">chess.conf</a>. Note that there are already further dataObjects and actions defined, described and used later. </p><h2 class="anchor anchorWithStickyNavbar_mojV" id="run">Run<a class="hash-link" href="#run" title="Direct link to heading">â€‹</a></h2><p>The Pod with metastore, polynote and the &quot;external&quot; SQL server should already being running. Now the SDLB container is launched within the same POD and the action histData ingests the data into the data lake:</p><div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">podman run --hostname localhost -e SPARK_LOCAL_HOSTNAME=localhost --rm --pod sdl_sql -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark --config /mnt/config --feed-sel ids:histData</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>The data can be inspected using the Polynote notebook (<code>sql_data_monitor.ipynb</code> downloaded above), which can be launched using <a href="http://localhost:8192/notebook/sql_data_monitor.ipynb" target="_blank" rel="noopener noreferrer">Polynote (click here)</a>. </p><p>Now, let&#x27;s assume a change in the source database. Here the <code>victory_status</code> <code>outoftime</code> is renamed to <code>overtime</code>. Furthermore one entry is deleted. Run script using:</p><div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">podman exec -it mssql /opt/mssql-tools/bin/sqlcmd -S mssqlserver -U sa -P &#x27;%abcd1234%&#x27; -i /config/db_mod_chess.sql</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Note: 1680 rows were changed + 1 row deleted.</p><p>Furthermore, the data lake gets updated using the same command as above:</p><div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">podman run --hostname localhost -e SPARK_LOCAL_HOSTNAME=localhost --rm --pod sdl_sql -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark --config /mnt/config --feed-sel ids:histData</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>In the <a href="http://localhost:8192/notebook/sql_data_monitor.ipynb" target="_blank" rel="noopener noreferrer">Polynote (click here)</a> sql_data_monitor.ipynb, the data lake table can be inspected again. The table and its additional columns are presented, as well as the original and updated rows for a modified row (<em>id = QQ3iIM2V</em>) and the deleted row (<em>id = 009mKOEz</em>).</p><p><img alt="polynote example output" src="/assets/images/historization_res-dbcab5954c3121455ffdc2dd351ccf93.png" width="911" height="385"></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="change-data-capture">Change Data Capture<a class="hash-link" href="#change-data-capture" title="Direct link to heading">â€‹</a></h2><p>So far the whole table is collected and compared with the existing data lake table.
Various databases support Change Data Capture (CDC). CDC already keeps track of changes similar to the comparision done by the historization feature of SDL.
This can be used to optimize performance of the historization feature, gathering only database updates, reducing the amount of transferred and compared data significantly. Therewith, only data changed (created, modified, or deleted) since the last synchronisation will be read from the database. It needs the status of the last synchronisation to be attached to the successful stream. This <strong>state</strong> is handled in SDLB. </p><p>In the following, an example is presented utilizing the MS SQL server CDC feature. Since the implemented JDBC connector cannot handle CDC data, an Airbyte connector is utilized, see <a href="https://docs.airbyte.com/understanding-airbyte/cdc/" target="_blank" rel="noopener noreferrer">Airbyte CDC</a> for details.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="enable-cdc-on-the-sql-server">Enable CDC on the SQL Server<a class="hash-link" href="#enable-cdc-on-the-sql-server" title="Direct link to heading">â€‹</a></h3><p>First the SQL server need to be configured to have a table <a href="https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/enable-and-disable-change-data-capture-sql-server?view=sql-server-ver15" target="_blank" rel="noopener noreferrer">CDC enabled</a>. Additionally to the used table <em>chess</em>, another table is created with the CDC feature enabled. This table <em>chess_cdc</em> is created by copying and deduplicating the original table. The table creation is already performed in the above introduced and used <a target="_blank" href="/assets/files/db_init_chess-f66d528d1f63d688cc156a7fb0e9516c.sql">MS SQL initalization</a> script. In practice, further SQL settings should be considered, including proper user and permissions specification, and an adaptation of the retention period (3 days default). </p><p>Furthermore, the SQL agent need to be enabled. Therefore, the database need to be restarted (here container is restarted). This is handled in the above mentioned <a target="_blank" href="/assets/files/restart_databases-ab3a7ace9c7c469008f6f050a44c4c89.sh">restart_databases.sh</a> script. If not already used above, run:</p><div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">bash restart_databases.sh</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Let&#x27;s double check the CDC enabled table:</p><div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">podman exec -it mssql /opt/mssql-tools/bin/sqlcmd -S mssqlserver -U sa -P &#x27;%abcd1234%&#x27; -Q &quot;SELECT * FROM foobar.cdc.dbo_chess_cdc_CT where id = &#x27;079kHDqh&#x27;&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Here the first 5 columns are added for the CDC.
It should be noted that CDC additional data vary by implementation from different DB products.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="airbyte-mssql-connector">Airbyte MSSQL connector<a class="hash-link" href="#airbyte-mssql-connector" title="Direct link to heading">â€‹</a></h3><p>Since Sparks JDBC data source (used above) does not support CDC data, the connector is changed to <a href="https://docs.airbyte.com/integrations/sources/mssql" target="_blank" rel="noopener noreferrer">Airbyte MSSQL</a>. In contrast to the article <a href="/blog/sdl-airbyte">Using Airbyte connector to inspect github data</a>, where Airbyte github connector ran as python script, here the connector runs as a container within the SDLB container.
I targeted a setup using: WSL2, SDLB with podman, and the Airbyte container with podman in the SDLB container. Unfortunately, there are issues with fuse overlay filesystem when using container in container with podman. Therefore, I switched to <a href="https://buildah.io/" target="_blank" rel="noopener noreferrer">buildah</a> in the SDLB container. Unfortunately, the entrypoint is not recognized as expected. As a workaround the following script corrects this.
I guess in another environment, e.g. in a cloud environment or just using docker in docker, this would work out of the box. </p><p>Here are my steps to get it running:</p><ul><li>add buildah and the Airbyte container to the SDLB <a target="_blank" href="/assets/files/Dockerfile-106772189af8db20db3f24d48737b13f.txt">Dockerfile</a> (just before the entrypoint):<div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">RUN apt-get update</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">RUN apt-get -y install buildah</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">RUN echo &#x27;unqualified-search-registries=[&quot;docker.io&quot;]&#x27; &gt;&gt; /etc/containers/registries.conf</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">RUN buildah --storage-driver=vfs from --name airbyte-mssql docker.io/airbyte/source-mssql</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div></li><li>rebuild the SDLB container: <code>podman build -t sdl-spark .</code></li><li>workaround script to parse all arguments correctly in the Airbyte container while using buildah without the proper entrypoint. Copy <a target="_blank" href="/assets/files/start_buildah-8928533426fd919b1146d8ddf307201b.sh">start_buildah.sh</a> script into <code>config</code> directory</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="sdlb-configuration">SDLB configuration<a class="hash-link" href="#sdlb-configuration" title="Direct link to heading">â€‹</a></h3><p>Now, the related dataObjects and action are added to the SDLB configuration <a target="_blank" href="/assets/files/chess-49c77f7e01ad6fb42540b06f4a93ac75.conf">config/chess.conf</a>.</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="dataobject">DataObject<a class="hash-link" href="#dataobject" title="Direct link to heading">â€‹</a></h4><p>As a source object the AirbyteDataObject is used. Again the MSSQL server with the user credentials are specified. Further, in the streamName the table is selected. The cmd specifies how to run Airbyte. Here the mentioned workaround script is called in the container. As target, again a Delta Lake table is chosen, here called <code>int_chess_cdc</code>. Practically, we would prevent of duplicating tables, here we create a new one to provide the possibility to compare both results. </p><div class="codeBlockContainer_I0IT language-hocon theme-code-block"><div class="codeBlockContent_wNvx hocon"><pre tabindex="0" class="prism-code language-hocon codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">dataObjects {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ext-chess-cdc {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    type = AirbyteDataObject</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    config = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      host = &quot;mssqlserver&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      port = 1433</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      database = &quot;foobar&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      username = &quot;sa&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      password = &quot;%abcd1234%&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      replication_method = &quot;CDC&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    streamName = &quot;chess_cdc&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cmd = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      type = DockerRunScript</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      name = &quot;airbyte_source-mssql&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      image = &quot;airbyte-mssql&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      linuxDockerCmd = &quot;bash /mnt/config/start_buildah.sh&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  int-chess-cdc {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    type = DeltaLakeTableDataObject</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    path = &quot;~{id}&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    table {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      db = &quot;default&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      name = &quot;int_chess_cdc&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      primaryKey = [id]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="action">Action<a class="hash-link" href="#action" title="Direct link to heading">â€‹</a></h4><p>Again the SDLB action <em>HistorizeAction</em> with <em>mergeModeEnabled</em> is selected. Further, the incremental execution mode is enabled. With CDC we get only changed data, which will be merged with the SDL existing table. Further, the column and value need to be specified to identify deleted data points. Depending on the CDC implementation this could be the deletion date (like we have here) or an operation flag mentioning the deletion operation as code, or even differently. SDLB expects a fixed value for deletion. That&#x27;s why we specify an <code>AdditionalColumnsTransformer</code> transformer to first create an intermediate column mapping any date to <em>true</em>. </p><div class="codeBlockContainer_I0IT language-hocon theme-code-block"><div class="codeBlockContent_wNvx hocon"><pre tabindex="0" class="prism-code language-hocon codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">actions {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  histDataAirbyte {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    type = HistorizeAction</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mergeModeEnable = true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    executionMode = { type = DataObjectStateIncrementalMode }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    inputId = ext-chess-cdc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    outputId = int-chess-cdc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mergeModeCDCColumn = &quot;cdc_deleted&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mergeModeCDCDeletedValue = true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    transformers = [{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      type = AdditionalColumnsTransformer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      additionalDerivedColumns = {cdc_deleted = &quot;_ab_cdc_deleted_at is not null&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    metadata {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      feed = download</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Finally, SDLB is launched using the same settings as above, now with the feed <code>ids:histDataAirbyte</code> and specifying the <em>state</em> directory and name:</p><div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">podman run --hostname localhost -e SPARK_LOCAL_HOSTNAME=localhost --rm --pod sdl_sql -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark --config /mnt/config --feed-sel ids:histDataAirbyte --state-path /mnt/data/state -n SDL_sql</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Again the SQL database modification is processed using <a target="_blank" href="/assets/files/db_mod_chess_cdc-11e5ec52cc1ebb7c34d5ae65ed898038.sql">config/db_mod_chess_cdc.sql</a>: </p><div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">podman exec -it mssql /opt/mssql-tools/bin/sqlcmd -S mssqlserver -U sa -P &#x27;%abcd1234%&#x27; -i /config/db_mod_chess_cdc.sql</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>And the SDL update with the same command as just used:</p><div class="codeBlockContainer_I0IT language-Bash theme-code-block"><div class="codeBlockContent_wNvx Bash"><pre tabindex="0" class="prism-code language-Bash codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">podman run --hostname localhost -e SPARK_LOCAL_HOSTNAME=localhost --rm --pod sdl_sql -v ${PWD}/data:/mnt/data -v ${PWD}/target:/mnt/lib -v ${PWD}/config:/mnt/config sdl-spark --config /mnt/config --feed-sel ids:histDataAirbyte --state-path /mnt/data/state -n SDL_sql</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Again the delta lake tables can be inspected using <a href="http://localhost:8192/notebook/sql_data_monitor.ipynb" target="_blank" rel="noopener noreferrer">Polynote (click here)</a>.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="summary">Summary<a class="hash-link" href="#summary" title="Direct link to heading">â€‹</a></h2><p>Smart Data Lake Builder (SDLB) provides a powerful tool to capture data from SQL databases and provides features to track changes, as well as optimized procedures to process Change Data Capture (CDC) data. There are various connectors to interact with SQL databases (e.g. JDBC and Airbyte). Powerful transformers help to handle the data stream within the action, e.g. for deduplication. Furthermore, the join and merge of new data with existing tables, as well as the writing of the data is optimized, reducing the computational an IO efforts with standard HistorizeAction.</p></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_h6_j"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/historization">historization</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/mssql">MSSQL</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/incremental">incremental</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/cdc">CDC</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/smart-data-lake/smart-data-lake/tree/documentation/blog/2022-05-11-SDL-historization/2022-05-11-historization.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/sdl-databricks"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Deployment on Databricks</div></a></div></nav></main><div class="col col--2"><div class="tableOfContents_cNA8 thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#test-case" class="table-of-contents__link toc-highlight">Test Case</a></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#prepare-source-database" class="table-of-contents__link toc-highlight">Prepare Source Database</a></li><li><a href="#define-workflow" class="table-of-contents__link toc-highlight">Define Workflow</a><ul><li><a href="#spark-settings" class="table-of-contents__link toc-highlight">Spark Settings</a></li><li><a href="#connection" class="table-of-contents__link toc-highlight">Connection</a></li><li><a href="#dataobjects" class="table-of-contents__link toc-highlight">DataObjects</a></li><li><a href="#actions" class="table-of-contents__link toc-highlight">Actions</a></li></ul></li><li><a href="#run" class="table-of-contents__link toc-highlight">Run</a></li><li><a href="#change-data-capture" class="table-of-contents__link toc-highlight">Change Data Capture</a><ul><li><a href="#enable-cdc-on-the-sql-server" class="table-of-contents__link toc-highlight">Enable CDC on the SQL Server</a></li><li><a href="#airbyte-mssql-connector" class="table-of-contents__link toc-highlight">Airbyte MSSQL connector</a></li><li><a href="#sdlb-configuration" class="table-of-contents__link toc-highlight">SDLB configuration</a></li></ul></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/">Getting started</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/smart-data-lake/smart-data-lake" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://github.com/smart-data-lake/smart-data-lake/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub Issues<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a href="https://www.elca.ch" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>ELCA<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022 Smart Data Lake, Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.20ecc8fe.js"></script>
<script src="/assets/js/main.c97093ac.js"></script>
</body>
</html>