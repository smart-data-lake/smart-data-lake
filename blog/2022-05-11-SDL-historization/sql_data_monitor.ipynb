{
  "metadata" : {
    "config" : {
      "dependencies" : {
        
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.ui.port" : "4140",
        "spark.sql.catalog.spark_catalog" : "org.apache.spark.sql.delta.catalog.DeltaCatalog",
        "spark.hadoop.javax.jdo.option.ConnectionDriverName" : "org.apache.derby.jdbc.ClientDriver",
        "spark.hadoop.javax.jdo.option.ConnectionPassword" : "1234",
        "spark.hadoop.javax.jdo.option.ConnectionURL" : "jdbc:derby://metastore:1527/db;create=true",
        "spark.hadoop.javax.jdo.option.ConnectionUserName" : "sa",
        "spark.sql.extensions" : "io.delta.sql.DeltaSparkSessionExtension"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# Historization test\n",
        "\n",
        "\n",
        "This notebook inspects the created table(s) of the SDL historization test.\n",
        "\n",
        "First the existing tables are listed.\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 1,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1651762013378,
          "endTs" : 1651762019953
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "spark.catalog.listTables.show(false)"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 2,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "Using SQL statement we can inspect the lines similar to the source database."
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 3,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1651762041875,
          "endTs" : 1651762052989
        },
        "language" : "sql"
      },
      "language" : "sql",
      "source" : [
        "select * from default.int_data"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 4,
      "metadata" : {
        "language" : "viz"
      },
      "language" : "viz",
      "source" : [
        "{\"type\":\"table\",\"value\":\"Out\",\"rowRange\":[0,2]}"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 5,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "Using Scala and SDL the DeltaLake Tables can be inspected."
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 6,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1651762310998,
          "endTs" : 1651762311356
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// import smartdatalake\r\n",
        "import io.smartdatalake.config.SdlConfigObject.stringToDataObjectId\r\n",
        "import io.smartdatalake.config.ConfigToolbox\r\n",
        "import io.smartdatalake.workflow.dataobject._\r\n",
        "import io.smartdatalake.workflow.ActionPipelineContext\r\n",
        "import io.smartdatalake.workflow.action.SDLExecutionId\r\n",
        "import io.smartdatalake.app.SmartDataLakeBuilderConfig\r\n",
        "import io.smartdatalake.workflow.ExecutionPhase\r\n",
        "implicit val ss = spark // make Spark session available implicitly"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 7,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1651762312830,
          "endTs" : 1651762319904
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// read config from mounted directory\r\n",
        "val (registry, globalConfig) = ConfigToolbox.loadAndParseConfig(Seq(\"/mnt/config\"), Some(this.getClass.getClassLoader))\r\n",
        "// Create the context used by SDL objects\r\n",
        "implicit val context = ConfigToolbox.getDefaultActionPipelineContext(spark, registry)"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 8,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1651762336795,
          "endTs" : 1651762338394
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// get a dataobject\r\n",
        "val dataInt = registry.get[DeltaLakeTableDataObject](\"int-data\")"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 9,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1651762364453,
          "endTs" : 1651762365952
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "dataInt.getDataFrame().show"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 10,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "NOTE: the additional columns.Â \n",
        "\n",
        "<div>NOW: update the source database, run SDLB config again.&nbsp;</div><div>Then we run the same commands again an can inspect the differences.</div>\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 11,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1651762685305,
          "endTs" : 1651762688167
        },
        "language" : "sql"
      },
      "language" : "sql",
      "source" : [
        "select * from default.int_data"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 12,
      "metadata" : {
        "language" : "viz"
      },
      "language" : "viz",
      "source" : [
        "{\"type\":\"table\",\"value\":\"Out\",\"rowRange\":[0,4]}"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 13,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1651762704660,
          "endTs" : 1651762705854
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "dataInt.getDataFrame().show"
      ],
      "outputs" : [
      ]
    }
  ]
}
