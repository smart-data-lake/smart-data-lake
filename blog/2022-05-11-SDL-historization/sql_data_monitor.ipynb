{
  "metadata" : {
    "config" : {
      "dependencies" : {
        
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.ui.port" : "4140",
        "spark.sql.catalog.spark_catalog" : "org.apache.spark.sql.delta.catalog.DeltaCatalog",
        "spark.hadoop.javax.jdo.option.ConnectionDriverName" : "org.apache.derby.jdbc.ClientDriver",
        "spark.hadoop.javax.jdo.option.ConnectionPassword" : "1234",
        "spark.hadoop.javax.jdo.option.ConnectionURL" : "jdbc:derby://metastore:1527/db;create=true",
        "spark.hadoop.javax.jdo.option.ConnectionUserName" : "sa",
        "spark.sql.extensions" : "io.delta.sql.DeltaSparkSessionExtension"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# Historization test\n",
        "\n",
        "\n",
        "This notebook inspects the created table(s) of the SDL historization test.\n",
        "\n",
        "\n",
        "At the beginning we inspect the injected table and verifying columns and deduplication.\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 1,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1653032395823,
          "endTs" : 1653032403919
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "spark.catalog.listTables.show(false)"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "spark.table(\"default.int_chess\")\r\n",
        ".summary()\r\n",
        ".show()"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 3,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1653040305871,
          "endTs" : 1653040308458
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "spark.table(\"default.int_chess\")\r\n",
        ".summary()\r\n",
        ".show()"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 4,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "In the summary the first line prints the amount of rows. \n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 5,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1653040329892,
          "endTs" : 1653040331052
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "spark.table(\"default.int_chess\")\r\n",
        ".where($\"id\"===\"QQ3iIM2V\" || $\"id\"===\"079kHDqh\")\r\n",
        ".show"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 6,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "Note the last three columns are added by the historization. The data point 079kHDqh is now deduplicated.\n",
        "\n",
        "# Update the databases\n",
        "\n",
        "\n",
        "<div>Now run the update in the source DB and the new injection.&nbsp;</div><div>Go back to the CLI and run the SQL update script and SDLB again.</div><div><br></div><div>Then, here the changes are inspected.</div>\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 7,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1653040383767,
          "endTs" : 1653040386633
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "spark.table(\"default.int_chess\")\r\n",
        ".show(2)\r\n",
        "spark.table(\"default.int_chess\")\r\n",
        ".summary()\r\n",
        ".show(1)"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 8,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "Note that the table grew about the amount of changed rows. Some lines were duplicates, thus the numbers do not match exactly. \n",
        "\n",
        "<div><br></div><div>In the next cell we inspect the changes. Note the differences in the<code>dl_ts_captured</code>and <code>dl_ts_delimited</code>&nbsp;columns.</div>\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 9,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1653040039359,
          "endTs" : 1653040040713
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "spark.table(\"default.int_chess\")\r\n",
        ".where($\"id\"===\"QQ3iIM2V\" || $\"id\"===\"009mKOEz\" )\r\n",
        ".select(\"id\", \"moves\", \"victory_status\", \"dl_ts_captured\", \"dl_ts_delimited\")\r\n",
        ".orderBy($\"id\", $\"dl_ts_captured\")\r\n",
        ".show()"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 10,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "Note the capturing of the old and new values with its validation ranges as well as the invalidated \"deleted\" data point 009mKOEz\n",
        "\n",
        "# CDC data\n",
        "\n",
        "\n",
        "<div>Now go back and implement the CDC in SQL server and SDL. Afterwards come back to monitor changes in the table here.&nbsp;</div><div><br></div>"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 11,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1653054759282,
          "endTs" : 1653054783501
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "spark.table(\"default.int_chess_cdc\")\r\n",
        ".summary()\r\n",
        ".show()"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 12,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1653055171316,
          "endTs" : 1653055173351
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "spark.table(\"default.int_chess_cdc\")\r\n",
        ".where($\"id\"===\"QQ3iIM2V\" || $\"id\"===\"009mKOEz\")\r\n",
        ".show"
      ],
      "outputs" : [
      ]
    }
  ]
}