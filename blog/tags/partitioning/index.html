<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.1">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Smart Data Lake Builder RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Smart Data Lake Builder Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="Smart Data Lake Builder" href="/opensearch.xml"><title data-rh="true">One post tagged with &quot;partitioning&quot; | Smart Data Lake Builder</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://www.smartdatalake.ch/blog/tags/partitioning"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="One post tagged with &quot;partitioning&quot; | Smart Data Lake Builder"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.smartdatalake.ch/blog/tags/partitioning"><link data-rh="true" rel="alternate" href="https://www.smartdatalake.ch/blog/tags/partitioning" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.smartdatalake.ch/blog/tags/partitioning" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://UOM3ZOMCU0-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.0f640fc3.css">
<link rel="preload" href="/assets/js/runtime~main.c080420f.js" as="script">
<link rel="preload" href="/assets/js/main.285498bb.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/sdl_logo.png" alt="Smart Data Lake Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/sdl_logo.png" alt="Smart Data Lake Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Smart Data Lake</b></a><a class="navbar__item navbar__link" href="/docs/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/JsonSchemaViewer">SchemaViewer</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/smart-data-lake/smart-data-lake" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/sdl-housekeeping">Housekeeping</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/sdl-hist">Incremental historization using CDC and Airbyte MSSQL connector</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/sdl-databricks">Deployment on Databricks</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/sdl-snowpark">Combine Spark and Snowpark to ingest and transform data in one pipeline</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/sdl-airbyte">Using Airbyte connector to inspect github data</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>One post tagged with &quot;partitioning&quot;</h1><a href="/blog/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/sdl-housekeeping">Housekeeping</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-06-08T00:00:00.000Z" itemprop="datePublished">June 8, 2023</time> · <!-- -->6 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/pgruetter" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Patrick Grütter</span></a></div></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>In this article, we&#x27;re taking a look on how we use SDLB&#x27;s housekeeping features to keep our pipelines running efficiently.</p><p>Some DataObject contain housekeeping features of their own.
Make sure you use them!
For example, Delta Tables support commands like <code>optimize</code> and <code>vacuum</code> to optimize storage and delete no longer needed files.</p><p>But usually, those commands do not re-organize your partitions.
This is where SDLBs housekeeping mode comes in.</p><p>The example is taken from a real world project we&#x27;ve implemented.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="context">Context<a class="hash-link" href="#context" title="Direct link to heading">​</a></h2><p>In this particular project we are collecting data from various reporting units and process it in batches.
The reporting units use an Azure Function to upload JSON files to an Azure Data Lake Storage.
From there, we pick them up for validation and processing.
Reporting units can upload data anytime, but it is only processed a few times a day.</p><p>Once validated, we use Delta Lake tables in Databricks to process data through the layers of the Lakehouse.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="partitioning">Partitioning<a class="hash-link" href="#partitioning" title="Direct link to heading">​</a></h2><p>The Azure Function puts uploaded JSON files in a subfolder for each reporting unit.
As such, JSON files are already neatly partitioned by <code>reporting_unit</code>:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">uploadFolder/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  reporting_unit=rp01</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    file1.json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    file2.json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    file3.json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  reporting_unit=rp02</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    file1.json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  reporting_unit=rp03</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    fileX.json</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>To read these JSON files, we can therefore use the following DataObject definition:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import_json {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    type = JsonFileDataObject</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    path = uploadFolder/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    partitions = [reporting_unit]    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>These files are then processed with a <code>FileTransferAction</code> into an output DataObject <code>stage_json</code>: </p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">stage_json {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    type = FileTransferAction</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    inputId = import_json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    outputId = stage_json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    executionMode = { type = FileIncrementalMoveMode }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    metadata.feed = stage_json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Each time we start to process uploaded data, we use the <code>run_id</code> to keep track of all batch jobs and version of files delivered.
If you use a state path (see <a href="/docs/reference/commandLine">commandLine</a>),
your runs automatically generate a <code>run_id</code> to identify the run, and you can use it by extending your DataObject:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">stage_json {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    type = JsonFileDataObject</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    path = processedFolder</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    partitions = [run_id,reporting_unit]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    schema = &quot;&quot;&quot;reporting_unit string, run_id string, ....&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Note how we just use run_id as part of the schema without any further declaration.
Since we use the state path, SDLB uses a <code>run_id</code> internally, and if it&#x27;s referenced as partition column in a DataObject, processed data get automatically assigned the id of the current run.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="drawback">Drawback<a class="hash-link" href="#drawback" title="Direct link to heading">​</a></h2><p>Let&#x27;s take a look at the resulting partition layout of <code>stage_json</code>:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">processedFolder/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  run_id=1/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    reporting_unit=rp01/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      file1.json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      file2.json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      file3.json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    reporting_unit=rp02/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      file1.json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    reporting_unit=rp03/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      fileX.json</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This partition layout has many advantages in our case as we know exactly
during which run a particular file was processed and which reporting unit uploaded it.
In further stages we can clearly work with files that were processed in the current run and not touch any old <code>run_id</code>s. </p><p>For this use case, a few things are important to note:</p><ul><li>Some reporting units don&#x27;t upload data for days. You end up with only a few reporting_unit partitions per run_id.</li><li>File sizes are rather small (&lt; 1 MiB), partition sizes end up very small too.</li><li>If you use hourly runs and run 24/7, you end up with 168 partitions per week, plus sub-partitions for reporting units.</li><li>Once files are correctly processed, we don&#x27;t read the uploaded files anymore.
We still keep them as raw files should we ever need to re-process them.</li></ul><p>The drawback becomes apparent when you have actions working with all partitions, they will become very slow.
Spark doesn&#x27;t like a lot of small partitions.</p><p>To mitigate that, we use SDLB&#x27;s Housekeeping Feature.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="housekeepingmode">HousekeepingMode<a class="hash-link" href="#housekeepingmode" title="Direct link to heading">​</a></h2><p>If you take a look at DataObject&#x27;s parameters, you will see a <code>housekeepingMode</code>.
There are two modes available:</p><ul><li><strong>PartitionArchiveCompactionMode</strong>: to compact / archive partitions  </li><li><strong>PartitionRetentionMode</strong>: to delete certain partitions completely</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="partitionarchivecompactionmode">PartitionArchiveCompactionMode<a class="hash-link" href="#partitionarchivecompactionmode" title="Direct link to heading">​</a></h3><p>In this mode, you solve two tasks at once:</p><ul><li>You define how many smaller partitions are aggregated into one larger partition (archive)</li><li>Rewrite all files in a partition to combine many small files into larger files (compact)</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="archive">Archive<a class="hash-link" href="#archive" title="Direct link to heading">​</a></h4><p>In our example above, we stated that we don&#x27;t want to alter any input files, so we won&#x27;t use compaction.
We want to keep them as is (raw data).
But we do want to get rid of all the small partitions after a certain amount of time.
For that, we extend <code>stage_json</code> to include the <code>housekeepingMode</code> with a <code>archivePartitionExpression</code>:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">stage_json {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    type = JsonFileDataObject</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    path = processedFolder</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    partitions = [run_id,reporting_unit]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    schema = &quot;&quot;&quot;reporting_unit string, run_id string, ....&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    housekeepingMode = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      type = PartitionArchiveCompactionMode</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      archivePartitionExpression = &quot;if( elements.run_id &lt; (runId - 500), map(&#x27;run_id&#x27;, (cast(elements.run_id as integer) div 500) * 500, &#x27;reporting_unit&#x27;, elements.reporting_unit), elements)&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This expression probably needs some explanation:<br>
<!-- -->The Spark SQL expression works with attributes of <a href="https://github.com/smart-data-lake/smart-data-lake/blob/master-spark3/sdl-core/src/main/scala/io/smartdatalake/workflow/dataobject/HousekeepingMode.scala#L136" target="_blank" rel="noopener noreferrer"><code>PartitionExpressionData</code></a>.
In this case we use <code>runId</code> (the current runId) and <code>elements</code> (all partition values as map(string,string)).
It needs to return a map(string,string) to define new partition values.
In our case, it needs to define <code>run_id</code> and <code>reporting_unit</code> because these are the partitions defined in <code>stage_json</code>.</p><p>Let&#x27;s take the expression apart:<br>
<code>if(elements.run_id &lt; (runId - 500), ...</code><br>
<!-- -->Only archive the partition if it&#x27;s runId is older than 500 run_ids ago. </p><p><code>map(&#x27;run_id&#x27;, (cast(elements.run_id as integer) div 500) * 500, &#x27;reporting_unit&#x27;, elements.reporting_unit)</code><br>
<!-- -->Creates the map with the new values for the partitions.
The run_id is floored to the next 500 value, so as example, the new value of run_id 1984 will be 1500 (because integer 1984/500=3, 3*500=1500).<br>
<!-- -->Remember that we need to return all partition values in the map, also the ones we don&#x27;t want to alter.
For <code>reporting_unit</code> we simply return the existing value <code>elements.reporting_unit</code>.</p><p><code>..., elements)</code><br>
<!-- -->This is the else condition and simply returns the existing partition values if there is nothing to archive.</p><div class="theme-admonition theme-admonition-info alert alert--info admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_S0QG"><p>The housekeeping mode is applied after writing a DataObject.
Keep in mind, that it is executed with every run.</p></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="compaction">Compaction<a class="hash-link" href="#compaction" title="Direct link to heading">​</a></h4><p>We don&#x27;t want to compact files in our case.
But from the documentation you can see that compaction works very similarly:<br>
<!-- -->You also work with attributes from <code>PartitionExpressionData</code> but instead of new partition values,
you return a boolean to indicate for each partition if it should be compacted or not. </p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="partitionretentionmode">PartitionRetentionMode<a class="hash-link" href="#partitionretentionmode" title="Direct link to heading">​</a></h3><p>Again, not used in our example as we never delete old files.
But if you need to, you define a Spark SQL expression returning a boolean indicating if a partition should be retained or deleted.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">stage_json {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    type = JsonFileDataObject</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    path = processedFolder</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    partitions = [run_id,reporting_unit]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    schema = &quot;&quot;&quot;reporting_unit string, run_id string, ....&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    housekeepingMode = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      type = PartitionRetentionMode</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      retentionCondition = &quot;elements.run_id &gt; (runId - 500)&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a class="hash-link" href="#result" title="Direct link to heading">​</a></h2><p>In our example, we had performance gradually decreasing because Spark had to read more than 10&#x27;000 partitions and subpartitions.
Just listing all available partitions, even if you only worked with the most recent one, took a few minutes and these operations added up.</p><p>With the housekeeping mode enabled, older partitions continuously get merged into larger partitions containing up to 500 runs.
This brought the duration of list operations back to a few seconds.</p><p>The operations are fully automated, no manual intervention is required.</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/housekeeping">housekeeping</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/performance">performance</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/partitioning">partitioning</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/">Getting started</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/smart-data-lake/smart-data-lake" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/smart-data-lake/smart-data-lake/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Issues<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.elca.ch" target="_blank" rel="noopener noreferrer" class="footer__link-item">ELCA<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Smart Data Lake, Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.c080420f.js"></script>
<script src="/assets/js/main.285498bb.js"></script>
</body>
</html>