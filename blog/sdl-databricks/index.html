<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.0">
<title data-rh="true">Deployment on Databricks | Smart Data Lake Builder</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://www.smartdatalake.ch/blog/sdl-databricks"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Deployment on Databricks | Smart Data Lake Builder"><meta data-rh="true" name="description" content="A brief example of deploying SDL on Databricks"><meta data-rh="true" property="og:description" content="A brief example of deploying SDL on Databricks"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2022-04-07T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/mand35"><meta data-rh="true" property="article:tag" content="Databricks,Cloud"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.smartdatalake.ch/blog/sdl-databricks"><link data-rh="true" rel="alternate" href="https://www.smartdatalake.ch/blog/sdl-databricks" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.smartdatalake.ch/blog/sdl-databricks" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://UOM3ZOMCU0-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Smart Data Lake Builder RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Smart Data Lake Builder Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="Smart Data Lake Builder" href="/opensearch.xml"><link rel="stylesheet" href="/assets/css/styles.882ac319.css">
<script src="/assets/js/runtime~main.0fae97fe.js" defer="defer"></script>
<script src="/assets/js/main.7b2a5441.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/sdl_logo.png" alt="Smart Data Lake Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/sdl_logo.png" alt="Smart Data Lake Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Smart Data Lake</b></a><a class="navbar__item navbar__link" href="/docs/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/json-schema-viewer">SchemaViewer</a><a href="https://ui-demo.smartdatalake.ch/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">UI-Demo<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/smart-data-lake/smart-data-lake" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/sdl-data-mesh">Data Mesh with SDL</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/sdl-housekeeping">Housekeeping</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/sdl-hist">Incremental historization using CDC and Airbyte MSSQL connector</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/blog/sdl-databricks">Deployment on Databricks</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/sdl-snowpark">Combine Spark and Snowpark to ingest and transform data in one pipeline</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="https://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="A brief example of deploying SDL on Databricks"><header><h1 class="title_f1Hy" itemprop="headline">Deployment on Databricks</h1><div class="container_mt6G margin-vert--md"><time datetime="2022-04-07T00:00:00.000Z" itemprop="datePublished">April 7, 2022</time> · <!-- -->6 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/mand35" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Mandes Schönherr</span></a></div><small class="avatar__subtitle" itemprop="description">Dr.sc.nat.</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><p>Many analytics applications are ported to the cloud, Data Lakes and Lakehouses in the cloud becoming more and more popular.
The <a href="https://databricks.com" target="_blank" rel="noopener noreferrer">Databricks</a> platform provides an easy accessible and easy configurable way to implement a modern analytics platform.
Smart Data Lake Builder on the other hand provides an open source, portable automation tool to load and transform the data.</p>
<p>In this article the deployment of Smart Data Lake Builder (SDLB) on <a href="https://databricks.com" target="_blank" rel="noopener noreferrer">Databricks</a> is described.</p>
<p>Before jumping in, it should be mentioned, that there are also many other methods to deploy SDLB in the cloud, e.g. using containers on Azure, Azure Kubernetes Service, Azure Synapse Clusters, Google Dataproc...
The present method provides the advantage of having many aspects taken care of by Databricks like Cluster management, Job scheduling and integrated data science notebooks.
Further, the presented SDLB pipeline is just a simple example, focusing on the integration into Databricks environment.
SDLB provides a wide range of features and its full power is not revealed here.</p>
<p>Let&#x27;s get started:</p>
<ol>
<li>
<p><a href="https://databricks.com" target="_blank" rel="noopener noreferrer"><strong>Databricks</strong></a> accounts can be created as <a href="https://databricks.com/try-databricks" target="_blank" rel="noopener noreferrer">Free Trial</a> or as <a href="https://community.databricks.com/s/login/SelfRegister" target="_blank" rel="noopener noreferrer">Community Account</a></p>
<ul>
<li>Account and Workspace creation are described in detail <a href="https://docs.databricks.com/getting-started/account-setup.html" target="_blank" rel="noopener noreferrer">here</a>, there are few hints and modifications presented below.</li>
<li>I selected AWS backend, but there are conceptually no differences to the other providers. If you already have an Azure, AWS or Google Cloud account/subscription this can be used, otherwise you can register a trial subscription there.</li>
</ul>
</li>
<li>
<p><strong>Workspace stack</strong> is created using the Quickstart as described in the documentation. When finished launch the Workspace.</p>
</li>
<li>
<p><strong>Databricks CLI</strong>: for file transfer of configuration files, scripts and data, the <a href="https://docs.databricks.com/dev-tools/cli/index.html" target="_blank" rel="noopener noreferrer">Databricks CLI</a> is installed locally. <strong>Configure</strong> the CLI, using the Workspace URL and in the Workspace &quot;Settings&quot; -&gt; &quot;User Settings&quot; -&gt; &quot;Access tokens&quot; create a new token.</p>
</li>
<li>
<p><strong>Cluster</strong> creation, in the Workspace open the <em>Cluster</em> Creation form.</p>
<ul>
<li>
<p>Spark version: When selecting the <em>Databricks version</em> pay attention to the related Spark version.
This needs to match the Spark version we build SDLB with later. Here, <code>10.4 LTS</code> is selected with <code>Spark 3.2.1</code> and <code>Scala 2.12</code>.
Alternatively, SDLB can be build with a different Spark version, see also <a href="/docs/architecture">Architecture</a> for supported versions.</p>
</li>
<li>
<p>typesafe library version correction script: the workspace currently includes version 1.2.1 from com.typesafe<!-- -->:config<!-- --> java library.
SDLB relies on functions of a newer version (&gt;1.3.0) of this library.
Thus, we provide a newer version of the com.typesafe<!-- -->:config<!-- --> java library in an initialization script: <em>Advanced options</em> -&gt; <em>Init Scripts</em> specify <code>dbfs:/databricks/scripts/config-install.sh</code></p>
<ul>
<li>Further, the script needs to be created and uploaded. You can use the following script in a local terminal:</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">cat &lt;&lt; EOF &gt;&gt; ./config-install.sh</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">#!/bin/bash</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">wget -O /databricks/jars/-----config-1.4.1.jar https://repo1.maven.org/maven2/com/typesafe/config/1.4.1/config-1.4.1.jar</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">EOF</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">databricks fs mkdirs dbfs:/databricks/scripts</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">databricks fs cp ./config-install.sh dbfs:/databricks/scripts/</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Alternatively, you can also use a Databricks notebook for the script upload by executing the following cell:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">%sh</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">cat &lt;&lt; EOF &gt;&gt; ./config-install.sh</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">#!/bin/bash</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">wget -O /databricks/jars/-----config-1.4.1.jar https://repo1.maven.org/maven2/com/typesafe/config/1.4.1/config-1.4.1.jar</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">EOF</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">mkdir /dbfs/databricks/scripts</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">cp ./config-install.sh /dbfs/databricks/scripts/</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Note: to double-check the library version I ran <code>grep typesafe pom.xml</code> in the <a href="https://github.com/smart-data-lake/smart-data-lake.git" target="_blank" rel="noopener noreferrer">SmartDataLake</a> source</p>
<p>Note: the added <code>-----</code> will ensure that this <code>.jar</code> is preferred before the default Workspace Spark version (which starts with <code>----</code>).
If you are curious you could double-check e.g. with a Workspace Shell Notebook running <code>ls /databricks/jars/*config*</code></p>
</li>
</ul>
</li>
<li>
<p><strong>fat-jar</strong>:
We need to provide the SDLB sources and all required libraries. Therefore, we compile and pack the Scala code into a Jar including the dependencies. We use the <a href="https://github.com/smart-data-lake/getting-started.git" target="_blank" rel="noopener noreferrer">getting-started</a> as dummy project, which itself pulls the SDLB sources.</p>
<ul>
<li>download the <a href="https://github.com/smart-data-lake/getting-started.git" target="_blank" rel="noopener noreferrer">getting-started</a> source and build it with the <code>-P fat-jar</code> profile</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">podman run -v ${PWD}:/mnt/project -v ${PWD}/.mvnrepo:/mnt/.mvnrepo maven:3.6.0-jdk-11-slim -- mvn -DskipTests  -P fat-jar  -f /mnt/project/pom.xml &quot;-Dmaven.repo.local=/mnt/.mvnrepo&quot; package</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>General build instructions can be found in the <a href="/docs/getting-started/setup#compile-scala-classes">getting-started</a> documentation.
Therewith, the file <code>target/getting-started-1.0-jar-with-dependencies.jar</code> is created.
The <em>fat-jar</em> profile will include all required dependencies. The profile is defined in the <a href="https://github.com/smart-data-lake/smart-data-lake" target="_blank" rel="noopener noreferrer">smart-data-lake</a> pom.xml.</p>
</li>
<li>
<p>upload files</p>
<ul>
<li>JAR: in the &quot;Workspace&quot; -&gt; your user -&gt; create a directory <code>jars</code> and &quot;import&quot; the library using the link in &quot;(To import a library, such as a jar or egg, click here)&quot; and select the above created fat-jar to upload. As a result the jar will be listed in the Workspace directory.</li>
<li><strong>SDLB application</strong>: As an example a dataset from Airbnb NYC will be downloaded from Github, first written into a CSV file and later partially ported into a table. Therefore, the pipeline is defined first locally in a new file <code>application.conf</code>:</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">dataObjects {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  ext-ab-csv-web {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = WebserviceFileDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    url = &quot;https://raw.githubusercontent.com/adishourya/Airbnb/master/new-york-city-airbnb-open-data/AB_NYC_2019.csv&quot;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    followRedirects = true</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    readTimeoutMs=200000</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  stg-ab {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = CsvFileDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    schema = &quot;&quot;&quot;id integer, name string, host_id integer, host_name string, neighbourhood_group string, neighbourhood string, latitude double, longitude double, room_type  string, price integer, minimum_nights integer, number_of_reviews integer, last_review timestamp, reviews_per_month double, calculated_host_listings_count integer, availability_365 integer&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    path = &quot;file:///dbfs/data/~{id}&quot;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  int-ab {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = DeltaLakeTableDataObject</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    path = &quot;~{id}&quot;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    table {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      db = &quot;default&quot;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      name = &quot;int_ab&quot;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      primaryKey = [id]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">actions {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  loadWeb2Csv {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = FileTransferAction</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    inputId = ext-ab-csv-web</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    outputId = stg-ab</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    metadata {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      feed = download</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  loadCsvLoc2Db {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    type = CopyAction</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    inputId = stg-ab</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    outputId = int-ab</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    transformers = [{</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      type = SQLDfTransformer</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      code = &quot;select id, name, host_id,host_name,neighbourhood_group,neighbourhood,latitude,longitude from stg_ab&quot;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    metadata {</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      feed = copy</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>upload using Databricks CLI</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#ffffff"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#000000;background-color:#ffffff"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">databricks fs mkdirs dbfs:/conf/</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">databricks fs cp application.conf dbfs:/conf/application.conf</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>
<p><strong>Job creation</strong>:
Here, the Databricks job gets defined, specifying the SDL library and, the entry point and the arguments. Here we specify only the download feed.
Therefore, open in the sidebar <em>Jobs</em> -&gt; <em>Create Job</em>:</p>
<ul>
<li><strong>Type</strong>: <code>JAR</code></li>
<li><strong>Main Class</strong>: <code>io.smartdatalake.app.LocalSmartDataLakeBuilder</code></li>
<li><strong>add</strong> <em>Dependent Libraries</em>: &quot;Workspace&quot; -&gt; select the file previously uploaded &quot;getting-started...&quot; file in the &quot;jars&quot; directory
<img loading="lazy" alt="jar select" src="/assets/images/add_library-004c4b45355447e0191352a0c3d1e26c.png" width="630" height="652" class="img_ev3q"></li>
<li><strong>Cluster</strong> select the cluster created above with the corrected typesafe library</li>
<li><strong>Parameters</strong>: <code>[&quot;-c&quot;, &quot;file:///dbfs/conf/&quot;, &quot;--feed-sel&quot;, &quot;download&quot;]</code>, which specifies the location of the SDLB configuration and selects the feed &quot;download&quot;
<img loading="lazy" alt="download task" src="/assets/images/download_task-104bd82fd84e5fb593b161282586942e.png" width="589" height="641" class="img_ev3q"></li>
</ul>
</li>
<li>
<p><strong>Launch</strong> the job:
Launch the job.
When finished in the &quot;Runs&quot; section of that job we can verify the successful run status</p>
</li>
<li>
<p><strong>Results</strong>
After running the SDLB pipeline the data should be downloaded into the staging file <code>stg_ab/result.csv</code> and selected parts into the table <code>int_ab</code></p>
<ul>
<li>csv file: in the first step we downloaded the CSV file. This can be verified, e.g. by inspecting the data directory in the Databricks CLI using <code>databricks fs ls dbfs:/data/stg-ab</code> or running in a Workspace shell notebook <code>ls /dbfs/data/stg-ab</code></li>
<li>database: in the second phase specific columns are put into the database. This can be verified in the Workspace -&gt; Data -&gt; default -&gt; int_ab
<img loading="lazy" alt="select table" src="/assets/images/select_table-7e7e1d0657aff229863bfe5d87b16c2e.png" width="726" height="476" class="img_ev3q">
<img loading="lazy" alt="table" src="/assets/images/table-f62d6019e5cbbb9c404209061ceb6b80.png" width="1694" height="821" class="img_ev3q"></li>
</ul>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>Note that our final table was defined as <code>DeltaLakeTableDataObject</code>.
With that, Smart Data Lake Builder automatically generates a Delta Lake Table in your Databricks workspace.</p></div></div>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="lessons-learned">Lessons Learned<a href="#lessons-learned" class="hash-link" aria-label="Direct link to Lessons Learned" title="Direct link to Lessons Learned">​</a></h2>
<p>There are a few steps necessary, including building and uploading SDLB.
Further, we need to be careful with the used versions of the underlying libraries.
With these few steps we can reveal the power of SDLB and Databricks, creating a portable and reproducible pipeline into a Databricks Lakehouse.</p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/databricks">Databricks</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/cloud">Cloud</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/smart-data-lake/smart-data-lake/tree/documentation/blog/2022-04-07-SDL_databricks/2022-04-07-Databricks.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/sdl-hist"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Incremental historization using CDC and Airbyte MSSQL connector</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/sdl-snowpark"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Combine Spark and Snowpark to ingest and transform data in one pipeline</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#lessons-learned" class="table-of-contents__link toc-highlight">Lessons Learned</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/">Getting started</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/smart-data-lake/smart-data-lake" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/smart-data-lake/smart-data-lake/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Issues<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.elca.ch" target="_blank" rel="noopener noreferrer" class="footer__link-item">ELCA<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Smart Data Lake, Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>