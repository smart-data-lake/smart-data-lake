# Root logger option
log4j.rootLogger=INFO, stdout

# Direct log messages to stdout
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Target=System.out
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n

# debugging
log4j.logger.io.smartdatalake.workflow.ActionDAG=DEBUG

# too verbose
log4j.logger.org.apache.spark.sql.catalyst.parser.CatalystSqlParser=WARN
log4j.logger.org.spark_project.jetty.server.handler.ContextHandler=WARN
log4j.logger.org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport=WARN
log4j.logger.org.apache.spark.sql.execution.datasources.parquet.ParquetReadSupport=WARN
log4j.logger.org.apache.spark.sql.execution.FileSourceScanExec=WARN
log4j.logger.org.apache.spark.sql.execution.datasources.FileSourceStrategy=WARN
log4j.logger.org.apache.spark.sql.execution.aggregate.HashAggregateExec=WARN
log4j.logger.org.apache.spark.sql.catalyst.expressions.codegen=WARN
log4j.logger.org.apache.spark.storage.memory.MemoryStore=WARN
log4j.logger.org.apache.spark.storage.ShuffleBlockFetcherIterator=WARN
log4j.logger.org.apache.spark.ContextCleaner=WARN
log4j.logger.org.apache.spark.sql.execution.command.DropTableCommand=ERROR
log4j.logger.org.apache.hadoop.hive.metastore.HiveMetaStore=WARN
log4j.logger.org.apache.parquet.filter2.compat.FilterCompat=WARN
log4j.logger.org.apache.parquet.hadoop.codec.CodecConfig=WARN
